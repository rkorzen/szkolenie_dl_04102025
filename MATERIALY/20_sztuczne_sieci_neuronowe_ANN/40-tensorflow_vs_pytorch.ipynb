{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0d836a4e18c5d49",
   "metadata": {},
   "source": [
    "# TensorFlow/Keras vs PyTorch — porównanie tworzenia modeli i warstw\n",
    "\n",
    "Cel: Krótkie, praktyczne porównanie sposobu definiowania modeli w TensorFlow/Keras i w PyTorch oraz mapowanie najpopularniejszych warstw/klas. Na końcu: notatka o różnicach (także dot. liczenia gradientów) i mini‑przykłady gradientów w obu bibliotekach.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9bbb6fdf2bff3",
   "metadata": {},
   "source": [
    "## Szybki przegląd API\n",
    "\n",
    "- Keras (tf.keras): wysoki poziom, dwa style definiowania modeli:\n",
    "  - Sequential (proste, warstwa po warstwie)\n",
    "  - Functional (dowolne grafy, wiele wejść/wyjść)\n",
    "- PyTorch: definiujemy klasę dziedziczącą po `nn.Module` i implementujemy metodę `forward`.\n",
    "- Trening:\n",
    "  - Keras: `model.compile(...); model.fit(...)`\n",
    "  - PyTorch: pętla treningowa: `zero_grad() → forward → loss → backward() → step()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3243becd70c9b80",
   "metadata": {},
   "source": [
    "## Mapowanie najpopularniejszych warstw i klas\n",
    "\n",
    "- Gęste\n",
    "  - Keras: `layers.Dense(units, activation=...)`\n",
    "  - PyTorch: `nn.Linear(in_features, out_features)` + aktywacja osobno (np. `nn.ReLU()`)\n",
    "- Konwolucje 2D\n",
    "  - Keras: `layers.Conv2D(filters, kernel_size, strides, padding)`\n",
    "  - PyTorch: `nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)`\n",
    "- Spłaszczanie\n",
    "  - Keras: `layers.Flatten()`\n",
    "  - PyTorch: `nn.Flatten()` lub `x.view(batch, -1)`\n",
    "- Dropout\n",
    "  - Keras: `layers.Dropout(rate)`\n",
    "  - PyTorch: `nn.Dropout(p)`\n",
    "- Batch Normalization (2D)\n",
    "  - Keras: `layers.BatchNormalization()`\n",
    "  - PyTorch: `nn.BatchNorm2d(num_features)`\n",
    "- Max/Average Pooling 2D\n",
    "  - Keras: `layers.MaxPooling2D(pool_size)`, `layers.AveragePooling2D(pool_size)`\n",
    "  - PyTorch: `nn.MaxPool2d(kernel_size)`, `nn.AvgPool2d(kernel_size)`\n",
    "- Global Average Pooling\n",
    "  - Keras: `layers.GlobalAveragePooling2D()`\n",
    "  - PyTorch: `nn.AdaptiveAvgPool2d((1, 1))` + `Flatten`\n",
    "- Embedding\n",
    "  - Keras: `layers.Embedding(input_dim, output_dim)`\n",
    "  - PyTorch: `nn.Embedding(num_embeddings, embedding_dim)`\n",
    "- RNN/LSTM/GRU\n",
    "  - Keras: `layers.SimpleRNN`, `layers.LSTM`, `layers.GRU`\n",
    "  - PyTorch: `nn.RNN`, `nn.LSTM`, `nn.GRU`\n",
    "- Aktywacje\n",
    "  - Keras: `activation='relu'` lub osobno `layers.ReLU()`\n",
    "  - PyTorch: `nn.ReLU()`, `nn.Sigmoid()`, `nn.Softmax(dim=...)` itd.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b033577d178a6",
   "metadata": {},
   "source": [
    "## Minimalny przykład: MLP w Keras (Sequential) vs PyTorch (nn.Module) vs fasti (PyTorch)\n",
    "\n",
    "Poniżej: ten sam pomysł na mały klasyfikator (dane sztuczne). Najpierw Keras, potem PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc651397-da8d-449f-b1fa-4a0220a9bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KERAS: prosty MLP (Sequential) i szybki trening na danych sztucznych\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5e4fbf-c146-46af-9eb6-50cf1dccdbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTORCH: prosty MLP (nn.Module) i szybki trening na danych sztucznych\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aecd97b5-344b-426e-83ce-48b24e09e46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c0934481b587b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras — ostatnia epoka accuracy: 0.41200000047683716\n"
     ]
    }
   ],
   "source": [
    "# KERAS: prosty MLP (Sequential) i szybki trening na danych sztucznych\n",
    "np.random.seed(0)\n",
    "\n",
    "# Dane sztuczne: 1000 próbek, 20 cech, 3 klasy\n",
    "X = np.random.randn(1000, 20).astype(\"float32\")\n",
    "y = np.random.randint(0, 3, size=(1000,)).astype(\"int32\")\n",
    "\n",
    "model_keras = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(20,)),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "model_keras.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-2),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "history = model_keras.fit(X, y, epochs=5, batch_size=32, verbose=0)\n",
    "print(\"Keras — ostatnia epoka accuracy:\", history.history[\"accuracy\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61a1c059e669317",
   "metadata": {},
   "source": [
    "Teraz PyTorch: definiujemy klasę `nn.Module` i pętlę uczącą.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc14ba1a-1ef6-40d6-84cf-dea598deeacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTORCH: prosty MLP (nn.Module) i szybki trening na danych sztucznych\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f9aff9cea8d6737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch — accuracy: 0.5350000262260437\n"
     ]
    }
   ],
   "source": [
    "# PYTORCH: prosty MLP (nn.Module) i szybki trening na danych sztucznych\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(20, 32), nn.ReLU(), nn.Dropout(p=0.2), nn.Linear(32, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Dane sztuczne: 1000 próbek, 20 cech, 3 klasy\n",
    "X = np.random.randn(1000, 20).astype(\"float32\")\n",
    "y = np.random.randint(0, 3, size=(1000,)).astype(\"int32\")\n",
    "X_t = torch.tensor(X)\n",
    "y_t = torch.tensor(y, dtype=torch.long)\n",
    "train_loader = DataLoader(TensorDataset(X_t, y_t), batch_size=32, shuffle=True)\n",
    "model_torch = MLP()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model_torch.parameters(), lr=1e-2)\n",
    "model_torch.train()\n",
    "for epoch in range(5):\n",
    "    for xb, yb in train_loader:\n",
    "        optim.zero_grad()\n",
    "        logits = model_torch(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "# Prosty accuracy na całym zbiorze\n",
    "model_torch.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model_torch(X_t).argmax(dim=1)\n",
    "acc = (preds == y_t).float().mean().item()\n",
    "print(\"PyTorch — accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29bce4f8-f6c6-4ee7-b095-7968a3e81301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dodam tez fastai - taki keras dla PyTorch\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.learner import Learner\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.optimizer import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a6ff2b6-928f-4f43-a84f-9040915f57cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1.1273056268692017, 1.0761957168579102, 0.4180000126361847, '00:00']\n",
      "[1, 1.0985183715820312, 1.0573548078536987, 0.4449999928474426, '00:00']\n",
      "[2, 1.0864070653915405, 1.0414248704910278, 0.46700000762939453, '00:00']\n",
      "[3, 1.0765001773834229, 1.0227164030075073, 0.4740000069141388, '00:00']\n",
      "[4, 1.0633543729782104, 1.007742166519165, 0.5149999856948853, '00:00']\n",
      "fastai — accuracy: 0.5149999856948853\n"
     ]
    }
   ],
   "source": [
    "# Dane sztuczne\n",
    "np.random.seed(0)\n",
    "X = np.random.randn(1000, 20).astype(\"float32\")\n",
    "y = np.random.randint(0, 3, size=(1000,)).astype(\"int64\")\n",
    "X_t = torch.tensor(X)\n",
    "y_t = torch.tensor(y)\n",
    "\n",
    "\n",
    "# Model taki jak u Ciebie\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(20, 32), nn.ReLU(), nn.Dropout(p=0.2), nn.Linear(32, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Datasety fastai\n",
    "train_ds = TensorDataset(X_t, y_t)\n",
    "dls = DataLoaders.from_dsets(train_ds, train_ds, bs=32, shuffle=True)\n",
    "# Learner z fastai Adam\n",
    "learn = Learner(\n",
    "    dls, MLP(), loss_func=nn.CrossEntropyLoss(), opt_func=Adam, metrics=accuracy\n",
    ")\n",
    "learn.fit(5, lr=1e-2)\n",
    "acc = learn.validate()[1]\n",
    "print(\"fastai — accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f816525628b5776d",
   "metadata": {},
   "source": [
    "## Functional API (Keras) vs dowolne grafy w PyTorch\n",
    "\n",
    "- Functional Keras pozwala łączyć warstwy w graf z wieloma wejściami/wyjściami.\n",
    "- PyTorch daje pełną swobodę w `forward` (instrukcje warunkowe, pętle, gałęzie).\n",
    "\n",
    "Krótki przykład Functional w Keras:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20f6e2f07654c5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">672</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m672\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> (3.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m771\u001b[0m (3.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> (3.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m771\u001b[0m (3.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "inp = Input(shape=(20,))\n",
    "h = layers.Dense(32, activation=\"relu\")(inp)\n",
    "h = layers.Dropout(0.1)(h)\n",
    "out = layers.Dense(3, activation=\"softmax\")(h)\n",
    "func_model = Model(inputs=inp, outputs=out)\n",
    "func_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73212d584e46aa7f",
   "metadata": {},
   "source": [
    "W PyTorch ekwiwalent jest po prostu arbitralną logiką w `forward`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe7f3b7816447261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BranchyNet(\n",
      "  (fc1): Linear(in_features=20, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (act): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class BranchyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(20, 32)\n",
    "        self.fc2 = nn.Linear(32, 3)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.act(self.fc1(x))\n",
    "        if self.training:\n",
    "            h = self.dropout(h)\n",
    "        return self.fc2(h)\n",
    "\n",
    "\n",
    "m = BranchyNet()\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ec98f50d4254b",
   "metadata": {},
   "source": [
    "## Uwaga o wymiarach (NCHW vs NHWC)\n",
    "\n",
    "N – batch size\n",
    "\n",
    "H – height\n",
    "\n",
    "W – width\n",
    "\n",
    "C – channels\n",
    "\n",
    "- Keras/TensorFlow (domyślnie): dane obrazowe często w układzie NHWC (batch, height, width, channels).\n",
    "- PyTorch: standardowo NCHW (batch, channels, height, width). \n",
    "- Wpływa to na parametry warstw (np. `in_channels`) i konieczność permutacji wymiarów przy konwersji między frameworkami.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f2b48f3805e7c9",
   "metadata": {},
   "source": [
    "## Różnice: TensorFlow vs Keras (i liczenie gradientów)\n",
    "\n",
    "- Keras to wysoki poziom API; w TF 2.x zazwyczaj używamy `tf.keras` (Keras z silnikiem TF).\n",
    "- Keras (wysoki poziom): `compile`/`fit`/`evaluate`/`predict` — wygoda i gotowe pętle.\n",
    "- TensorFlow niski poziom: `tf.GradientTape` do ręcznego liczenia gradientów i pełnej kontroli.\n",
    "- PyTorch: jeden spójny, niski poziom; automatyczne różniczkowanie przez Autograd, pętle treningowe piszemy sami.\n",
    "- Gradienty:\n",
    "  - TensorFlow: w kontekście `tf.GradientTape()` śledzimy operacje i liczymy `tape.gradient(loss, params)`.\n",
    "  - PyTorch: tensory z `requires_grad=True`, wołamy `loss.backward()`, gradienty trafiają do `param.grad`.\n",
    "- Różnice praktyczne:\n",
    "  - Keras ukrywa sporo szczegółów (łatwy start). PyTorch wymaga więcej kodu, ale daje pełną elastyczność w `forward` i pętli treningowej.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5763f35f1a1c67ac",
   "metadata": {},
   "source": [
    "## Mini‑przykłady gradientów\n",
    "\n",
    "Pokażemy pochodną funkcji f(x) = x^2 w jednym punkcie w obu bibliotekach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e866491ea17f09e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF — dy/dx dla x=3: 6.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow: GradientTape\n",
    "x = tf.Variable(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    y = x**2\n",
    "(dy_dx,) = tape.gradient(y, [x])\n",
    "print(\"TF — dy/dx dla x=3:\", dy_dx.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51665cf08d7dc63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch — dy/dx dla x=3: 6.0\n"
     ]
    }
   ],
   "source": [
    "# PyTorch: Autograd\n",
    "t = torch.tensor(3.0, requires_grad=True)\n",
    "y = t**2\n",
    "y.backward()\n",
    "print(\"PyTorch — dy/dx dla x=3:\", t.grad.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489e405810ae0d1",
   "metadata": {},
   "source": [
    "## Krótkie podsumowanie\n",
    "\n",
    "- Definicja modeli:\n",
    "  - Keras: `Sequential` (najszybciej) lub `Functional` (elastycznie, wieloweściowy graf).\n",
    "  - PyTorch: klasa `nn.Module` + `forward` (pełna kontrola przepływu danych).\n",
    "- Warstwy mają bezpośrednie odpowiedniki (lista na górze), różnią się nazwami i detalami argumentów.\n",
    "- Gradienty: `tf.GradientTape` vs Autograd/`backward()`. Keras na wysokim poziomie ukrywa szczegóły w `fit()`.\n",
    "\n",
    "Gotowe — możesz skopiować i adaptować pokazane szablony do własnych projektów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b3d3d-c798-4977-b8fc-a23cab21c390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
