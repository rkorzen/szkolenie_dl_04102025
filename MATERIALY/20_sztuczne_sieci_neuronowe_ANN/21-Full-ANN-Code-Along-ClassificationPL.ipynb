{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Kompletny przykład sztucznej sieci neuronowej – **KLASYFIKACJA**\n",
    "\n",
    "W poprzedniej sekcji korzystaliśmy z czterech zmiennych ciągłych (długości), aby przeprowadzić klasyfikację.  \n",
    "\n",
    "Teraz połączymy dane **ciągłe** i **kategoryczne**, by wykonać podobną klasyfikację.  \n",
    "\n",
    "Celem jest oszacowanie, czy **przejazd taksówką w Nowym Jorku kosztuje mniej czy więcej niż 10 dolarów**, na podstawie kilku zmiennych wejściowych. \n",
    "\n",
    "Inspiracją do tego ćwiczenia jest [konkurs na Kaggle](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction).\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<strong>UWAGA:</strong>  \n",
    "Ten notatnik różni się od poprzedniego notatnika regresyjnego tym, że dla zbioru <tt><strong>y</strong></tt> używamy kolumny <tt>'fare_class'</tt>.  \n",
    "Wyjście ma **dwie wartości zamiast jednej**.  \n",
    "W tym zadaniu uczymy **model klasyfikacji binarnej** – przewiduje, czy kurs kosztuje **poniżej** czy **powyżej** 10 dolarów.\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "## Praca z danymi tabelarycznymi\n",
    "\n",
    "Uczenie głębokie z sieciami neuronowymi często kojarzy się z zaawansowanym rozpoznawaniem obrazów.  \n",
    "W kolejnych rozdziałach będziemy trenować modele analizujące piksele, wzorce i kolory.\n",
    "\n",
    "Tym razem pracujemy z **danymi tabelarycznymi** (arkusze kalkulacyjne, tabele SQL itp.), w których kolumny mogą – ale nie muszą – być istotne.  \n",
    "\n",
    "Sieci neuronowe potrafią odkrywać zależności, na które sami byśmy nie wpadli.  \n",
    "Aby to było możliwe, musimy traktować zmienne **kategoryczne** inaczej niż **ciągłe**.\n",
    "\n",
    "---\n",
    "\n",
    "### Kluczowe zagadnienia\n",
    "\n",
    "- **wartości ciągłe vs. kategoryczne**  \n",
    "- **embeddings**  \n",
    "- **batch normalization**  \n",
    "- **warstwy dropout**\n",
    "```\n",
    "\n",
    "Chcesz, żebym też zamienił ten `<div class=\"alert ...\">` na czysto-markdownowy blok typu > **UWAGA:**, żeby było w 100% zgodne z Markdownem, czy zostawić w wersji HTML (tak jak masz teraz)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykonaj standardowe importy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytaj zbiór NYC Taxi Fares\n",
    "<a href='https://www.kaggle.com/c/new-york-city-taxi-fare-prediction'>Konkurs Kaggle</a> udostępnia zbiór około 55 milionów rekordów. Dane obejmują wyłącznie datę i godzinę rozpoczęcia kursu, współrzędne GPS miejsca startu i zakończenia oraz liczbę pasażerów. To uczestnik konkursu decyduje, jakie dodatkowe informacje wydobyć. Czy pora dnia ma znaczenie? Dzień tygodnia? Jak wyliczyć odległość na podstawie par współrzędnych GPS?\n",
    "\n",
    "Na potrzeby ćwiczenia ograniczyliśmy zbiór do 120 000 rekordów z okresu 11–24 kwietnia 2010 r. Rekordy są losowo posortowane. Pokażemy, jak obliczyć odległość ze współrzędnych GPS oraz jak stworzyć obiekt datetime z kolumny tekstowej. Dzięki temu szybko uzyskamy informacje takie jak dzień tygodnia czy podział na AM/PM.\n",
    "\n",
    "Zaczynajmy!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/NYCTaxiFares.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fare_class\n",
       "0    80000\n",
       "1    40000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wygodnie, bo 2/3 danych zawiera kursy tańsze niż \\$10, a 1/3 droższe lub równe \\$10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasy odpowiadają kwotom przejazdu następująco:\n",
    "<table style=\"display: inline-block\">\n",
    "<tr><th>Klasa</th><th>Wartości</th></tr>\n",
    "<tr><td>0</td><td>< \\$10.00</td></tr>\n",
    "<tr><td>1</td><td>>= \\$10.00</td></tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oblicz przejechaną odległość\n",
    "<a href='https://en.wikipedia.org/wiki/Haversine_formula'>Wzór haversine</a> wyznacza odległość na kuli pomiędzy dwiema parami współrzędnych GPS.<br>\n",
    "Szerokość geograficzną oznaczymy przez $\\varphi$ (phi), a długość przez $\\lambda$ (lambda).\n",
    "\n",
    "Wzór przyjmuje postać\n",
    "\n",
    "${\\displaystyle d=2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\:\\cos(\\varphi _{2})\\:\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$\n",
    "\n",
    "przy czym\n",
    "\n",
    "$\\begin{split} r&: \\text{promień kuli (średni promień Ziemi to 6371 km)}\\\\\n",
    "\\varphi_1, \\varphi_2&: \\text{szerokości geograficzne punktów 1 i 2}\\\\\n",
    "\\lambda_1, \\lambda_2&: \\text{długości geograficzne punktów 1 i 2}\\end{split}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # średni promień Ziemi w kilometrach\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # w kilometrach\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km  \n",
       "0  2.126312  \n",
       "1  1.392307  \n",
       "2  3.326763  \n",
       "3  1.864129  \n",
       "4  7.231321  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dist_km'] = haversine_distance(df,'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodaj kolumnę datetime i wyprowadź przydatne statystyki\n",
    "Tworząc obiekt datetime, możemy wydobyć informacje takie jak „dzień tygodnia” czy „przed południem / po południu”. Zwróć uwagę, że dane zapisano w czasie UTC. Nasz zakres obejmuje kwiecień 2010 r., czyli okres obowiązywania czasu letniego w Nowym Jorku. Dlatego przeliczymy czas na EDT, odejmując cztery godziny (UTC-4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "      <th>EDTdate</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AMorPM</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>2010-04-19 04:17:56</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>2010-04-17 11:43:53</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>2010-04-17 07:23:26</td>\n",
       "      <td>7</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>2010-04-11 17:25:03</td>\n",
       "      <td>17</td>\n",
       "      <td>pm</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "      <td>2010-04-16 22:19:01</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km             EDTdate  Hour AMorPM Weekday  \n",
       "0  2.126312 2010-04-19 04:17:56     4     am     Mon  \n",
       "1  1.392307 2010-04-17 11:43:53    11     am     Sat  \n",
       "2  3.326763 2010-04-17 07:23:26     7     am     Sat  \n",
       "3  1.864129 2010-04-11 17:25:03    17     pm     Sun  \n",
       "4  7.231321 2010-04-16 22:19:01    22     pm     Fri  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)\n",
    "df['Hour'] = df['EDTdate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour']<12,'am','pm')\n",
    "df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-04-11 00:00:10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-04-24 23:59:42')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oddziel kolumny kategoryczne od ciągłych\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'dist_km', 'EDTdate', 'Hour', 'AMorPM', 'Weekday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "y_col = ['fare_class']  # ta kolumna zawiera etykiety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>UWAGA:</strong> Jeśli planujesz wykorzystać wszystkie kolumny z tabeli, możesz w prosty sposób pobrać pozostałe kolumny ciągłe:<br>\n",
    "<pre style='background-color:rgb(217,237,247)'>cont_cols = [col for col in df.columns if col not in cat_cols + y_col]</pre>\n",
    "\n",
    "Tutaj wpisaliśmy kolumny ciągłe ręcznie, ponieważ pomijamy te, które nie trafią do modelu (fare_amount i EDTdate).</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zamiana na typ category\n",
    "Pandas udostępnia typ danych <a href='https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html'><strong>category</strong></a>, który zamienia wartości kategoryczne na kody liczbowe. Zbiór zawierający miesiące roku otrzyma 12 kodów, po jednym na każdy miesiąc (zwykle od 0 do 11). Pandas zastępuje wartości w kolumnie kodami i przechowuje listę kategorii. W kolejnych krokach będziemy odwoływać się do „nazw” kategorii i przypisanych im „kodów”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zamień trzy kolumny kategoryczne na typ category.\n",
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime              object\n",
       "fare_amount                 float64\n",
       "fare_class                    int64\n",
       "pickup_longitude            float64\n",
       "pickup_latitude             float64\n",
       "dropoff_longitude           float64\n",
       "dropoff_latitude            float64\n",
       "passenger_count               int64\n",
       "dist_km                     float64\n",
       "EDTdate              datetime64[ns]\n",
       "Hour                       category\n",
       "AMorPM                     category\n",
       "Weekday                    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy sprawdzić, że <tt>df['Hour']</tt> to cecha kategoryczna, wyświetlając kilka wierszy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    11\n",
       "2     7\n",
       "3    17\n",
       "4    22\n",
       "Name: Hour, dtype: category\n",
       "Categories (24, int32): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy, że nazwami kategorii są tutaj liczby całkowite od 0 do 23, czyli 24 unikalne wartości. Te liczby <em>również</em> odpowiadają kodom nadanym każdej nazwie.\n",
    "\n",
    "Do nazw kategorii odwołujemy się przez <tt>Series.cat.categories</tt>, a do samych kodów przez <tt>Series.cat.codes</tt>. Łatwiej to zrozumieć na przykładzie <tt>df['AMorPM']</tt>:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    am\n",
       "1    am\n",
       "2    am\n",
       "3    pm\n",
       "4    pm\n",
       "Name: AMorPM, dtype: category\n",
       "Categories (2, object): ['am', 'pm']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['am', 'pm'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "dtype: int8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head().cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    2\n",
       "3    3\n",
       "4    0\n",
       "dtype: int8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].head().cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>UWAGA:</strong> W danych kategorycznych wartości NaN otrzymują kod -1. W tym zbiorze takich wartości nie ma.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz chcemy połączyć trzy kolumny kategoryczne w jedną tablicę wejściową przy użyciu <a href='https://docs.scipy.org/doc/numpy/reference/generated/numpy.stack.html'><tt>numpy.stack</tt></a>. Interesują nas wyłącznie wartości, bez indeksu Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1],\n",
       "       [11,  0,  2],\n",
       "       [ 7,  0,  2],\n",
       "       [17,  1,  3],\n",
       "       [22,  1,  0]], dtype=int8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr = df['Hour'].cat.codes.values\n",
    "ampm = df['AMorPM'].cat.codes.values\n",
    "wkdy = df['Weekday'].cat.codes.values\n",
    "\n",
    "cats = np.stack([hr, ampm, wkdy], 1)\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>UWAGA:</strong> Można to zrobić w jednej linii z użyciem list comprehension:\n",
    "<pre style='background-color:rgb(217,237,247)'>cats = np.stack([df[col].cat.codes.values for col in cat_cols], 1)</pre>\n",
    "\n",
    "Nie przejmujemy się na razie typem danych – ustawimy <tt>int64</tt>, gdy będziemy tworzyć tensor.</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwersja tablic NumPy na tensory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3],\n",
       "        [22,  1,  0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Przekonwertuj zmienne kategoryczne na tensor\n",
    "cats = torch.tensor(cats, dtype=torch.int64)\n",
    "# this syntax is ok, since the source data is an array, not an existing tensor\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy przekazać wszystkie zmienne ciągłe do modelu jako tensor. Zauważ, że nie normalizujemy ich teraz – pozwolimy zrobić to modelowi.\n",
    "<div class=\"alert alert-info\"><strong>UWAGA:</strong> Aby batch normalization działał poprawnie, musimy zapisać <tt>conts</tt> i <tt>y</tt> jako tensory typu Float (float32), a nie Double (float64).</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   1.0000,   2.1263],\n",
       "        [ 40.7406, -73.9901,  40.7441, -73.9742,   1.0000,   1.3923],\n",
       "        [ 40.7511, -73.9941,  40.7662, -73.9601,   2.0000,   3.3268],\n",
       "        [ 40.7564, -73.9905,  40.7482, -73.9712,   1.0000,   1.8641],\n",
       "        [ 40.7342, -73.9910,  40.7431, -73.9060,   1.0000,   7.2313]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Przekonwertuj zmienne ciągłe na tensor\n",
    "conts = np.stack([df[col].values for col in cont_cols], 1)\n",
    "conts = torch.tensor(conts, dtype=torch.float)\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uwaga: funkcja CrossEntropyLoss, której użyjemy później, oczekuje tensorów y w postaci 1D. Zamiast <tt>.reshape(-1,1)</tt> użyjemy więc tym razem <tt>.flatten()</tt>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Przekonwertuj etykiety na tensor\n",
    "y = torch.tensor(df[y_col].values).flatten()\n",
    "\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ustal rozmiary embeddingów\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will set embedding sizes for Hours, AMvsPM and Weekdays\n",
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zdefiniuj TabularModel\n",
    "Model nawiązuje nieco do <a href='https://docs.fast.ai/tabular.models.html'>biblioteki fast.ai</a>. Chcemy zdefiniować architekturę na podstawie liczby kolumn ciągłych (<tt>conts.shape[1]</tt>) oraz liczby kolumn kategorycznych i ich embeddingów (<tt>len(emb_szs)</tt> i <tt>emb_szs</tt>). Wyjściem może być regresja (pojedyncza wartość zmiennoprzecinkowa) albo klasyfikacja (zestaw klas i ich wartości softmax). W tym ćwiczeniu wyjście będzie dwuelementowym wektorem – po jednej wartości dla każdej klasy. Założymy, że dane zawierają zarówno cechy kategoryczne, jak i ciągłe. We własnych klasach możesz dodać parametry boolowskie, aby obsługiwać inne przypadki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Model sieci neuronowej do danych tabelarycznych łączący:\n",
    "    - embeddingi dla zmiennych kategorycznych,\n",
    "    - normalizację i gęste warstwy dla zmiennych ciągłych.\n",
    "\n",
    "    Założenia / Konwencje:\n",
    "    - Każda kolumna kategoryczna jest reprezentowana jako indeks całkowity (torch.long)\n",
    "      w zakresie [0, liczba_kategorii-1]. To bardzo ważne dla nn.Embedding.\n",
    "    - Zmienne ciągłe są typu float (torch.float) i mają kształt [batch_size, n_cont].\n",
    "    - Wyjście to logity o kształcie [batch_size, out_sz]; do klasyfikacji z CrossEntropyLoss.\n",
    "\n",
    "    Parametry\n",
    "    ---------\n",
    "    emb_szs : list[tuple[int, int]]\n",
    "        Lista krotek (liczba_kategorii, wymiar_embeddingu) dla każdej kolumny kategorycznej.\n",
    "        Np. [(2, 2), (14, 6), (6, 3), (5, 3), (12, 6)].\n",
    "        Uwaga: indeksy wejściowe MUSZĄ być 0-based i < liczba_kategorii.\n",
    "    n_cont : int\n",
    "        Liczba zmiennych ciągłych (kolumn numerycznych).\n",
    "    out_sz : int\n",
    "        Rozmiar wyjścia modelu (np. liczba klas).\n",
    "    layers : list[int]\n",
    "        Rozmiary kolejnych ukrytych warstw liniowych (np. [200, 100]).\n",
    "    p : float, domyślnie 0.5\n",
    "        Prawdopodobieństwo dropout (stosowane zarówno na embeddingach, jak i w warstwach gęstych).\n",
    "\n",
    "    Przepływ danych\n",
    "    ---------------\n",
    "    x_cat (LongTensor) -> Embedding -> konkatenacja -> Dropout\n",
    "                         + x_cont (FloatTensor) -> BatchNorm -> konkatenacja\n",
    "                         -> bloki Linear/ReLU/BatchNorm/Dropout -> Linear -> logity\n",
    "\n",
    "    Przykład wejścia\n",
    "    ----------------\n",
    "    x_cat : torch.LongTensor o kształcie [B, K] (B — batch, K — liczba kolumn kategorycznych)\n",
    "    x_cont: torch.FloatTensor o kształcie [B, n_cont]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embeddingi dla każdej kolumny kategorycznej.\n",
    "        # Dla (ni, nf): ni = liczba kategorii, nf = wymiar wektora embeddingu.\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in emb_szs])\n",
    "\n",
    "        # Dropout na połączonych embeddingach pomaga zapobiegać przeuczeniu (overfitting).\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "\n",
    "        # Normalizacja zmiennych ciągłych stabilizuje trening (uśrednia/standaryzuje aktywacje).\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "\n",
    "        # Obliczamy łączny wymiar embeddingów i wejścia do pierwszej warstwy gęstej.\n",
    "        n_emb = sum(nf for _, nf in emb_szs)  # suma wymiarów wszystkich embeddingów\n",
    "        n_in = n_emb + n_cont                 # embeddingi + zmienne ciągłe\n",
    "\n",
    "        # Budujemy sekwencję bloków: Linear -> ReLU -> BatchNorm -> Dropout\n",
    "        layerlist = []\n",
    "        for hidden_size in layers:\n",
    "            layerlist.append(nn.Linear(n_in, hidden_size))   # projekcja do ukrytej przestrzeni\n",
    "            layerlist.append(nn.ReLU(inplace=True))          # nieliniowość (szybka i stabilna)\n",
    "            layerlist.append(nn.BatchNorm1d(hidden_size))    # stabilizacja rozkładu aktywacji\n",
    "            layerlist.append(nn.Dropout(p))                  # regularizacja\n",
    "            n_in = hidden_size\n",
    "\n",
    "        # Ostatnia warstwa liniowa do rozmiaru wyjścia (np. liczba klas).\n",
    "        layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "\n",
    "        # Łączymy wszystko w jedną sekwencję wykonywalnych modułów.\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "\n",
    "    def forward(self, x_cat: torch.Tensor, x_cont: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Wykonuje propagację w przód.\n",
    "\n",
    "        Parametry\n",
    "        ---------\n",
    "        x_cat : torch.LongTensor, kształt [B, K]\n",
    "            Indeksy kategorii (0-based) dla K kolumn kategorycznych. Każda kolumna musi\n",
    "            mieć wartości < liczba_kategorii zdefiniowana w `emb_szs`.\n",
    "        x_cont : torch.FloatTensor, kształt [B, n_cont]\n",
    "            Zmienne ciągłe (numeryczne).\n",
    "\n",
    "        Zwraca\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Logity o kształcie [B, out_sz] — surowe wyniki do użycia z CrossEntropyLoss.\n",
    "        \"\"\"\n",
    "        # 1) Embedding dla każdej kolumny kategorycznej; dostajemy listę [B, nf_i]\n",
    "        embeddings = []\n",
    "        for i, emb in enumerate(self.embeds):\n",
    "            # x_cat[:, i] to wektor indeksów dla i-tej kolumny (kształt: [B])\n",
    "            embeddings.append(emb(x_cat[:, i]))\n",
    "\n",
    "        # 2) Konkatenacja wszystkich embeddingów do jednego tensora [B, sum(nf)]\n",
    "        x = torch.cat(embeddings, dim=1)\n",
    "\n",
    "        # 3) Dropout na embeddingach (regularizacja)\n",
    "        x = self.emb_drop(x)\n",
    "\n",
    "        # 4) Normalizacja zmiennych ciągłych i doklejenie ich do embeddingów\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], dim=1)\n",
    "\n",
    "        # 5) Przepuszczenie przez zdefiniowane bloki gęste\n",
    "        x = self.layers(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ℹ️ Przejdźmy przez kroki, które wykonaliśmy. Poniżej znajdziesz bardziej szczegółowe informacje.**\n",
    "\n",
    "---\n",
    "\n",
    "1. **Rozszerzamy bazową klasę `Module` i przekazujemy parametry:**\n",
    "   - `emb_szs`: lista krotek – liczba kategorii oraz rozmiar embeddingu dla każdej kolumny  \n",
    "   - `n_cont`: liczba zmiennych ciągłych  \n",
    "   - `out_sz`: rozmiar wyjścia  \n",
    "   - `layers`: lista rozmiarów kolejnych warstw  \n",
    "   - `p`: prawdopodobieństwo dropout (dla uproszczenia jedna wartość)  \n",
    "\n",
    "   ```python\n",
    "   class TabularModel(nn.Module):\n",
    "       def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "           super().__init__()\n",
    "\n",
    "\n",
    "2. **Tworzymy warstwy embeddingów** przy użyciu [`torch.nn.ModuleList`](https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html) oraz [`torch.nn.Embedding`](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html).\n",
    "   Dane kategoryczne przejdą przez te embeddingi w metodzie `forward`.\n",
    "\n",
    "   ```python\n",
    "   self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in emb_szs])\n",
    "   ```\n",
    "\n",
    "3. **Dodajemy dropout** dla embeddingów za pomocą [`torch.nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html).\n",
    "   Domyślnie `p = 0.5`.\n",
    "\n",
    "   ```python\n",
    "   self.emb_drop = nn.Dropout(p)\n",
    "   ```\n",
    "\n",
    "4. **Tworzymy funkcję normalizującą** dla zmiennych ciągłych z [`torch.nn.BatchNorm1d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html).\n",
    "\n",
    "   ```python\n",
    "   self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "   ```\n",
    "\n",
    "5. **Budujemy sekwencję warstw sieci:**\n",
    "   `Linear → ReLU → BatchNorm → Dropout`\n",
    "   Na końcu dodajemy warstwę wyjściową. Wszystko składamy w [`torch.nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html).\n",
    "\n",
    "   ```python\n",
    "   layerlist = []\n",
    "   n_emb = sum((nf for ni, nf in emb_szs))\n",
    "   n_in = n_emb + n_cont\n",
    "\n",
    "   for i in layers:\n",
    "       layerlist.append(nn.Linear(n_in, i))\n",
    "       layerlist.append(nn.ReLU(inplace=True))\n",
    "       layerlist.append(nn.BatchNorm1d(i))\n",
    "       layerlist.append(nn.Dropout(p))\n",
    "       n_in = i\n",
    "\n",
    "   layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "   self.layers = nn.Sequential(*layerlist)\n",
    "   ```\n",
    "\n",
    "6. **Definiujemy metodę `forward`:**\n",
    "\n",
    "   * najpierw przetwarzamy embeddingi\n",
    "   * następnie normalizujemy zmienne ciągłe\n",
    "   * na końcu przekazujemy dane przez warstwy\n",
    "\n",
    "   Do łączenia tensorów używamy [`torch.cat`](https://pytorch.org/docs/stable/generated/torch.cat.html).\n",
    "\n",
    "   ```python\n",
    "   def forward(self, x_cat, x_cont):\n",
    "       embeddings = []\n",
    "       for i, e in enumerate(self.embeds):\n",
    "           embeddings.append(e(x_cat[:, i]))\n",
    "       x = torch.cat(embeddings, 1)\n",
    "       x = self.emb_drop(x)\n",
    "\n",
    "       x_cont = self.bn_cont(x_cont)\n",
    "       x = torch.cat([x, x_cont], 1)\n",
    "\n",
    "       x = self.layers(x)\n",
    "       return x\n",
    "   ```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>Breaking down the embeddings steps</strong> (this code is for illustration purposes only.)</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To nasze dane źródłowe\n",
    "catz = cats[:4]\n",
    "catz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To jest przekazywane podczas tworzenia instancji modelu\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 4)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To przypisanie wykonywane jest w metodzie __init__()\n",
    "selfembeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "selfembeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, Embedding(24, 12)), (1, Embedding(2, 1)), (2, Embedding(7, 4))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(selfembeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.7232, -0.7835,  0.7790, -1.0627, -1.5836,  1.2645, -1.3451,  0.1102,\n",
       "          -0.6855,  1.0613,  0.4491, -0.2776],\n",
       "         [ 0.7909, -0.1582,  0.1696, -0.6959,  1.5319,  0.4137, -1.3975,  0.7816,\n",
       "          -0.2047, -1.3527, -0.0670, -1.7311],\n",
       "         [ 1.1835,  0.0372, -0.1430,  1.3317, -0.8409,  2.3899,  0.7840, -0.8389,\n",
       "           0.7472,  0.3831,  0.8816,  0.7843],\n",
       "         [-0.5777,  0.4101, -0.6764,  0.4647, -0.6966, -0.7015, -0.8748, -1.4114,\n",
       "           0.5709, -0.3537, -0.6927,  0.1717]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.7280],\n",
       "         [-0.7280],\n",
       "         [-0.7280],\n",
       "         [-0.7037]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.2462,  1.7763,  0.3319, -1.4416],\n",
       "         [ 1.5747, -0.2930, -0.2527, -0.3491],\n",
       "         [ 1.5747, -0.2930, -0.2527, -0.3491],\n",
       "         [-0.6523,  0.5418, -1.2006, -0.3129]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To dzieje się wewnątrz metody forward()\n",
    "embeddingz = []\n",
    "for i,e in enumerate(selfembeds):\n",
    "    embeddingz.append(e(catz[:,i]))\n",
    "embeddingz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7232, -0.7835,  0.7790, -1.0627, -1.5836,  1.2645, -1.3451,  0.1102,\n",
       "         -0.6855,  1.0613,  0.4491, -0.2776, -0.7280, -0.2462,  1.7763,  0.3319,\n",
       "         -1.4416],\n",
       "        [ 0.7909, -0.1582,  0.1696, -0.6959,  1.5319,  0.4137, -1.3975,  0.7816,\n",
       "         -0.2047, -1.3527, -0.0670, -1.7311, -0.7280,  1.5747, -0.2930, -0.2527,\n",
       "         -0.3491],\n",
       "        [ 1.1835,  0.0372, -0.1430,  1.3317, -0.8409,  2.3899,  0.7840, -0.8389,\n",
       "          0.7472,  0.3831,  0.8816,  0.7843, -0.7280,  1.5747, -0.2930, -0.2527,\n",
       "         -0.3491],\n",
       "        [-0.5777,  0.4101, -0.6764,  0.4647, -0.6966, -0.7015, -0.8748, -1.4114,\n",
       "          0.5709, -0.3537, -0.6927,  0.1717, -0.7037, -0.6523,  0.5418, -1.2006,\n",
       "         -0.3129]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Łączymy sekcje embeddingów (12,1,4) w jedną (17)\n",
    "z = torch.cat(embeddingz, 1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To zostało przypisane w metodzie __init__()\n",
    "selfembdrop = nn.Dropout(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2053, -1.3058,  1.2983, -1.7711, -2.6394,  2.1076, -2.2419,  0.1837,\n",
       "         -1.1426,  1.7688,  0.0000, -0.4627, -0.0000, -0.0000,  2.9605,  0.0000,\n",
       "         -2.4027],\n",
       "        [ 1.3181, -0.0000,  0.2827, -0.0000,  0.0000,  0.6896, -2.3291,  1.3026,\n",
       "         -0.3411, -2.2545, -0.0000, -2.8851, -0.0000,  2.6245, -0.4884, -0.4212,\n",
       "         -0.0000],\n",
       "        [ 1.9725,  0.0621, -0.0000,  2.2194, -1.4014,  3.9831,  1.3067, -0.0000,\n",
       "          0.0000,  0.0000,  1.4693,  0.0000, -1.2133,  2.6245, -0.0000, -0.0000,\n",
       "         -0.5818],\n",
       "        [-0.0000,  0.6835, -0.0000,  0.0000, -0.0000, -1.1691, -1.4580, -0.0000,\n",
       "          0.9515, -0.0000, -1.1545,  0.2861, -1.1728, -1.0871,  0.9029, -2.0010,\n",
       "         -0.5215]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = selfembdrop(z)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><strong>Tak przekazujemy embeddingi kategoryczne do kolejnych warstw.</strong></div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs, conts.shape[1], 2, [200,100], p=0.4) # out_sz = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zdefiniuj funkcję straty i optymalizator\n",
    "W klasyfikacji zastąpimy funkcję MSE odpowiednikiem <a href='https://pytorch.org/docs/stable/nn.html#crossentropyloss'><strong><tt>torch.nn.CrossEntropyLoss()</tt></strong></a>.<br>\n",
    "Jako optymalizatora nadal użyjemy <a href='https://pytorch.org/docs/stable/optim.html#torch.optim.Adam'><strong><tt>torch.optim.Adam()</tt></strong></a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podziel dane na zbiory treningowy i testowy\n",
    "W tej chwili rozmiar partii odpowiada całemu zbiorowi 120 000 rekordów. Aby oszczędzić czas, wykorzystamy pierwsze 60 000. Pamiętaj, że nasze tensory są już losowo potasowane.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60000\n",
    "test_size = 12000\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wytrenuj model\n",
    "Przygotuj się na około 30 minut pracy! Dodaliśmy kod, który na końcu poda czas trwania.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 0.83336741\n",
      "epoch:  26  loss: 0.37834561\n",
      "epoch:  51  loss: 0.33235851\n",
      "epoch:  76  loss: 0.31583560\n",
      "epoch: 101  loss: 0.30307907\n",
      "epoch: 126  loss: 0.29316762\n",
      "epoch: 151  loss: 0.28483155\n",
      "epoch: 176  loss: 0.28016236\n",
      "epoch: 201  loss: 0.27618173\n",
      "epoch: 226  loss: 0.26887164\n",
      "epoch: 251  loss: 0.26491734\n",
      "epoch: 276  loss: 0.26132721\n",
      "epoch: 300  loss: 0.25677466\n",
      "\n",
      "Duration: 29 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # sprytny trik, żeby oszczędzić miejsce na ekranie:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # wypisz ostatnią linię\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # wypisz czas trwania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykres funkcji straty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), [loss.detach().numpy() for loss in losses])\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zweryfikuj model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.25060156\n"
     ]
    }
   ],
   "source": [
    "# ABY OCENIĆ CAŁY ZBIÓR TESTOWY\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'CE Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spójrzmy teraz na pierwsze 50 przewidywanych wartości.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT               ARGMAX  Y_TEST\n",
      "tensor([ 2.2166, -0.9363])    0      0   \n",
      "tensor([-3.9228,  3.1928])    1      0   \n",
      "tensor([ 2.1874, -1.1944])    0      0   \n",
      "tensor([-1.6648,  0.9327])    1      1   \n",
      "tensor([ 2.8884, -1.1588])    0      0   \n",
      "tensor([ 1.1080, -2.1643])    0      0   \n",
      "tensor([ 2.4007, -1.4130])    0      0   \n",
      "tensor([-4.9656,  1.4911])    1      1   \n",
      "tensor([ 1.0492, -3.0409])    0      0   \n",
      "tensor([-1.2398,  1.3428])    1      1   \n",
      "tensor([ 1.2044, -1.7862])    0      0   \n",
      "tensor([ 3.0715, -0.9532])    0      0   \n",
      "tensor([ 1.8248, -1.4403])    0      0   \n",
      "tensor([-2.0106,  0.7805])    1      1   \n",
      "tensor([ 1.7691, -2.1559])    0      0   \n",
      "tensor([-3.5679,  1.1670])    1      1   \n",
      "tensor([ 1.5308, -2.3760])    0      1   \n",
      "tensor([ 1.7814, -2.1364])    0      0   \n",
      "tensor([ 1.0488, -0.3051])    0      0   \n",
      "tensor([ 2.2438, -1.7580])    0      0   \n",
      "tensor([-2.7073,  0.2314])    1      1   \n",
      "tensor([-1.4891,  0.5462])    1      1   \n",
      "tensor([-2.0723,  0.4434])    1      1   \n",
      "tensor([-2.5130,  1.7858])    1      1   \n",
      "tensor([-5.9460,  3.6746])    1      1   \n",
      "tensor([ 1.4134, -1.7819])    0      0   \n",
      "tensor([ 1.7990, -2.3646])    0      0   \n",
      "tensor([ 1.3151, -1.1858])    0      0   \n",
      "tensor([-1.8215,  1.3192])    1      1   \n",
      "tensor([ 1.7808, -1.2366])    0      0   \n",
      "tensor([ 1.5861, -1.7808])    0      0   \n",
      "tensor([-5.0697,  3.4757])    1      1   \n",
      "tensor([-1.7587,  1.1426])    1      1   \n",
      "tensor([-2.2388,  1.2163])    1      1   \n",
      "tensor([ 1.5983, -1.7567])    0      0   \n",
      "tensor([ 0.8129, -0.4442])    0      0   \n",
      "tensor([-4.2066,  3.1407])    1      1   \n",
      "tensor([ 1.4215, -1.0084])    0      1   \n",
      "tensor([ 0.7268, -0.5954])    0      1   \n",
      "tensor([ 1.2073, -1.6507])    0      0   \n",
      "tensor([0.8005, 0.0820])      0      0   \n",
      "tensor([ 0.2287, -0.7798])    0      0   \n",
      "tensor([-0.8904,  1.5076])    1      1   \n",
      "tensor([ 1.7653, -2.2026])    0      0   \n",
      "tensor([ 1.1502, -1.3617])    0      0   \n",
      "tensor([-2.2024,  0.3694])    1      1   \n",
      "tensor([-4.7752,  2.3362])    1      1   \n",
      "tensor([ 3.3072, -1.2142])    0      0   \n",
      "tensor([ 2.8488, -0.8065])    0      0   \n",
      "tensor([-0.3670, -0.0448])    1      0   \n",
      "\n",
      "45 out of 50 = 90.00% correct\n"
     ]
    }
   ],
   "source": [
    "rows = 50\n",
    "correct = 0\n",
    "print(f'{\"MODEL OUTPUT\":26} ARGMAX  Y_TEST')\n",
    "for i in range(rows):\n",
    "    print(f'{str(y_val[i]):26} {y_val[i].argmax():^7}{y_test[i]:^7}')\n",
    "    if y_val[i].argmax().item() == y_test[i]:\n",
    "        correct += 1\n",
    "print(f'\\n{correct} out of {rows} = {100*correct/rows:.2f}% correct')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapisz model\n",
    "Zapisz wytrenowany model do pliku, aby w przyszłości móc zasilić go nowymi danymi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pamiętaj, żeby zapisać model dopiero po zakończeniu treningu!\n",
    "if len(losses) == epochs:\n",
    "    torch.save(model.state_dict(), 'TaxiFareClssModel.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytanie zapisanego modelu (od zera)\n",
    "Możemy wczytać wyuczone wagi i biasy z zapisanej wersji. Jeśli dopiero otworzyłeś notatnik, uruchom najpierw standardowe importy i definicje funkcji. Aby to zademonstrować, przed dalszą pracą zrestartuj kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    r = 6371\n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    return r * c\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujmy model. Zanim załadujemy zapisane ustawienia, musimy utworzyć TabularModel z tymi samymi parametrami co wcześniej (rozmiary embeddingów, liczba zmiennych ciągłych, rozmiar wyjścia, rozmiary warstw i wartość dropout).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = [(24, 12), (2, 1), (7, 4)]\n",
    "model2 = TabularModel(emb_szs, 6, 2, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy model jest gotowy, załadowanie zapisanych ustawień to formalność.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('TaxiFareClssModel.pt'));\n",
    "model2.eval() # koniecznie wykonaj ten krok!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujemy teraz funkcję, która przyjmie nowe dane użytkownika, wykona wszystkie opisane wcześniej kroki przetwarzania i przekaże dane przez wytrenowany model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(mdl): # przekaż nazwę nowego modelu\n",
    "    # WPROWADŹ NOWE DANE\n",
    "    plat = float(input('What is the pickup latitude?  '))\n",
    "    plong = float(input('What is the pickup longitude? '))\n",
    "    dlat = float(input('What is the dropoff latitude?  '))\n",
    "    dlong = float(input('What is the dropoff longitude? '))\n",
    "    psngr = int(input('How many passengers? '))\n",
    "    dt = input('What is the pickup date and time?\\nFormat as YYYY-MM-DD HH:MM:SS     ')\n",
    "    \n",
    "    # PRZETWÓRZ DANE\n",
    "    dfx_dict = {'pickup_latitude':plat,'pickup_longitude':plong,'dropoff_latitude':dlat,\n",
    "         'dropoff_longitude':dlong,'passenger_count':psngr,'EDTdate':dt}\n",
    "    dfx = pd.DataFrame(dfx_dict, index=[0])\n",
    "    dfx['dist_km'] = haversine_distance(dfx,'pickup_latitude', 'pickup_longitude',\n",
    "                                        'dropoff_latitude', 'dropoff_longitude')\n",
    "    dfx['EDTdate'] = pd.to_datetime(dfx['EDTdate'])\n",
    "    \n",
    "    # Możemy pominąć krok .astype(category), bo pola są niewielkie,\n",
    "    # i zakodować je od razu\n",
    "    dfx['Hour'] = dfx['EDTdate'].dt.hour\n",
    "    dfx['AMorPM'] = np.where(dfx['Hour']<12,0,1) \n",
    "    dfx['Weekday'] = dfx['EDTdate'].dt.strftime(\"%a\")\n",
    "    dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n",
    "                                            [0,1,2,3,4,5,6]).astype('int64')\n",
    "    # UTWÓRZ TENSORY KAT I CONT\n",
    "    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "    cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "                 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "    xcats = np.stack([dfx[col].values for col in cat_cols], 1)\n",
    "    xcats = torch.tensor(xcats, dtype=torch.int64)\n",
    "    xconts = np.stack([dfx[col].values for col in cont_cols], 1)\n",
    "    xconts = torch.tensor(xconts, dtype=torch.float)\n",
    "    \n",
    "    # PRZEPROWADŹ DANE PRZEZ MODEL BEZ WYKONYWANIA BACKPROP\n",
    "    with torch.no_grad():\n",
    "        z = mdl(xcats, xconts).argmax().item()\n",
    "    print(f'\\nThe predicted fare class is {z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przepuść nowe dane przez wytrenowany model\n",
    "Dla wygody poniżej znajdziesz wartości minimalne i maksymalne każdej zmiennej:\n",
    "<table style=\"display: inline-block\">\n",
    "<tr><th>Kolumna</th><th>Minimum</th><th>Maksimum</th></tr>\n",
    "<tr><td>pickup_latitude</td><td>40</td><td>41</td></tr>\n",
    "<tr><td>pickup_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n",
    "<tr><td>dropoff_latitude</td><td>40</td><td>41</td></tr>\n",
    "<tr><td>dropoff_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n",
    "<tr><td>passenger_count</td><td>1</td><td>5</td></tr>\n",
    "<tr><td>EDTdate</td><td>2010-04-11 00:00:00</td><td>2010-04-24 23:59:42</td></tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Zachowaj ostrożność!</strong> Odległość odpowiadająca 1 stopniowi szerokości geograficznej (od 40 do 41) to 111 km (69 mil), a 1 stopniowi długości (od -73 do -74) – 85 km (53 mile). Najdłuższy kurs w zbiorze różnił się zaledwie o 0.243 stopnia szerokości i 0.284 stopnia długości. Średnia różnica dla obu wynosi ok. 0.02. Aby uzyskać wiarygodne prognozy, korzystaj z wartości położonych blisko siebie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "What is the pickup latitude?   40\n",
      "What is the pickup longitude?  -74.5\n",
      "What is the dropoff latitude?   41\n",
      "What is the dropoff longitude?  -73\n",
      "How many passengers?  2\n",
      "What is the pickup date and time?\n",
      "Format as YYYY-MM-DD HH:MM:SS      2010-04-22 11:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted fare class is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/6wst9f1n1g96lc__ld426szh0000gn/T/ipykernel_36178/1854116044.py:23: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n"
     ]
    }
   ],
   "source": [
    "test_data(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Świetnie! Poprzednia regresja przewidywała cenę około \\$14, a klasyfikacja binarna słusznie ocenia, że kurs przekracza 10 dolarów.\n",
    "## Świetna robota!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
