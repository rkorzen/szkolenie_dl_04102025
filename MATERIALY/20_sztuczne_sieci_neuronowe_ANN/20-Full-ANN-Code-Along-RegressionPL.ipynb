{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kompletny przykład sztucznej sieci neuronowej\n",
    "\n",
    "W poprzedniej sekcji korzystaliśmy z czterech zmiennych ciągłych (długości), aby przeprowadzić klasyfikację. Teraz połączymy dane ciągłe i kategoryczne, by wykonać regresję. Celem jest oszacowanie kosztu przejazdu taksówką w Nowym Jorku na podstawie kilku zmiennych wejściowych. Inspiracją do tego ćwiczenia jest ostatni [konkurs na Kaggle](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction).\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**UWAGA:**  \n",
    "W tym notatniku przeprowadzimy regresję z pojedynczą wartością wyjściową. W kolejnym wykonamy klasyfikację binarną z dwiema wartościami wyjściowymi.\n",
    "\n",
    "</div>\n",
    "\n",
    "## Praca z danymi tabelarycznymi\n",
    "\n",
    "Uczenie głębokie z sieciami neuronowymi często kojarzy się z zaawansowanym rozpoznawaniem obrazów. W kolejnych rozdziałach będziemy trenować modele analizujące piksele, wzorce i kolory.\n",
    "\n",
    "Tym razem pracujemy z danymi tabelarycznymi (arkusze kalkulacyjne, tabele SQL itp.), w których kolumny mogą, ale nie muszą być istotne. Sieci neuronowe potrafią odkrywać zależności, na które sami byśmy nie wpadli. \n",
    "\n",
    "Aby to jednak umożliwić, musimy traktować zmienne kategoryczne inaczej niż ciągłe.\n",
    "\n",
    "Na początku musimy przyjrzeć się tym zagadnieniom by wykorzystać tę wiedze dalej:\n",
    "\n",
    "\n",
    "* wartości ciągłe vs. kategoryczne  \n",
    "* embeddings  \n",
    "* batch normalization  \n",
    "* warstwy dropout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykonaj standardowe importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:43.426865Z",
     "start_time": "2025-09-24T20:17:41.981833Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytaj zbiór NYC Taxi Fares\n",
    "\n",
    "[Konkurs Kaggle](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction) udostępnia zbiór około 55 milionów rekordów. Dane obejmują wyłącznie datę i godzinę rozpoczęcia kursu, współrzędne GPS miejsca startu i zakończenia oraz liczbę pasażerów. To uczestnik konkursu decyduje, jakie dodatkowe informacje wydobyć. Czy pora dnia ma znaczenie? Dzień tygodnia? Jak wyliczyć odległość na podstawie par współrzędnych GPS?  \n",
    "\n",
    "Na potrzeby ćwiczenia ograniczyliśmy zbiór do **120 000 rekordów** z okresu 11–24 kwietnia 2010 r. Rekordy są losowo posortowane. \n",
    "\n",
    "Pokażemy, jak obliczyć odległość ze współrzędnych GPS oraz jak stworzyć obiekt `datetime` z kolumny tekstowej. Dzięki temu szybko uzyskamy informacje takie jak dzień tygodnia, podział na AM/PM itd.  \n",
    "\n",
    "Zaczynajmy!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:45.834863Z",
     "start_time": "2025-09-24T20:17:45.711085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/NYCTaxiFares.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:46.979977Z",
     "start_time": "2025-09-24T20:17:46.970742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120000.000000\n",
       "mean         10.040326\n",
       "std           7.500134\n",
       "min           2.500000\n",
       "25%           5.700000\n",
       "50%           7.700000\n",
       "75%          11.300000\n",
       "max          49.900000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy, że ceny wahają się od `$2.50` do `$49.90`, średnia wynosi `$10.04`, a mediana `\\$7.70`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oblicz przejechaną odległość\n",
    "\n",
    "[Wzór haversine](https://en.wikipedia.org/wiki/Haversine_formula) wyznacza odległość na kuli pomiędzy dwiema parami współrzędnych GPS.  \n",
    "\n",
    "Szerokość geograficzną oznaczymy przez $\\varphi$ (phi), a długość przez $\\lambda$ (lambda).\n",
    "\n",
    "Wzór przyjmuje postać:\n",
    "\n",
    "$$\n",
    "d = 2r \\arcsin \\left( \n",
    "    \\sqrt{ \n",
    "        \\sin^2\\!\\left(\\frac{\\varphi_2 - \\varphi_1}{2}\\right) \n",
    "        + \\cos(\\varphi_1)\\cos(\\varphi_2)\\sin^2\\!\\left(\\frac{\\lambda_2 - \\lambda_1}{2}\\right) \n",
    "    } \n",
    "\\right)\n",
    "$$\n",
    "\n",
    "przy czym:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "r & : \\text{ promień kuli (średni promień Ziemi to 6371 km)} \\\\\n",
    "\\varphi_1, \\varphi_2 & : \\text{ szerokości geograficzne punktów 1 i 2} \\\\\n",
    "\\lambda_1, \\lambda_2 & : \\text{ długości geograficzne punktów 1 i 2} \\\\\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:50.425594Z",
     "start_time": "2025-09-24T20:17:50.422943Z"
    }
   },
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # średni promień Ziemi w kilometrach\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # w kilometrach\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastosujmy tę funkcję do stworzenia nowej kolumny:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:51.903127Z",
     "start_time": "2025-09-24T20:17:51.893907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km  \n",
       "0  2.126312  \n",
       "1  1.392307  \n",
       "2  3.326763  \n",
       "3  1.864129  \n",
       "4  7.231321  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dist_km'] = haversine_distance(df,'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodaj kolumnę datetime i wyprowadź przydatne statystyki\n",
    "\n",
    "Tworząc obiekt `datetime`, możemy wydobyć takie informacje jak „dzień tygodnia” czy „przed południem / po południu”.  \n",
    "Zwróć uwagę, że dane zapisano w czasie **UTC**. Nasz zakres obejmuje kwiecień 2010 r., czyli okres obowiązywania czasu letniego w Nowym Jorku.  \n",
    "\n",
    "Dlatego przeliczymy czas na **EDT**, odejmując cztery godziny (UTC-4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:54.479729Z",
     "start_time": "2025-09-24T20:17:54.222033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "      <th>EDTdate</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AMorPM</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>2010-04-19 04:17:56</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>2010-04-17 11:43:53</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>2010-04-17 07:23:26</td>\n",
       "      <td>7</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>2010-04-11 17:25:03</td>\n",
       "      <td>17</td>\n",
       "      <td>pm</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "      <td>2010-04-16 22:19:01</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km             EDTdate  Hour AMorPM Weekday  \n",
       "0  2.126312 2010-04-19 04:17:56     4     am     Mon  \n",
       "1  1.392307 2010-04-17 11:43:53    11     am     Sat  \n",
       "2  3.326763 2010-04-17 07:23:26     7     am     Sat  \n",
       "3  1.864129 2010-04-11 17:25:03    17     pm     Sun  \n",
       "4  7.231321 2010-04-16 22:19:01    22     pm     Fri  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)\n",
    "df['Hour'] = df['EDTdate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour']<12,'am','pm')\n",
    "df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:55.716068Z",
     "start_time": "2025-09-24T20:17:55.712855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-04-11 00:00:10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:56.877014Z",
     "start_time": "2025-09-24T20:17:56.874605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-04-24 23:59:42')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oddziel kolumny kategoryczne od ciągłych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:00.979481Z",
     "start_time": "2025-09-24T20:18:00.976742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'dist_km', 'EDTdate', 'Hour', 'AMorPM', 'Weekday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:02.988549Z",
     "start_time": "2025-09-24T20:18:02.986693Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "y_col = ['fare_amount']  # ta kolumna zawiera etykiety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**UWAGA:**  \n",
    "Jeśli planujesz wykorzystać wszystkie kolumny z tabeli, możesz w prosty sposób pobrać pozostałe kolumny ciągłe:\n",
    "\n",
    "```python\n",
    "cont_cols = [col for col in df.columns if col not in cat_cols + y_col]\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zamiana na typ category\n",
    "\n",
    "Pandas udostępnia typ danych [**category**](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html), \n",
    "który zamienia wartości kategoryczne na kody liczbowe.  \n",
    "\n",
    "Zbiór zawierający miesiące roku otrzyma 12 kodów, po jednym na każdy miesiąc (zwykle od 0 do 11).  \n",
    "Pandas zastępuje wartości w kolumnie kodami i przechowuje listę kategorii.  \n",
    "\n",
    "W kolejnych krokach będziemy odwoływać się do „nazw” kategorii i przypisanych im „kodów”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:19.625653Z",
     "start_time": "2025-09-24T20:18:19.583713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zamień trzy kolumny kategoryczne na typ category.\n",
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:20.617148Z",
     "start_time": "2025-09-24T20:18:20.612202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime              object\n",
       "fare_amount                 float64\n",
       "fare_class                    int64\n",
       "pickup_longitude            float64\n",
       "pickup_latitude             float64\n",
       "dropoff_longitude           float64\n",
       "dropoff_latitude            float64\n",
       "passenger_count               int64\n",
       "dist_km                     float64\n",
       "EDTdate              datetime64[ns]\n",
       "Hour                       category\n",
       "AMorPM                     category\n",
       "Weekday                    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Możemy sprawdzić, że `df['Hour']` to cecha kategoryczna, wyświetlając kilka wierszy:\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:36.743533Z",
     "start_time": "2025-09-24T20:18:36.740786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    11\n",
       "2     7\n",
       "3    17\n",
       "4    22\n",
       "Name: Hour, dtype: category\n",
       "Categories (24, int32): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy, że nazwami kategorii są tutaj liczby całkowite od 0 do 23, czyli 24 unikalne wartości.  \n",
    "Te liczby *również* odpowiadają kodom nadanym każdej nazwie.  \n",
    "\n",
    "Do nazw kategorii odwołujemy się przez `Series.cat.categories`,  \n",
    "a do samych kodów przez `Series.cat.codes`.  \n",
    "\n",
    "Łatwiej to zrozumieć na przykładzie `df['AMorPM']`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:54.294917Z",
     "start_time": "2025-09-24T20:18:54.289742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    am\n",
       "1    am\n",
       "2    am\n",
       "3    pm\n",
       "4    pm\n",
       "Name: AMorPM, dtype: category\n",
       "Categories (2, object): ['am', 'pm']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:55.509077Z",
     "start_time": "2025-09-24T20:18:55.505691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['am', 'pm'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:56.492350Z",
     "start_time": "2025-09-24T20:18:56.486048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "dtype: int8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head().cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:59.402117Z",
     "start_time": "2025-09-24T20:18:59.398906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:00.477241Z",
     "start_time": "2025-09-24T20:19:00.474161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    2\n",
       "3    3\n",
       "4    0\n",
       "dtype: int8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].head().cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**UWAGA:**  \n",
    "W danych kategorycznych wartości `NaN` otrzymują kod `-1`.  \n",
    "W tym zbiorze takich wartości nie ma.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz chcemy połączyć trzy kolumny kategoryczne w jedną tablicę wejściową przy użyciu <a href='https://docs.scipy.org/doc/numpy/reference/generated/numpy.stack.html'><tt>numpy.stack</tt></a>. Interesują nas wyłącznie wartości, bez indeksu Series.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:19.361739Z",
     "start_time": "2025-09-24T20:19:19.317963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1],\n",
       "       [11,  0,  2],\n",
       "       [ 7,  0,  2],\n",
       "       [17,  1,  3],\n",
       "       [22,  1,  0]], dtype=int8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr = df['Hour'].cat.codes.values\n",
    "ampm = df['AMorPM'].cat.codes.values\n",
    "wkdy = df['Weekday'].cat.codes.values\n",
    "\n",
    "cats = np.stack([hr, ampm, wkdy], 1)\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**UWAGA:**  \n",
    "Można to zrobić w jednej linii z użyciem list comprehension:\n",
    "\n",
    "```python\n",
    "cats = np.stack([df[col].cat.codes.values for col in cat_cols], 1)\n",
    "```\n",
    "\n",
    "Nie przejmujemy się na razie typem danych – ustawimy int64, gdy będziemy tworzyć tensor.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwersja tablic NumPy na tensory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:33.611802Z",
     "start_time": "2025-09-24T20:19:33.559387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3],\n",
       "        [22,  1,  0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Przekonwertuj zmienne kategoryczne na tensor\n",
    "cats = torch.tensor(cats, dtype=torch.int64) \n",
    "# ta składnia jest w porządku, ponieważ dane źródłowe to tablica, a nie istniejący tensor\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Możemy przekazać wszystkie zmienne ciągłe do modelu jako tensor.  \n",
    "Zauważ, że nie normalizujemy ich teraz – pozwolimy zrobić to modelowi.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**UWAGA:**  \n",
    "Aby batch normalization działał poprawnie, najlepiej zapisywać dane wejściowe (`conts`) w typie **Float** (`float32`), a nie **Double** (`float64`).  \n",
    "\n",
    "BatchNorm w PyTorchu i TensorFlow potrafi działać także na `float64` czy `float16`, o ile wszystkie wejścia i parametry mają ten sam typ.  \n",
    "W praktyce jednak niemal zawsze stosuje się `float32`, ponieważ:  \n",
    "\n",
    "- jest to standardowy typ dla CPU i GPU,  \n",
    "- zapewnia lepszą wydajność i mniejsze zużycie pamięci niż `float64`,  \n",
    "- większość warstw i optymalizatorów jest testowana właśnie na `float32`.  \n",
    "\n",
    "`float64` działa wolniej i rzadko daje korzyści w uczeniu modeli.  \n",
    "\n",
    "**Wyjątki – typ zmiennej docelowej `y`:**  \n",
    "- w **klasyfikacji wieloklasowej** (`nn.CrossEntropyLoss`) `y` powinna być typu `LongTensor` z **indeksami klas** (np. `[0, 2, 1]`),  \n",
    "  ponieważ `CrossEntropyLoss` sam stosuje *softmax* i porównuje logity modelu z numerem poprawnej klasy.  \n",
    "- w **regresji** `y` zwykle jest `float32`.  \n",
    "\n",
    "👉 **Podsumowanie:**  \n",
    "- Dane ciągłe (`conts`) → `float32`  \n",
    "- Zmienna docelowa (`y`) → zależy od zadania:  \n",
    "  - klasyfikacja → `long` (indeksy klas)  \n",
    "  - regresja → `float32`\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:43.324264Z",
     "start_time": "2025-09-24T20:19:43.295467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   1.0000,   2.1263],\n",
       "        [ 40.7406, -73.9901,  40.7441, -73.9742,   1.0000,   1.3923],\n",
       "        [ 40.7511, -73.9941,  40.7662, -73.9601,   2.0000,   3.3268],\n",
       "        [ 40.7564, -73.9905,  40.7482, -73.9712,   1.0000,   1.8641],\n",
       "        [ 40.7342, -73.9910,  40.7431, -73.9060,   1.0000,   7.2313]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Przekonwertuj zmienne ciągłe na tensor\n",
    "conts = np.stack([df[col].values for col in cont_cols], 1)\n",
    "conts = torch.tensor(conts, dtype=torch.float)\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:47.266476Z",
     "start_time": "2025-09-24T20:19:47.263457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:49.544854Z",
     "start_time": "2025-09-24T20:19:49.538436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.5000],\n",
       "        [ 6.9000],\n",
       "        [10.1000],\n",
       "        [ 8.9000],\n",
       "        [19.7000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Przekonwertuj etykiety na tensor\n",
    "y = torch.tensor(df[y_col].values, dtype=torch.float).reshape(-1,1)\n",
    "\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:51.096527Z",
     "start_time": "2025-09-24T20:19:51.093479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:56.748749Z",
     "start_time": "2025-09-24T20:19:56.744205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:20:04.234068Z",
     "start_time": "2025-09-24T20:20:04.231836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ustal rozmiary embeddingów\n",
    "\n",
    "- [Dokumentacja PyTorch – nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)  \n",
    "- [Dyskusja na Quora: What does PyTorch Embedding do?](https://www.quora.com/What-does-PyTorch-Embedding-do)\n",
    "\n",
    "**Embedding** to sposób reprezentowania wartości kategorycznych jako gęstych wektorów liczb zmiennoprzecinkowych.  \n",
    "Zamiast korzystać z **one-hot encoding** (gdzie każdy unikalny element dostaje bardzo długi wektor pełen zer), embedding przypisuje każdej kategorii krótki wektor o ustalonej liczbie wymiarów.  \n",
    "\n",
    "Na przykład:  \n",
    "- mamy kolumnę `day_of_week` z wartościami od 0 do 6,  \n",
    "- zamiast zamieniać to na 7 kolumn zero-jedynkowych, możemy każdej kategorii przypisać wektor, np. 3-wymiarowy:  \n",
    "```\n",
    "\n",
    "Monday    → [ 0.1,  0.8, -0.3]\n",
    "Tuesday   → [-0.5,  0.2,  0.7]\n",
    "...\n",
    "Sunday    → [ 0.3, -0.6,  0.1]\n",
    "\n",
    "```\n",
    "- Wektory embeddingów są **uczone w trakcie trenowania modelu**, więc sieć sama dobiera ich wartości, tak aby najlepiej reprezentowały informację.\n",
    "\n",
    "---\n",
    "\n",
    "### Jak dobrać rozmiar embeddingu?\n",
    "\n",
    "Nie istnieje ścisła reguła matematyczna, ale w praktyce stosuje się proste heurystyki:\n",
    "\n",
    "- **Częsta zasada**:  \n",
    "Rozmiar embeddingu ≈ liczba unikalnych kategorii ÷ 2  \n",
    "\n",
    "- **Ograniczenie górne**:  \n",
    "Zwykle nie ma sensu przekraczać ~50 wymiarów (dla większości klasycznych problemów tablicowych).  \n",
    "\n",
    "- **Przykłady**:  \n",
    "| Kolumna                  | Liczba unikalnych wartości | Rozmiar embeddingu |\n",
    "|---------------------------|-----------------------------|---------------------|\n",
    "| `day_of_week` (dni tygodnia) | 7                           | 3–4                 |\n",
    "| `month` (miesiące roku)      | 12                          | 6                   |\n",
    "| `zipcode` (kody pocztowe)    | 200                         | 50 (górny limit)    |\n",
    "| `user_id` (duży zbiór ID)    | 10 000                      | 50 (górny limit)    |\n",
    "\n",
    "---\n",
    "\n",
    "### Dlaczego embeddingi są lepsze niż one-hot?\n",
    "\n",
    "- **Kompaktowość** – dużo mniejszy wymiar wejściowy,  \n",
    "- **Uczenie zależności** – sieć sama odkrywa, które kategorie są do siebie podobne,  \n",
    "- **Wydajność** – mniej pamięci, szybsze trenowanie.  \n",
    "\n",
    "👉 Dzięki embeddingom model może np. nauczyć się, że „sobota” i „niedziela” mają podobny wpływ na wynik, mimo że w indeksach są odległe.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:20:16.208969Z",
     "start_time": "2025-09-24T20:20:16.206122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ustawi to rozmiary embeddingów dla Hours, AMvsPM i Weekdays\n",
    "\n",
    "# cat_szs = lista liczby unikalnych kategorii dla każdej kolumny kategorycznej\n",
    "# np. Hours ma 24 wartości (0–23), AMvsPM ma 2 wartości, Weekdays ma 7 wartości\n",
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "\n",
    "# emb_szs = lista krotek (num_categories, embedding_dim)\n",
    "# embedding_dim = połowa liczby kategorii, zaokrąglona w górę, ale maksymalnie 50\n",
    "# czyli stosujemy regułę: min(50, (N+1)//2)\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "\n",
    "# emb_szs będzie np. [(24, 12), (2, 1), (7, 4)]\n",
    "emb_szs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Hours` → embedding o wymiarze 12\n",
    "* `AMvsPM` → embedding o wymiarze 1\n",
    "* `Weekdays` → embedding o wymiarze 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**💡 Ciekawostka: fastai**\n",
    "\n",
    "Istnieje biblioteka **[fastai](https://docs.fast.ai/)** – można powiedzieć, że to taki *Keras dla PyTorcha*.  \n",
    "Powstała, aby **ułatwić i przyspieszyć** trenowanie modeli deep learning, korzystając z najlepszych praktyk.\n",
    "\n",
    "- działa na bazie **PyTorcha**, ale zapewnia **wyższy poziom abstrakcji**,\n",
    "- ma gotowe moduły do pracy z różnymi typami danych: obrazy, tekst, dane tabelaryczne, rekomendacje,\n",
    "- pozwala w kilku liniach stworzyć model i go wytrenować,\n",
    "- jednocześnie daje dostęp do „czystego” PyTorcha, gdy potrzebujesz pełnej kontroli.\n",
    "\n",
    "👉 Można więc powiedzieć, że **fastai = PyTorch dla praktyków** – szybki start, proste API, ale możliwość zejścia głębiej.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicja TabularModel\n",
    "\n",
    "To podejście częściowo nawiązuje do [biblioteki fast.ai](https://docs.fast.ai/tabular.model.html).  \n",
    "\n",
    "Celem jest zbudowanie modelu, który uwzględnia:\n",
    "\n",
    "- liczbę kolumn ciągłych (podaną przez `conts.shape[1]`),  \n",
    "- liczbę kolumn kategorycznych i odpowiadające im embeddingi (podane przez `len(emb_szs)` oraz samą listę `emb_szs`).  \n",
    "\n",
    "Wyjściem modelu może być:  \n",
    "\n",
    "- **regresja** – pojedyncza wartość zmiennoprzecinkowa,  \n",
    "- **klasyfikacja** – rozkład prawdopodobieństwa po klasach (np. wartości po softmax).  \n",
    "\n",
    "W tym ćwiczeniu naszym celem będzie **pojedyncza wartość regresyjna**.  \n",
    "\n",
    "Zakładamy, że dane zawierają zarówno zmienne kategoryczne, jak i ciągłe.  \n",
    "\n",
    "Do własnej klasy modelu można dodać parametry logiczne (np. `use_cats`, `use_conts`), aby obsłużyć różne warianty zbiorów danych.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krok po kroku – co robi TabularModel?\n",
    "\n",
    "### 1. Definiujemy parametry klasy\n",
    "\n",
    "* `emb_szs`: lista krotek z liczbą kategorii i rozmiarem embeddingu\n",
    "* `n_cont`: liczba zmiennych ciągłych\n",
    "* `out_sz`: rozmiar wyjścia\n",
    "* `layers`: lista rozmiarów kolejnych warstw ukrytych\n",
    "* `p`: wartość dropout dla każdej warstwy\n",
    "\n",
    "```python\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Tworzymy warstwy embeddingów\n",
    "\n",
    "Używamy [`torch.nn.ModuleList()`](https://pytorch.org/docs/stable/nn.html#modulelist) i [`torch.nn.Embedding()`](https://pytorch.org/docs/stable/nn.html#embedding). Dane kategoryczne przechodzą przez te embeddingi w metodzie forward.\n",
    "\n",
    "```python\n",
    "self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in emb_szs])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Dodajemy dropout do embeddingów\n",
    "\n",
    "Wykorzystujemy [`torch.nn.Dropout()`](https://pytorch.org/docs/stable/nn.html#dropout). Domyślnie `p = 0.5`.\n",
    "\n",
    "```python\n",
    "self.emb_drop = nn.Dropout(emb_drop)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Normalizujemy zmienne ciągłe\n",
    "\n",
    "Sięgamy po [`torch.nn.BatchNorm1d()`](https://pytorch.org/docs/stable/nn.html#batchnorm1d).\n",
    "\n",
    "```python\n",
    "self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Budujemy sekwencję warstw sieci\n",
    "\n",
    "Każda warstwa zawiera:\n",
    "\n",
    "* warstwę `Linear`\n",
    "* funkcję aktywacji (ReLU)\n",
    "* krok normalizacji\n",
    "* warstwę dropout\n",
    "\n",
    "Składamy je przy pomocy [`torch.nn.Sequential()`](https://pytorch.org/docs/stable/nn.html#sequential).\n",
    "\n",
    "```python\n",
    "self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "layerlist = []\n",
    "\n",
    "n_emb = sum((nf for ni, nf in emb_szs))\n",
    "n_in = n_emb + n_cont\n",
    "\n",
    "for i in layers:\n",
    "    layerlist.append(nn.Linear(n_in, i))\n",
    "    layerlist.append(nn.ReLU(inplace=True))\n",
    "    layerlist.append(nn.BatchNorm1d(i))\n",
    "    layerlist.append(nn.Dropout(p))\n",
    "    n_in = i\n",
    "\n",
    "layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "\n",
    "self.layers = nn.Sequential(*layerlist)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Definiujemy metodę `forward`\n",
    "\n",
    "Przetwarzamy embeddingi, normalizujemy zmienne ciągłe, a następnie przekazujemy wszystko przez kolejne warstwy. Do łączenia tensorów używamy [`torch.cat()`](https://pytorch.org/docs/stable/torch.html#torch.cat).\n",
    "\n",
    "```python\n",
    "def forward(self, x_cat, x_cont):\n",
    "    embeddings = []\n",
    "    for i, e in enumerate(self.embeds):\n",
    "        embeddings.append(e(x_cat[:, i]))\n",
    "    x = torch.cat(embeddings, 1)\n",
    "    x = self.emb_drop(x)\n",
    "\n",
    "    x_cont = self.bn_cont(x_cont)\n",
    "    x = torch.cat([x, x_cont], 1)\n",
    "    x = self.layers(x)\n",
    "    return x\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Pozostawiamy ten układ krok po kroku bez dodatkowych wyróżników – jest przejrzysty i wystarczający.\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\\\"alert alert-danger\\\"><strong>Rozbijamy krok embeddingów na części składowe</strong> (ten kod służy wyłącznie ilustracji).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:34.763036Z",
     "start_time": "2025-09-24T20:21:34.753376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To nasze dane źródłowe\n",
    "catz = cats[:4]\n",
    "catz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:36.086978Z",
     "start_time": "2025-09-24T20:21:36.083675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To jest przekazywane podczas tworzenia instancji modelu\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:37.891192Z",
     "start_time": "2025-09-24T20:21:37.887079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 4)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To przypisanie wykonywane jest w metodzie __init__()\n",
    "selfembeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "selfembeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:38.921117Z",
     "start_time": "2025-09-24T20:21:38.918681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, Embedding(24, 12)), (1, Embedding(2, 1)), (2, Embedding(7, 4))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(selfembeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:39.552902Z",
     "start_time": "2025-09-24T20:21:39.545002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.9052,  0.1919,  0.5433, -0.3039,  0.3522,  0.3176, -0.1628,  0.0160,\n",
       "          -1.8537,  0.0525,  0.6894,  2.2636],\n",
       "         [-0.8170, -0.2481, -0.5454,  0.9071,  1.5864, -0.0928,  0.6091,  0.0478,\n",
       "           0.2307, -1.8650, -0.9861,  0.2455],\n",
       "         [-0.8156,  1.3224,  0.6381,  0.7878,  0.2942,  1.2955, -0.7603,  0.5212,\n",
       "          -0.4220,  0.5602, -0.5419, -0.5408],\n",
       "         [ 0.9723, -0.4110, -1.3849,  0.2936, -0.2292,  0.4962, -0.5656,  1.2057,\n",
       "           2.6844, -0.8396, -1.7026,  0.3883]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 1.8399],\n",
       "         [ 1.8399],\n",
       "         [ 1.8399],\n",
       "         [-0.3339]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.6708, -2.2616,  0.7411, -0.0683],\n",
       "         [-0.9923, -0.3268,  0.4467,  2.0421],\n",
       "         [-0.9923, -0.3268,  0.4467,  2.0421],\n",
       "         [ 0.0135,  0.4746,  0.8613, -1.3922]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To dzieje się wewnątrz metody forward()\n",
    "embeddingz = []\n",
    "for i,e in enumerate(selfembeds):\n",
    "    embeddingz.append(e(catz[:,i]))\n",
    "embeddingz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:41.296841Z",
     "start_time": "2025-09-24T20:21:41.291532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9052,  0.1919,  0.5433, -0.3039,  0.3522,  0.3176, -0.1628,  0.0160,\n",
       "         -1.8537,  0.0525,  0.6894,  2.2636,  1.8399, -0.6708, -2.2616,  0.7411,\n",
       "         -0.0683],\n",
       "        [-0.8170, -0.2481, -0.5454,  0.9071,  1.5864, -0.0928,  0.6091,  0.0478,\n",
       "          0.2307, -1.8650, -0.9861,  0.2455,  1.8399, -0.9923, -0.3268,  0.4467,\n",
       "          2.0421],\n",
       "        [-0.8156,  1.3224,  0.6381,  0.7878,  0.2942,  1.2955, -0.7603,  0.5212,\n",
       "         -0.4220,  0.5602, -0.5419, -0.5408,  1.8399, -0.9923, -0.3268,  0.4467,\n",
       "          2.0421],\n",
       "        [ 0.9723, -0.4110, -1.3849,  0.2936, -0.2292,  0.4962, -0.5656,  1.2057,\n",
       "          2.6844, -0.8396, -1.7026,  0.3883, -0.3339,  0.0135,  0.4746,  0.8613,\n",
       "         -1.3922]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Łączymy sekcje embeddingów (12,1,4) w jedną (17)\n",
    "z = torch.cat(embeddingz, 1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:44.443784Z",
     "start_time": "2025-09-24T20:21:44.441489Z"
    }
   },
   "outputs": [],
   "source": [
    "# To zostało przypisane w metodzie __init__()\n",
    "selfembdrop = nn.Dropout(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:45.200786Z",
     "start_time": "2025-09-24T20:21:45.191279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5087,  0.0000,  0.9056, -0.0000,  0.5871,  0.5293, -0.2713,  0.0000,\n",
       "         -3.0895,  0.0000,  1.1490,  0.0000,  3.0666, -1.1180, -0.0000,  0.0000,\n",
       "         -0.1139],\n",
       "        [-1.3617, -0.4134, -0.9089,  1.5119,  2.6440, -0.0000,  1.0151,  0.0000,\n",
       "          0.3845, -3.1084, -0.0000,  0.0000,  3.0666, -0.0000, -0.0000,  0.7445,\n",
       "          3.4034],\n",
       "        [-1.3594,  2.2041,  0.0000,  1.3130,  0.0000,  2.1591, -0.0000,  0.8687,\n",
       "         -0.7034,  0.0000, -0.9032, -0.9014,  3.0666, -1.6538, -0.5447,  0.0000,\n",
       "          3.4034],\n",
       "        [ 0.0000, -0.0000, -2.3082,  0.0000, -0.0000,  0.0000, -0.0000,  2.0095,\n",
       "          0.0000, -0.0000, -2.8376,  0.0000, -0.0000,  0.0000,  0.0000,  1.4355,\n",
       "         -0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = selfembdrop(z)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\\\"alert alert-danger\\\"><strong>Tak przekazujemy embeddingi kategoryczne do kolejnych warstw.</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(24, 12)\n",
      "    (1): Embedding(2, 1)\n",
      "    (2): Embedding(7, 4)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        # Embeddingi dla kolumn kategorycznych\n",
    "        # Każda kategoria (np. \"miasto\", \"płeć\") dostaje własny wektor liczb\n",
    "        # To będzie powiązane z danymi które podamy w metodzie format\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in emb_szs])\n",
    "        \n",
    "        # Dropout na embeddingach – losowo zeruje część wartości, by model nie przeuczał się\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        \n",
    "        # BatchNorm dla cech ciągłych – normalizacja (średnia=0, wariancja=1), stabilizuje uczenie\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        # Budowa sieci gęstej (MLP)\n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni, nf in emb_szs))  # całkowita długość wektora embeddingów\n",
    "        n_in = n_emb + n_cont                    # wejście = embeddingi + cechy ciągłe\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in, i))     # warstwa liniowa (pełne połączenie)\n",
    "            layerlist.append(nn.ReLU(inplace=True))  # aktywacja ReLU wprowadza nieliniowość\n",
    "            layerlist.append(nn.BatchNorm1d(i))      # normalizacja wyjść danej warstwy\n",
    "            layerlist.append(nn.Dropout(p))          # dropout zapobiega przeuczeniu\n",
    "            n_in = i                                 # rozmiar wyjścia staje się wejściem dla następnej\n",
    "        layerlist.append(nn.Linear(layers[-1], out_sz))  # ostatnia warstwa → wynik (np. 1 logit)\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)  # łączenie wszystkiego w sekwencję\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        # --- 1. Embeddingi dla kolumn kategorycznych ---\n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:, i]))        # wektor embeddingu dla danej kolumny\n",
    "        \n",
    "        # Sklej wszystkie embeddingi w jedną macierz\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        \n",
    "        # Dropout na embeddingach\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        # --- 2. Normalizacja cech ciągłych ---\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        \n",
    "        # --- 3. Połączenie embeddingów i cech ciągłych ---\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        \n",
    "        # --- 4. Przepuszczenie przez sieć gęstą (MLP) ---\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# Przykład: 3 kolumny kategoryczne + 6 cech ciągłych\n",
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs=[(24, 12), (2, 1), (7, 4)],  # embeddingi dla kolumn kategorycznych\n",
    "                     n_cont=6,                           # liczba cech ciągłych\n",
    "                     out_sz=1,                           # jedno wyjście (np. do regresji/klasyfikacji binarnej)\n",
    "                     layers=[200, 100],                  # ukryte warstwy: 200 → 100\n",
    "                     p=0.4)                              # dropout = 0.4\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs, conts.shape[1], 1, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zdefiniuj funkcję straty i optymalizator\n",
    "\n",
    "PyTorch nie ma wbudowanej funkcji straty <a href='https://en.wikipedia.org/wiki/Root-mean-square_deviation'>RMSE</a>, a chcielibyśmy użyć jej zamiast MSE.\n",
    "\n",
    "Dlatego podczas trenowania zastosujemy `torch.sqrt()` na wyniku `MSELoss`.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # później przekształcimy to na RMSE\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podziel dane na zbiory treningowy i testowy\n",
    "\n",
    "W tej chwili rozmiar partii odpowiada całemu zbiorowi 120 000 rekordów. Trenowanie trwałoby bardzo długo, więc warto go zmniejszyć. My użyjemy 60 000. Pamiętaj, że nasze tensory są już losowo potasowane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60000\n",
    "test_size = int(batch_size * .2)\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wytrenuj model\n",
    "\n",
    "Przygotuj się na kilka minut pracy! Dodaliśmy kod, który na końcu poda czas trwania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 12.56661701\n",
      "epoch:  26  loss: 10.91411972\n",
      "epoch:  51  loss: 10.22180843\n",
      "epoch:  76  loss: 9.74225330\n",
      "epoch: 101  loss: 9.18566704\n",
      "epoch: 126  loss: 8.43124580\n",
      "epoch: 151  loss: 7.42796469\n",
      "epoch: 176  loss: 6.23023224\n",
      "epoch: 201  loss: 5.07406998\n",
      "epoch: 226  loss: 4.21130562\n",
      "epoch: 251  loss: 3.89492106\n",
      "epoch: 276  loss: 3.78523421\n",
      "epoch: 301  loss: 3.67429900\n",
      "epoch: 326  loss: 3.64834642\n",
      "epoch: 351  loss: 3.58250666\n",
      "epoch: 376  loss: 3.53372526\n",
      "epoch: 400  loss: 3.49451923\n",
      "\n",
      "Duration: 37 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 400\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # sprytny trik, żeby oszczędzić miejsce na ekranie:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # wypisz ostatnią linię\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # wypisz czas trwania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykres funkcji straty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), [loss.detach().numpy() for loss in losses])\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zweryfikuj model\n",
    "\n",
    "Przepuścimy cały zbiór testowy przez model i porównamy wyniki z rzeczywistymi etykietami.  \n",
    "Na tym etapie **nie chcemy aktualizować wag i biasów**, dlatego użyjemy kontekstu `torch.no_grad()`.\n",
    "\n",
    "---\n",
    "\n",
    "## RMSE – Root Mean Squared Error\n",
    "\n",
    "**RMSE** (pierwiastek z błędu średniokwadratowego) to jedna z najczęściej stosowanych metryk do oceny jakości modeli regresyjnych.  \n",
    "\n",
    "### Jak działa?\n",
    "\n",
    "1. Model przewiduje wartości $\\hat{y}_i$, a my mamy wartości rzeczywiste $y_i$.  \n",
    "2. Liczymy różnice (residua): $e_i = y_i - \\hat{y}_i$.  \n",
    "3. Podnosimy różnice do kwadratu: $e_i^2$ – dzięki temu nie ma znaczenia znak i mocniej karzemy duże błędy.  \n",
    "4. Liczymy średnią z tych kwadratów – to **MSE** (*Mean Squared Error*).  \n",
    "5. Bierzemy pierwiastek kwadratowy → otrzymujemy **RMSE**.  \n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 }\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretacja\n",
    "\n",
    "- RMSE jest **w tej samej jednostce**, co przewidywana wartość (np. złote, kilometry, stopnie Celsjusza).  \n",
    "- **Im mniejsze RMSE, tym lepiej** – oznacza to, że przewidywania są bliżej wartości rzeczywistych.  \n",
    "- RMSE jest **wrażliwe na duże odchylenia** (outliers), ponieważ błędy są podnoszone do kwadratu.  \n",
    "\n",
    "👉 Możesz myśleć o RMSE jako o **„średnim błędzie” w jednostkach przewidywanej wielkości**.\n",
    "\n",
    "```\n",
    "\n",
    "Chcesz, żebym przygotował jeszcze krótką tabelkę porównującą RMSE z MAE i R², żeby było jasne, kiedy którą metrykę wybrać?\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.43492579\n"
     ]
    }
   ],
   "source": [
    "# ABY OCENIĆ CAŁY ZBIÓR TESTOWY\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = torch.sqrt(criterion(y_val, y_test))\n",
    "print(f'RMSE: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oznacza to, że średnio prognozy różnią się od wartości rzeczywistej o ±\\$3.31.\n",
    "\n",
    "Spójrzmy teraz na pierwsze 10 przewidywanych wartości:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PREDICTED   ACTUAL     DIFF\n",
      " 1.   4.2129   2.9000   1.3129\n",
      " 2.  23.5540   5.7000  17.8540\n",
      " 3.   4.2738   7.7000   3.4262\n",
      " 4.  11.8067  12.5000   0.6933\n",
      " 5.   4.0164   4.1000   0.0836\n",
      " 6.   4.4431   5.3000   0.8569\n",
      " 7.   1.5540   3.7000   2.1460\n",
      " 8.  13.7873  14.5000   0.7127\n",
      " 9.   5.6618   5.7000   0.0382\n",
      "10.  14.4415  10.1000   4.3415\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
    "for i in range(10):\n",
    "    diff = np.abs(y_val[i].item()-y_test[i].item())\n",
    "    print(f'{i+1:2}. {y_val[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiele predykcji pomyliło się o kilka centów, ale niektóre nawet o kilkanaście dolarów.\n",
    "\n",
    "\n",
    "Spróbuj zmieniać rozmiar partii, wielkość zbioru testowego i liczbę epok, aby uzyskać lepszy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapisz model\n",
    "\n",
    "Wytrenowany model warto zachować, by później móc wykorzystać go do nowych danych.  \n",
    "Najlepszą praktyką jest zapis **stanu modelu** (wag i biasów), a nie całej definicji.  \n",
    "\n",
    "Upewnij się też, że zapisujesz wyłącznie **model po treningu**, aby nie nadpisać poprzedniej wersji nieprzeszkolonym modelem.  \n",
    "\n",
    "Więcej informacji znajdziesz w [oficjalnym poradniku PyTorch](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pamiętaj, żeby zapisać model dopiero po zakończeniu treningu!\n",
    "if len(losses) == epochs:\n",
    "    torch.save(model.state_dict(), 'TaxiFareRegrModel.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytanie zapisanego modelu (od zera)\n",
    "\n",
    "Możemy wczytać wyuczone wagi i biasy z zapisanej wersji.  \n",
    "Jeśli dopiero otworzyłeś notatnik, uruchom najpierw **standardowe importy** i **definicje funkcji**.  \n",
    "\n",
    "Aby to zademonstrować, przed dalszą pracą **zrestartuj kernel**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 12.50666714\n",
      "epoch:  26  loss: 10.72367573\n",
      "epoch:  51  loss: 10.12331867\n",
      "epoch:  76  loss: 9.70387554\n",
      "epoch: 101  loss: 9.19267559\n",
      "epoch: 126  loss: 8.44067955\n",
      "epoch: 151  loss: 7.45702410\n",
      "epoch: 176  loss: 6.23063993\n",
      "epoch: 201  loss: 4.99481392\n",
      "epoch: 226  loss: 4.14790440\n",
      "epoch: 251  loss: 3.81091595\n",
      "epoch: 276  loss: 3.70445657\n",
      "epoch: 301  loss: 3.64069176\n",
      "epoch: 326  loss: 3.58935976\n",
      "epoch: 351  loss: 3.55485582\n",
      "epoch: 376  loss: 3.53260016\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    r = 6371\n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    return r * c\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        return self.layers(x)\n",
    "\n",
    "emb_szs = [(24, 12), (2, 1), (7, 4)]\n",
    "model2 = TabularModel(emb_szs, 6, 1, [200,100], p=0.4)\n",
    "\n",
    "criterion = nn.MSELoss()  # później przekształcimy to na RMSE\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 400\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model2(cat_train, con_train)\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # sprytny trik, żeby oszczędzić miejsce na ekranie:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 12.54976082\n",
      "epoch:  26  loss: 12.54480553\n",
      "epoch:  51  loss: 12.54600620\n",
      "epoch:  76  loss: 12.54979801\n",
      "epoch: 101  loss: 12.54709244\n",
      "epoch: 126  loss: 12.55134201\n",
      "epoch: 151  loss: 12.55424976\n",
      "epoch: 176  loss: 12.54741573\n",
      "epoch: 201  loss: 12.54950523\n",
      "epoch: 226  loss: 12.55294704\n",
      "epoch: 251  loss: 12.55544281\n",
      "epoch: 276  loss: 12.55192089\n",
      "epoch: 301  loss: 12.55470371\n",
      "epoch: 326  loss: 12.54674244\n",
      "epoch: 351  loss: 12.54883003\n",
      "epoch: 376  loss: 12.54930496\n",
      "epoch: 400  loss: 12.54578018\n",
      "\n",
      "Duration: 40 seconds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujmy model. \n",
    "\n",
    "Zanim załadujemy zapisane ustawienia, musimy utworzyć instancję TabularModel z tymi samymi parametrami co wcześniej \n",
    "(rozmiary embeddingów, liczba zmiennych ciągłych, rozmiar wyjścia, rozmiary warstw i wartość dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_szs = [(24, 12), (2, 1), (7, 4)]\n",
    "# model2 = TabularModel(emb_szs, 6, 1, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy model jest gotowy, załadowanie zapisanych ustawień to formalność.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.load_state_dict(torch.load('TaxiFareRegrModel.pt'));\n",
    "# model2.eval() # koniecznie wykonaj ten krok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"TaxiFareClssModel.pt\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujemy teraz funkcję, która przyjmie nowe dane użytkownika, wykona wszystkie opisane wcześniej kroki przetwarzania i przepuści dane przez wytrenowany model.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_dataframe(\n",
    "    plat: float, plong: float,\n",
    "    dlat: float, dlong: float,\n",
    "    psngr: int, dt: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Buduje bazowy DataFrame z pojedynczym rekordem.\"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'pickup_latitude': plat,\n",
    "        'pickup_longitude': plong,\n",
    "        'dropoff_latitude': dlat,\n",
    "        'dropoff_longitude': dlong,\n",
    "        'passenger_count': psngr,\n",
    "        'EDTdate': pd.to_datetime(dt)\n",
    "    }, index=[0])\n",
    "\n",
    "\n",
    "def add_distance_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Dodaje kolumnę z odległością (w km).\"\"\"\n",
    "    df['dist_km'] = haversine_distance(\n",
    "        df, 'pickup_latitude', 'pickup_longitude',\n",
    "        'dropoff_latitude', 'dropoff_longitude'\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_datetime_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Dodaje cechy związane z czasem (Hour, AMorPM, Weekday).\"\"\"\n",
    "    df['Hour'] = df['EDTdate'].dt.hour\n",
    "    df['AMorPM'] = np.where(df['Hour'] < 12, 0, 1)\n",
    "    df['Weekday'] = (\n",
    "        df['EDTdate']\n",
    "        .dt.strftime(\"%a\")\n",
    "        .replace(\n",
    "            ['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n",
    "            [0,1,2,3,4,5,6]\n",
    "        )\n",
    "        .astype('int64')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def dataframe_to_tensors(df: pd.DataFrame) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Konwertuje DataFrame do tensorów kategorii i wartości ciągłych.\"\"\"\n",
    "    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "    cont_cols = [\n",
    "        'pickup_latitude', 'pickup_longitude',\n",
    "        'dropoff_latitude', 'dropoff_longitude',\n",
    "        'passenger_count', 'dist_km'\n",
    "    ]\n",
    "\n",
    "    xcats = torch.tensor(\n",
    "        np.stack([df[col].values for col in cat_cols], 1),\n",
    "        dtype=torch.int64\n",
    "    )\n",
    "    xconts = torch.tensor(\n",
    "        np.stack([df[col].values for col in cont_cols], 1),\n",
    "        dtype=torch.float\n",
    "    )\n",
    "    return xcats, xconts\n",
    "\n",
    "\n",
    "def prepare_features(\n",
    "    plat: float, plong: float,\n",
    "    dlat: float, dlong: float,\n",
    "    psngr: int, dt: str\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Przygotowuje cechy wejściowe (kategoryczne i ciągłe) \n",
    "    na podstawie podanych parametrów.\n",
    "    \"\"\"\n",
    "    df = build_dataframe(plat, plong, dlat, dlong, psngr, dt)\n",
    "    df = add_distance_feature(df)\n",
    "    df = add_datetime_features(df)\n",
    "    return dataframe_to_tensors(df)\n",
    "\n",
    "\n",
    "def predict_fare(\n",
    "    model,\n",
    "    plat: float, plong: float,\n",
    "    dlat: float, dlong: float,\n",
    "    psngr: int, dt: str\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Zwraca przewidywaną opłatę za kurs taksówką na podstawie modelu i parametrów wejściowych.\n",
    "    \"\"\"\n",
    "    xcats, xconts = prepare_features(plat, plong, dlat, dlong, psngr, dt)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(xcats, xconts)\n",
    "\n",
    "    return prediction.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przepuść nowe dane przez wytrenowany model\n",
    "\n",
    "Dla wygody poniżej znajdziesz wartości minimalne i maksymalne każdej zmiennej:\n",
    "\n",
    "| Kolumna           | Minimum               | Maksimum             |\n",
    "|-------------------|-----------------------|----------------------|\n",
    "| pickup_latitude   | 40                    | 41                   |\n",
    "| pickup_longitude  | -74.5                 | -73.3                |\n",
    "| dropoff_latitude  | 40                    | 41                   |\n",
    "| dropoff_longitude | -74.5                 | -73.3                |\n",
    "| passenger_count   | 1                     | 5                    |\n",
    "| EDTdate           | 2010-04-11 00:00:00   | 2010-04-24 23:59:42  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted fare amount is $192.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/6wst9f1n1g96lc__ld426szh0000gn/T/ipykernel_84035/566468548.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(\n"
     ]
    }
   ],
   "source": [
    "fare = predict_fare(\n",
    "    model2,\n",
    "    plat=40.0,\n",
    "    plong=-74.5,\n",
    "    dlat=41,\n",
    "    dlong=-73.3,\n",
    "    psngr=1,\n",
    "    dt=\"2010-04-12 08:24:00\"\n",
    ")\n",
    "print(f\"The predicted fare amount is ${fare:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Zachowaj ostrożność!</strong> Odległość odpowiadająca 1 stopniowi szerokości geograficznej (od 40 do 41) to 111 km (69 mil), a 1 stopniowi długości (od -73 do -74) – 85 km (53 mile). \n",
    "\n",
    "Najdłuższy kurs w zbiorze różnił się zaledwie o 0.243 stopnia szerokości i 0.284 stopnia długości. \n",
    "\n",
    "Średnia różnica dla obu wynosi ok. 0.02. \n",
    "\n",
    "Aby otrzymać wiarygodne prognozy, korzystaj z wartości położonych blisko siebie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zróbmy to jeszcze w TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogiczny model w TensorFlow/Keras\n",
    "\n",
    "Poniższa sekcja odtwarza sieć tablicową w Keras, korzystając z tych samych cech kategorycznych i ciągłych oraz analogicznej architektury (embeddingi + MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cats[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Ustawiamy ziarno losowe (seed), żeby wyniki były powtarzalne\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Konwersja danych wejściowych z tensora PyTorch/TF na numpy arrays \n",
    "# i rzutowanie na odpowiednie typy (int32 dla kategorii, float32 dla liczb zmiennoprzecinkowych).\n",
    "# Dzięki temu model w Kerasie dostaje dane w formacie, którego oczekuje.\n",
    "cat_train_np = cat_train.numpy().astype('int32')\n",
    "cat_test_np = cat_test.numpy().astype('int32')\n",
    "con_train_np = con_train.numpy().astype('float32')\n",
    "con_test_np = con_test.numpy().astype('float32')\n",
    "y_train_np = y_train.numpy().astype('float32')\n",
    "y_test_np = y_test.numpy().astype('float32')\n",
    "\n",
    "# Przygotowanie słownika wejść dla modelu:\n",
    "# - każdy atrybut kategoryczny dostaje osobny \"wektor kolumnowy\"\n",
    "# - dane ciągłe grupujemy razem w jednej macierzy pod kluczem 'cont'\n",
    "train_inputs = {f'cat_{i}': cat_train_np[:, i:i+1] for i in range(cat_train_np.shape[1])}\n",
    "test_inputs = {f'cat_{i}': cat_test_np[:, i:i+1] for i in range(cat_test_np.shape[1])}\n",
    "train_inputs['cont'] = con_train_np\n",
    "test_inputs['cont'] = con_test_np\n",
    "\n",
    "# Informacyjnie wypisujemy wersję TensorFlow (pomocne przy debugowaniu i odtwarzaniu wyników)\n",
    "print(f'TensorFlow version: {tf.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_cat = []     # lista wejść dla zmiennych kategorycznych\n",
    "embeddings = []     # lista embeddingów odpowiadających tym wejściom\n",
    "\n",
    "# Tworzymy osobne wejście i warstwę embedding dla każdej cechy kategorycznej\n",
    "for idx, (cardinality, emb_dim) in enumerate(emb_szs):\n",
    "    # Wejście (pojedyncza liczba całkowita reprezentująca kategorię)\n",
    "    input_layer = keras.Input(shape=(1,), name=f'cat_{idx}')\n",
    "    \n",
    "    # Warstwa embedding: zamiana indeksu kategorii na gęsty wektor o wymiarze emb_dim\n",
    "    embed = keras.layers.Embedding(cardinality, emb_dim, name=f'emb_{idx}')(input_layer)\n",
    "    \n",
    "    # Reshape: spłaszczenie (bo Embedding zwraca kształt (batch, 1, emb_dim))\n",
    "    embed = keras.layers.Reshape((emb_dim,), name=f'emb_{idx}_reshape')(embed)\n",
    "    \n",
    "    # Zbieramy do list\n",
    "    embeddings.append(embed)\n",
    "    inputs_cat.append(input_layer)\n",
    "\n",
    "embeddings, inputs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# łączymy je w jeden wektor cech\n",
    "cat_features = keras.layers.Concatenate(name='cats_concat')(embeddings)\n",
    "\n",
    "\n",
    "# Dropout dla embeddingów — redukuje przeuczenie\n",
    "cat_features = keras.layers.Dropout(0.4, name='cats_dropout')(cat_features)\n",
    "\n",
    "# Wejście dla zmiennych ciągłych\n",
    "cont_input = keras.Input(shape=(con_train_np.shape[1],), name='cont')\n",
    "\n",
    "# BatchNormalization — normalizacja danych ciągłych (przyspiesza uczenie)\n",
    "cont_features = keras.layers.BatchNormalization(name='cont_bn')(cont_input)\n",
    "\n",
    "# Połączenie cech kategorycznych i ciągłych w jeden wektor\n",
    "x = keras.layers.Concatenate(name='features_concat')([cat_features, cont_features])\n",
    "\n",
    "# Klasyczne gęste warstwy ukryte (MLP)\n",
    "for i, units in enumerate([200, 100]):\n",
    "    # Gęsta warstwa w pełni połączona z ReLU\n",
    "    x = keras.layers.Dense(units, activation='relu', name=f'dense_{i}')(x)\n",
    "    # Normalizacja batchowa stabilizuje rozkład aktywacji\n",
    "    x = keras.layers.BatchNormalization(name=f'bn_{i}')(x)\n",
    "    # Dropout dla redukcji przeuczenia\n",
    "    x = keras.layers.Dropout(0.4, name=f'dropout_{i}')(x)\n",
    "\n",
    "# Warstwa wyjściowa — 1 neuron (predykcja ceny przejazdu)\n",
    "output = keras.layers.Dense(1, name='fare')(x)\n",
    "\n",
    "# Składamy cały model — wejścia to embeddingi + cechy ciągłe\n",
    "tf_model = keras.Model(inputs=inputs_cat + [cont_input], outputs=output, name='taxi_fare_model_tf')\n",
    "\n",
    "# Kompilacja modelu:\n",
    "# - optimizer Adam (0.001)\n",
    "# - funkcja straty: MSE (błąd średniokwadratowy)\n",
    "# - metryka: RMSE (bardziej interpretowalna w jednostkach ceny)\n",
    "tf_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.001),\n",
    "    loss='mse',\n",
    "    metrics=[keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    ")\n",
    "\n",
    "# Podsumowanie modelu (lista warstw, parametry, kształty)\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback: EarlyStopping\n",
    "# Monitorujemy walidacyjną metrykę RMSE (val_rmse).\n",
    "# Jeśli przez 20 epok nie będzie poprawy, zatrzymujemy trening.\n",
    "# restore_best_weights=True oznacza, że model przywróci najlepsze wagi z okresu treningu.\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_rmse',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Trening modelu:\n",
    "# - dane treningowe (wejścia + etykiety)\n",
    "# - walidacja na zbiorze testowym\n",
    "# - max 200 epok, batch_size=512\n",
    "# - verbose=0, czyli bez spamowania logami\n",
    "# - EarlyStopping, żeby nie przeuczać modelu\n",
    "history = tf_model.fit(\n",
    "    train_inputs,\n",
    "    y_train_np,\n",
    "    validation_data=(test_inputs, y_test_np),\n",
    "    epochs=200,\n",
    "    batch_size=512,\n",
    "    verbose=0,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Historia treningu (loss + metryki) do DataFrame dla wygodnego przeglądania\n",
    "history_df = pd.DataFrame(history.history)\n",
    "print(history_df[['rmse', 'val_rmse']].tail())\n",
    "\n",
    "# Ewaluacja na danych testowych — obliczamy stratę i RMSE\n",
    "test_loss, test_rmse = tf_model.evaluate(test_inputs, y_test_np, verbose=0)\n",
    "print(f'Test RMSE: {test_rmse:.4f}')\n",
    "\n",
    "# Predykcje na zbiorze testowym\n",
    "preds = tf_model.predict(test_inputs, verbose=0).flatten()\n",
    "actuals = y_test_np.flatten()\n",
    "\n",
    "# Porównanie: przewidywane vs rzeczywiste wartości (pierwsze 10 przypadków)\n",
    "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
    "for i in range(10):\n",
    "    diff = abs(preds[i] - actuals[i])  # różnica absolutna\n",
    "    print(f'{i+1:2}. {preds[i]:8.4f} {actuals[i]:8.4f} {diff:8.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_fare_keras(model, plat, plong, dlat, dlong, psngr, dt):\n",
    "    xcats, xconts = prepare_features(plat, plong, dlat, dlong, psngr, dt)\n",
    "    keras_inputs = {f'cat_{i}': xcats.numpy()[:, i:i+1].astype('int32') for i in range(xcats.shape[1])}\n",
    "    keras_inputs['cont'] = xconts.numpy().astype('float32')\n",
    "    prediction = model.predict(keras_inputs, verbose=0)\n",
    "    return float(prediction.squeeze())\n",
    "\n",
    "fare_tf = predict_fare_keras(\n",
    "    tf_model,\n",
    "    plat=40.0,\n",
    "    plong=-74.5,\n",
    "    dlat=41,\n",
    "    dlong=-73.3,\n",
    "    psngr=1,\n",
    "    dt=\"2010-04-12 08:24:00\"\n",
    ")\n",
    "print(f\"TensorFlow prognoza opłaty: ${fare_tf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uwaga - w przykladzie PyTorch nie byo early stoppingu. Trzeba by go implementowac ręcznie w petli uczenia\n",
    "\n",
    "Coś w ten deseń:\n",
    "\n",
    "\n",
    "```python\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_one_epoch(...)   # trening na batchach\n",
    "    val_loss = evaluate_on_validation(...)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "# przywracamy najlepsze wagi\n",
    "model.load_state_dict(best_model_wts)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
