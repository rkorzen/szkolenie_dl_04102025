{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kompletny przyk≈Çad sztucznej sieci neuronowej\n",
    "\n",
    "W poprzedniej sekcji korzystali≈õmy z czterech zmiennych ciƒÖg≈Çych (d≈Çugo≈õci), aby przeprowadziƒá klasyfikacjƒô. Teraz po≈ÇƒÖczymy dane ciƒÖg≈Çe i kategoryczne, by wykonaƒá regresjƒô. Celem jest oszacowanie kosztu przejazdu taks√≥wkƒÖ w Nowym Jorku na podstawie kilku zmiennych wej≈õciowych. InspiracjƒÖ do tego ƒáwiczenia jest ostatni [konkurs na Kaggle](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction).\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "**UWAGA:**  \n",
    "W tym notatniku przeprowadzimy regresjƒô z pojedynczƒÖ warto≈õciƒÖ wyj≈õciowƒÖ. W kolejnym wykonamy klasyfikacjƒô binarnƒÖ z dwiema warto≈õciami wyj≈õciowymi.\n",
    "\n",
    "</div>\n",
    "\n",
    "## Praca z danymi tabelarycznymi\n",
    "\n",
    "Uczenie g≈Çƒôbokie z sieciami neuronowymi czƒôsto kojarzy siƒô z zaawansowanym rozpoznawaniem obraz√≥w. W kolejnych rozdzia≈Çach bƒôdziemy trenowaƒá modele analizujƒÖce piksele, wzorce i kolory.\n",
    "\n",
    "Tym razem pracujemy z danymi tabelarycznymi (arkusze kalkulacyjne, tabele SQL itp.), w kt√≥rych kolumny mogƒÖ, ale nie muszƒÖ byƒá istotne. Sieci neuronowe potrafiƒÖ odkrywaƒá zale≈ºno≈õci, na kt√≥re sami by≈õmy nie wpadli. \n",
    "\n",
    "Aby to jednak umo≈ºliwiƒá, musimy traktowaƒá zmienne kategoryczne inaczej ni≈º ciƒÖg≈Çe.\n",
    "\n",
    "Na poczƒÖtku musimy przyjrzeƒá siƒô tym zagadnieniom by wykorzystaƒá tƒô wiedze dalej:\n",
    "\n",
    "\n",
    "* warto≈õci ciƒÖg≈Çe vs. kategoryczne  \n",
    "* embeddings  \n",
    "* batch normalization  \n",
    "* warstwy dropout  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykonaj standardowe importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:43.426865Z",
     "start_time": "2025-09-24T20:17:41.981833Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytaj zbi√≥r NYC Taxi Fares\n",
    "\n",
    "[Konkurs Kaggle](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction) udostƒôpnia zbi√≥r oko≈Ço 55 milion√≥w rekord√≥w. Dane obejmujƒÖ wy≈ÇƒÖcznie datƒô i godzinƒô rozpoczƒôcia kursu, wsp√≥≈Çrzƒôdne GPS miejsca startu i zako≈Ñczenia oraz liczbƒô pasa≈ºer√≥w. To uczestnik konkursu decyduje, jakie dodatkowe informacje wydobyƒá. Czy pora dnia ma znaczenie? Dzie≈Ñ tygodnia? Jak wyliczyƒá odleg≈Ço≈õƒá na podstawie par wsp√≥≈Çrzƒôdnych GPS?  \n",
    "\n",
    "Na potrzeby ƒáwiczenia ograniczyli≈õmy zbi√≥r do **120 000 rekord√≥w** z okresu 11‚Äì24 kwietnia 2010 r. Rekordy sƒÖ losowo posortowane. \n",
    "\n",
    "Poka≈ºemy, jak obliczyƒá odleg≈Ço≈õƒá ze wsp√≥≈Çrzƒôdnych GPS oraz jak stworzyƒá obiekt `datetime` z kolumny tekstowej. Dziƒôki temu szybko uzyskamy informacje takie jak dzie≈Ñ tygodnia, podzia≈Ç na AM/PM itd.  \n",
    "\n",
    "Zaczynajmy!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:45.834863Z",
     "start_time": "2025-09-24T20:17:45.711085Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/NYCTaxiFares.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:46.979977Z",
     "start_time": "2025-09-24T20:17:46.970742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120000.000000\n",
       "mean         10.040326\n",
       "std           7.500134\n",
       "min           2.500000\n",
       "25%           5.700000\n",
       "50%           7.700000\n",
       "75%          11.300000\n",
       "max          49.900000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy, ≈ºe ceny wahajƒÖ siƒô od `$2.50` do `$49.90`, ≈õrednia wynosi `$10.04`, a mediana `\\$7.70`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oblicz przejechanƒÖ odleg≈Ço≈õƒá\n",
    "\n",
    "[Wz√≥r haversine](https://en.wikipedia.org/wiki/Haversine_formula) wyznacza odleg≈Ço≈õƒá na kuli pomiƒôdzy dwiema parami wsp√≥≈Çrzƒôdnych GPS.  \n",
    "\n",
    "Szeroko≈õƒá geograficznƒÖ oznaczymy przez $\\varphi$ (phi), a d≈Çugo≈õƒá przez $\\lambda$ (lambda).\n",
    "\n",
    "Wz√≥r przyjmuje postaƒá:\n",
    "\n",
    "$$\n",
    "d = 2r \\arcsin \\left( \n",
    "    \\sqrt{ \n",
    "        \\sin^2\\!\\left(\\frac{\\varphi_2 - \\varphi_1}{2}\\right) \n",
    "        + \\cos(\\varphi_1)\\cos(\\varphi_2)\\sin^2\\!\\left(\\frac{\\lambda_2 - \\lambda_1}{2}\\right) \n",
    "    } \n",
    "\\right)\n",
    "$$\n",
    "\n",
    "przy czym:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "r & : \\text{ promie≈Ñ kuli (≈õredni promie≈Ñ Ziemi to 6371 km)} \\\\\n",
    "\\varphi_1, \\varphi_2 & : \\text{ szeroko≈õci geograficzne punkt√≥w 1 i 2} \\\\\n",
    "\\lambda_1, \\lambda_2 & : \\text{ d≈Çugo≈õci geograficzne punkt√≥w 1 i 2} \\\\\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:50.425594Z",
     "start_time": "2025-09-24T20:17:50.422943Z"
    }
   },
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # ≈õredni promie≈Ñ Ziemi w kilometrach\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # w kilometrach\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zastosujmy tƒô funkcjƒô do stworzenia nowej kolumny:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:51.903127Z",
     "start_time": "2025-09-24T20:17:51.893907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km  \n",
       "0  2.126312  \n",
       "1  1.392307  \n",
       "2  3.326763  \n",
       "3  1.864129  \n",
       "4  7.231321  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dist_km'] = haversine_distance(df,'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodaj kolumnƒô datetime i wyprowad≈∫ przydatne statystyki\n",
    "\n",
    "TworzƒÖc obiekt `datetime`, mo≈ºemy wydobyƒá takie informacje jak ‚Äûdzie≈Ñ tygodnia‚Äù czy ‚Äûprzed po≈Çudniem / po po≈Çudniu‚Äù.  \n",
    "Zwr√≥ƒá uwagƒô, ≈ºe dane zapisano w czasie **UTC**. Nasz zakres obejmuje kwiecie≈Ñ 2010 r., czyli okres obowiƒÖzywania czasu letniego w Nowym Jorku.  \n",
    "\n",
    "Dlatego przeliczymy czas na **EDT**, odejmujƒÖc cztery godziny (UTC-4).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:54.479729Z",
     "start_time": "2025-09-24T20:17:54.222033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "      <th>EDTdate</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AMorPM</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>2010-04-19 04:17:56</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>2010-04-17 11:43:53</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>2010-04-17 07:23:26</td>\n",
       "      <td>7</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>2010-04-11 17:25:03</td>\n",
       "      <td>17</td>\n",
       "      <td>pm</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "      <td>2010-04-16 22:19:01</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km             EDTdate  Hour AMorPM Weekday  \n",
       "0  2.126312 2010-04-19 04:17:56     4     am     Mon  \n",
       "1  1.392307 2010-04-17 11:43:53    11     am     Sat  \n",
       "2  3.326763 2010-04-17 07:23:26     7     am     Sat  \n",
       "3  1.864129 2010-04-11 17:25:03    17     pm     Sun  \n",
       "4  7.231321 2010-04-16 22:19:01    22     pm     Fri  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)\n",
    "df['Hour'] = df['EDTdate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour']<12,'am','pm')\n",
    "df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:55.716068Z",
     "start_time": "2025-09-24T20:17:55.712855Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-04-11 00:00:10')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:17:56.877014Z",
     "start_time": "2025-09-24T20:17:56.874605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-04-24 23:59:42')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oddziel kolumny kategoryczne od ciƒÖg≈Çych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:00.979481Z",
     "start_time": "2025-09-24T20:18:00.976742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'dist_km', 'EDTdate', 'Hour', 'AMorPM', 'Weekday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:02.988549Z",
     "start_time": "2025-09-24T20:18:02.986693Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "y_col = ['fare_amount']  # ta kolumna zawiera etykiety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**UWAGA:**  \n",
    "Je≈õli planujesz wykorzystaƒá wszystkie kolumny z tabeli, mo≈ºesz w prosty spos√≥b pobraƒá pozosta≈Çe kolumny ciƒÖg≈Çe:\n",
    "\n",
    "```python\n",
    "cont_cols = [col for col in df.columns if col not in cat_cols + y_col]\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zamiana na typ category\n",
    "\n",
    "Pandas udostƒôpnia typ danych [**category**](https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html), \n",
    "kt√≥ry zamienia warto≈õci kategoryczne na kody liczbowe.  \n",
    "\n",
    "Zbi√≥r zawierajƒÖcy miesiƒÖce roku otrzyma 12 kod√≥w, po jednym na ka≈ºdy miesiƒÖc (zwykle od 0 do 11).  \n",
    "Pandas zastƒôpuje warto≈õci w kolumnie kodami i przechowuje listƒô kategorii.  \n",
    "\n",
    "W kolejnych krokach bƒôdziemy odwo≈Çywaƒá siƒô do ‚Äûnazw‚Äù kategorii i przypisanych im ‚Äûkod√≥w‚Äù.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:19.625653Z",
     "start_time": "2025-09-24T20:18:19.583713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zamie≈Ñ trzy kolumny kategoryczne na typ category.\n",
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:20.617148Z",
     "start_time": "2025-09-24T20:18:20.612202Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime              object\n",
       "fare_amount                 float64\n",
       "fare_class                    int64\n",
       "pickup_longitude            float64\n",
       "pickup_latitude             float64\n",
       "dropoff_longitude           float64\n",
       "dropoff_latitude            float64\n",
       "passenger_count               int64\n",
       "dist_km                     float64\n",
       "EDTdate              datetime64[ns]\n",
       "Hour                       category\n",
       "AMorPM                     category\n",
       "Weekday                    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mo≈ºemy sprawdziƒá, ≈ºe `df['Hour']` to cecha kategoryczna, wy≈õwietlajƒÖc kilka wierszy:\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:36.743533Z",
     "start_time": "2025-09-24T20:18:36.740786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    11\n",
       "2     7\n",
       "3    17\n",
       "4    22\n",
       "Name: Hour, dtype: category\n",
       "Categories (24, int32): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widzimy, ≈ºe nazwami kategorii sƒÖ tutaj liczby ca≈Çkowite od 0 do 23, czyli 24 unikalne warto≈õci.  \n",
    "Te liczby *r√≥wnie≈º* odpowiadajƒÖ kodom nadanym ka≈ºdej nazwie.  \n",
    "\n",
    "Do nazw kategorii odwo≈Çujemy siƒô przez `Series.cat.categories`,  \n",
    "a do samych kod√≥w przez `Series.cat.codes`.  \n",
    "\n",
    "≈Åatwiej to zrozumieƒá na przyk≈Çadzie `df['AMorPM']`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:54.294917Z",
     "start_time": "2025-09-24T20:18:54.289742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    am\n",
       "1    am\n",
       "2    am\n",
       "3    pm\n",
       "4    pm\n",
       "Name: AMorPM, dtype: category\n",
       "Categories (2, object): ['am', 'pm']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:55.509077Z",
     "start_time": "2025-09-24T20:18:55.505691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['am', 'pm'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:56.492350Z",
     "start_time": "2025-09-24T20:18:56.486048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "dtype: int8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head().cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:18:59.402117Z",
     "start_time": "2025-09-24T20:18:59.398906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Fri', 'Mon', 'Sat', 'Sun', 'Thu', 'Tue', 'Wed'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:00.477241Z",
     "start_time": "2025-09-24T20:19:00.474161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    2\n",
       "3    3\n",
       "4    0\n",
       "dtype: int8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Weekday'].head().cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**UWAGA:**  \n",
    "W danych kategorycznych warto≈õci `NaN` otrzymujƒÖ kod `-1`.  \n",
    "W tym zbiorze takich warto≈õci nie ma.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz chcemy po≈ÇƒÖczyƒá trzy kolumny kategoryczne w jednƒÖ tablicƒô wej≈õciowƒÖ przy u≈ºyciu <a href='https://docs.scipy.org/doc/numpy/reference/generated/numpy.stack.html'><tt>numpy.stack</tt></a>. InteresujƒÖ nas wy≈ÇƒÖcznie warto≈õci, bez indeksu Series.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:19.361739Z",
     "start_time": "2025-09-24T20:19:19.317963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1],\n",
       "       [11,  0,  2],\n",
       "       [ 7,  0,  2],\n",
       "       [17,  1,  3],\n",
       "       [22,  1,  0]], dtype=int8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr = df['Hour'].cat.codes.values\n",
    "ampm = df['AMorPM'].cat.codes.values\n",
    "wkdy = df['Weekday'].cat.codes.values\n",
    "\n",
    "cats = np.stack([hr, ampm, wkdy], 1)\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**UWAGA:**  \n",
    "Mo≈ºna to zrobiƒá w jednej linii z u≈ºyciem list comprehension:\n",
    "\n",
    "```python\n",
    "cats = np.stack([df[col].cat.codes.values for col in cat_cols], 1)\n",
    "```\n",
    "\n",
    "Nie przejmujemy siƒô na razie typem danych ‚Äì ustawimy int64, gdy bƒôdziemy tworzyƒá tensor.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konwersja tablic NumPy na tensory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:33.611802Z",
     "start_time": "2025-09-24T20:19:33.559387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3],\n",
       "        [22,  1,  0]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Przekonwertuj zmienne kategoryczne na tensor\n",
    "cats = torch.tensor(cats, dtype=torch.int64) \n",
    "# ta sk≈Çadnia jest w porzƒÖdku, poniewa≈º dane ≈∫r√≥d≈Çowe to tablica, a nie istniejƒÖcy tensor\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Mo≈ºemy przekazaƒá wszystkie zmienne ciƒÖg≈Çe do modelu jako tensor.  \n",
    "Zauwa≈º, ≈ºe nie normalizujemy ich teraz ‚Äì pozwolimy zrobiƒá to modelowi.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**UWAGA:**  \n",
    "Aby batch normalization dzia≈Ça≈Ç poprawnie, najlepiej zapisywaƒá dane wej≈õciowe (`conts`) w typie **Float** (`float32`), a nie **Double** (`float64`).  \n",
    "\n",
    "BatchNorm w PyTorchu i TensorFlow potrafi dzia≈Çaƒá tak≈ºe na `float64` czy `float16`, o ile wszystkie wej≈õcia i parametry majƒÖ ten sam typ.  \n",
    "W praktyce jednak niemal zawsze stosuje siƒô `float32`, poniewa≈º:  \n",
    "\n",
    "- jest to standardowy typ dla CPU i GPU,  \n",
    "- zapewnia lepszƒÖ wydajno≈õƒá i mniejsze zu≈ºycie pamiƒôci ni≈º `float64`,  \n",
    "- wiƒôkszo≈õƒá warstw i optymalizator√≥w jest testowana w≈Ça≈õnie na `float32`.  \n",
    "\n",
    "`float64` dzia≈Ça wolniej i rzadko daje korzy≈õci w uczeniu modeli.  \n",
    "\n",
    "**WyjƒÖtki ‚Äì typ zmiennej docelowej `y`:**  \n",
    "- w **klasyfikacji wieloklasowej** (`nn.CrossEntropyLoss`) `y` powinna byƒá typu `LongTensor` z **indeksami klas** (np. `[0, 2, 1]`),  \n",
    "  poniewa≈º `CrossEntropyLoss` sam stosuje *softmax* i por√≥wnuje logity modelu z numerem poprawnej klasy.  \n",
    "- w **regresji** `y` zwykle jest `float32`.  \n",
    "\n",
    "üëâ **Podsumowanie:**  \n",
    "- Dane ciƒÖg≈Çe (`conts`) ‚Üí `float32`  \n",
    "- Zmienna docelowa (`y`) ‚Üí zale≈ºy od zadania:  \n",
    "  - klasyfikacja ‚Üí `long` (indeksy klas)  \n",
    "  - regresja ‚Üí `float32`\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:43.324264Z",
     "start_time": "2025-09-24T20:19:43.295467Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   1.0000,   2.1263],\n",
       "        [ 40.7406, -73.9901,  40.7441, -73.9742,   1.0000,   1.3923],\n",
       "        [ 40.7511, -73.9941,  40.7662, -73.9601,   2.0000,   3.3268],\n",
       "        [ 40.7564, -73.9905,  40.7482, -73.9712,   1.0000,   1.8641],\n",
       "        [ 40.7342, -73.9910,  40.7431, -73.9060,   1.0000,   7.2313]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Przekonwertuj zmienne ciƒÖg≈Çe na tensor\n",
    "conts = np.stack([df[col].values for col in cont_cols], 1)\n",
    "conts = torch.tensor(conts, dtype=torch.float)\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:47.266476Z",
     "start_time": "2025-09-24T20:19:47.263457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:49.544854Z",
     "start_time": "2025-09-24T20:19:49.538436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.5000],\n",
       "        [ 6.9000],\n",
       "        [10.1000],\n",
       "        [ 8.9000],\n",
       "        [19.7000]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Przekonwertuj etykiety na tensor\n",
    "y = torch.tensor(df[y_col].values, dtype=torch.float).reshape(-1,1)\n",
    "\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:51.096527Z",
     "start_time": "2025-09-24T20:19:51.093479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:19:56.748749Z",
     "start_time": "2025-09-24T20:19:56.744205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:20:04.234068Z",
     "start_time": "2025-09-24T20:20:04.231836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ustal rozmiary embedding√≥w\n",
    "\n",
    "- [Dokumentacja PyTorch ‚Äì nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)  \n",
    "- [Dyskusja na Quora: What does PyTorch Embedding do?](https://www.quora.com/What-does-PyTorch-Embedding-do)\n",
    "\n",
    "**Embedding** to spos√≥b reprezentowania warto≈õci kategorycznych jako gƒôstych wektor√≥w liczb zmiennoprzecinkowych.  \n",
    "Zamiast korzystaƒá z **one-hot encoding** (gdzie ka≈ºdy unikalny element dostaje bardzo d≈Çugi wektor pe≈Çen zer), embedding przypisuje ka≈ºdej kategorii kr√≥tki wektor o ustalonej liczbie wymiar√≥w.  \n",
    "\n",
    "Na przyk≈Çad:  \n",
    "- mamy kolumnƒô `day_of_week` z warto≈õciami od 0 do 6,  \n",
    "- zamiast zamieniaƒá to na 7 kolumn zero-jedynkowych, mo≈ºemy ka≈ºdej kategorii przypisaƒá wektor, np. 3-wymiarowy:  \n",
    "```\n",
    "\n",
    "Monday    ‚Üí [ 0.1,  0.8, -0.3]\n",
    "Tuesday   ‚Üí [-0.5,  0.2,  0.7]\n",
    "...\n",
    "Sunday    ‚Üí [ 0.3, -0.6,  0.1]\n",
    "\n",
    "```\n",
    "- Wektory embedding√≥w sƒÖ **uczone w trakcie trenowania modelu**, wiƒôc sieƒá sama dobiera ich warto≈õci, tak aby najlepiej reprezentowa≈Çy informacjƒô.\n",
    "\n",
    "---\n",
    "\n",
    "### Jak dobraƒá rozmiar embeddingu?\n",
    "\n",
    "Nie istnieje ≈õcis≈Ça regu≈Ça matematyczna, ale w praktyce stosuje siƒô proste heurystyki:\n",
    "\n",
    "- **Czƒôsta zasada**:  \n",
    "Rozmiar embeddingu ‚âà liczba unikalnych kategorii √∑ 2  \n",
    "\n",
    "- **Ograniczenie g√≥rne**:  \n",
    "Zwykle nie ma sensu przekraczaƒá ~50 wymiar√≥w (dla wiƒôkszo≈õci klasycznych problem√≥w tablicowych).  \n",
    "\n",
    "- **Przyk≈Çady**:  \n",
    "| Kolumna                  | Liczba unikalnych warto≈õci | Rozmiar embeddingu |\n",
    "|---------------------------|-----------------------------|---------------------|\n",
    "| `day_of_week` (dni tygodnia) | 7                           | 3‚Äì4                 |\n",
    "| `month` (miesiƒÖce roku)      | 12                          | 6                   |\n",
    "| `zipcode` (kody pocztowe)    | 200                         | 50 (g√≥rny limit)    |\n",
    "| `user_id` (du≈ºy zbi√≥r ID)    | 10 000                      | 50 (g√≥rny limit)    |\n",
    "\n",
    "---\n",
    "\n",
    "### Dlaczego embeddingi sƒÖ lepsze ni≈º one-hot?\n",
    "\n",
    "- **Kompaktowo≈õƒá** ‚Äì du≈ºo mniejszy wymiar wej≈õciowy,  \n",
    "- **Uczenie zale≈ºno≈õci** ‚Äì sieƒá sama odkrywa, kt√≥re kategorie sƒÖ do siebie podobne,  \n",
    "- **Wydajno≈õƒá** ‚Äì mniej pamiƒôci, szybsze trenowanie.  \n",
    "\n",
    "üëâ Dziƒôki embeddingom model mo≈ºe np. nauczyƒá siƒô, ≈ºe ‚Äûsobota‚Äù i ‚Äûniedziela‚Äù majƒÖ podobny wp≈Çyw na wynik, mimo ≈ºe w indeksach sƒÖ odleg≈Çe.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:20:16.208969Z",
     "start_time": "2025-09-24T20:20:16.206122Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ustawi to rozmiary embedding√≥w dla Hours, AMvsPM i Weekdays\n",
    "\n",
    "# cat_szs = lista liczby unikalnych kategorii dla ka≈ºdej kolumny kategorycznej\n",
    "# np. Hours ma 24 warto≈õci (0‚Äì23), AMvsPM ma 2 warto≈õci, Weekdays ma 7 warto≈õci\n",
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "\n",
    "# emb_szs = lista krotek (num_categories, embedding_dim)\n",
    "# embedding_dim = po≈Çowa liczby kategorii, zaokrƒÖglona w g√≥rƒô, ale maksymalnie 50\n",
    "# czyli stosujemy regu≈Çƒô: min(50, (N+1)//2)\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "\n",
    "# emb_szs bƒôdzie np. [(24, 12), (2, 1), (7, 4)]\n",
    "emb_szs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Hours` ‚Üí embedding o wymiarze 12\n",
    "* `AMvsPM` ‚Üí embedding o wymiarze 1\n",
    "* `Weekdays` ‚Üí embedding o wymiarze 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**üí° Ciekawostka: fastai**\n",
    "\n",
    "Istnieje biblioteka **[fastai](https://docs.fast.ai/)** ‚Äì mo≈ºna powiedzieƒá, ≈ºe to taki *Keras dla PyTorcha*.  \n",
    "Powsta≈Ça, aby **u≈Çatwiƒá i przyspieszyƒá** trenowanie modeli deep learning, korzystajƒÖc z najlepszych praktyk.\n",
    "\n",
    "- dzia≈Ça na bazie **PyTorcha**, ale zapewnia **wy≈ºszy poziom abstrakcji**,\n",
    "- ma gotowe modu≈Çy do pracy z r√≥≈ºnymi typami danych: obrazy, tekst, dane tabelaryczne, rekomendacje,\n",
    "- pozwala w kilku liniach stworzyƒá model i go wytrenowaƒá,\n",
    "- jednocze≈õnie daje dostƒôp do ‚Äûczystego‚Äù PyTorcha, gdy potrzebujesz pe≈Çnej kontroli.\n",
    "\n",
    "üëâ Mo≈ºna wiƒôc powiedzieƒá, ≈ºe **fastai = PyTorch dla praktyk√≥w** ‚Äì szybki start, proste API, ale mo≈ºliwo≈õƒá zej≈õcia g≈Çƒôbiej.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicja TabularModel\n",
    "\n",
    "To podej≈õcie czƒô≈õciowo nawiƒÖzuje do [biblioteki fast.ai](https://docs.fast.ai/tabular.model.html).  \n",
    "\n",
    "Celem jest zbudowanie modelu, kt√≥ry uwzglƒôdnia:\n",
    "\n",
    "- liczbƒô kolumn ciƒÖg≈Çych (podanƒÖ przez `conts.shape[1]`),  \n",
    "- liczbƒô kolumn kategorycznych i odpowiadajƒÖce im embeddingi (podane przez `len(emb_szs)` oraz samƒÖ listƒô `emb_szs`).  \n",
    "\n",
    "Wyj≈õciem modelu mo≈ºe byƒá:  \n",
    "\n",
    "- **regresja** ‚Äì pojedyncza warto≈õƒá zmiennoprzecinkowa,  \n",
    "- **klasyfikacja** ‚Äì rozk≈Çad prawdopodobie≈Ñstwa po klasach (np. warto≈õci po softmax).  \n",
    "\n",
    "W tym ƒáwiczeniu naszym celem bƒôdzie **pojedyncza warto≈õƒá regresyjna**.  \n",
    "\n",
    "Zak≈Çadamy, ≈ºe dane zawierajƒÖ zar√≥wno zmienne kategoryczne, jak i ciƒÖg≈Çe.  \n",
    "\n",
    "Do w≈Çasnej klasy modelu mo≈ºna dodaƒá parametry logiczne (np. `use_cats`, `use_conts`), aby obs≈Çu≈ºyƒá r√≥≈ºne warianty zbior√≥w danych.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krok po kroku ‚Äì co robi TabularModel?\n",
    "\n",
    "### 1. Definiujemy parametry klasy\n",
    "\n",
    "* `emb_szs`: lista krotek z liczbƒÖ kategorii i rozmiarem embeddingu\n",
    "* `n_cont`: liczba zmiennych ciƒÖg≈Çych\n",
    "* `out_sz`: rozmiar wyj≈õcia\n",
    "* `layers`: lista rozmiar√≥w kolejnych warstw ukrytych\n",
    "* `p`: warto≈õƒá dropout dla ka≈ºdej warstwy\n",
    "\n",
    "```python\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Tworzymy warstwy embedding√≥w\n",
    "\n",
    "U≈ºywamy [`torch.nn.ModuleList()`](https://pytorch.org/docs/stable/nn.html#modulelist) i [`torch.nn.Embedding()`](https://pytorch.org/docs/stable/nn.html#embedding). Dane kategoryczne przechodzƒÖ przez te embeddingi w metodzie forward.\n",
    "\n",
    "```python\n",
    "self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in emb_szs])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Dodajemy dropout do embedding√≥w\n",
    "\n",
    "Wykorzystujemy [`torch.nn.Dropout()`](https://pytorch.org/docs/stable/nn.html#dropout). Domy≈õlnie `p = 0.5`.\n",
    "\n",
    "```python\n",
    "self.emb_drop = nn.Dropout(emb_drop)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Normalizujemy zmienne ciƒÖg≈Çe\n",
    "\n",
    "Siƒôgamy po [`torch.nn.BatchNorm1d()`](https://pytorch.org/docs/stable/nn.html#batchnorm1d).\n",
    "\n",
    "```python\n",
    "self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Budujemy sekwencjƒô warstw sieci\n",
    "\n",
    "Ka≈ºda warstwa zawiera:\n",
    "\n",
    "* warstwƒô `Linear`\n",
    "* funkcjƒô aktywacji (ReLU)\n",
    "* krok normalizacji\n",
    "* warstwƒô dropout\n",
    "\n",
    "Sk≈Çadamy je przy pomocy [`torch.nn.Sequential()`](https://pytorch.org/docs/stable/nn.html#sequential).\n",
    "\n",
    "```python\n",
    "self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "layerlist = []\n",
    "\n",
    "n_emb = sum((nf for ni, nf in emb_szs))\n",
    "n_in = n_emb + n_cont\n",
    "\n",
    "for i in layers:\n",
    "    layerlist.append(nn.Linear(n_in, i))\n",
    "    layerlist.append(nn.ReLU(inplace=True))\n",
    "    layerlist.append(nn.BatchNorm1d(i))\n",
    "    layerlist.append(nn.Dropout(p))\n",
    "    n_in = i\n",
    "\n",
    "layerlist.append(nn.Linear(layers[-1], out_sz))\n",
    "\n",
    "self.layers = nn.Sequential(*layerlist)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Definiujemy metodƒô `forward`\n",
    "\n",
    "Przetwarzamy embeddingi, normalizujemy zmienne ciƒÖg≈Çe, a nastƒôpnie przekazujemy wszystko przez kolejne warstwy. Do ≈ÇƒÖczenia tensor√≥w u≈ºywamy [`torch.cat()`](https://pytorch.org/docs/stable/torch.html#torch.cat).\n",
    "\n",
    "```python\n",
    "def forward(self, x_cat, x_cont):\n",
    "    embeddings = []\n",
    "    for i, e in enumerate(self.embeds):\n",
    "        embeddings.append(e(x_cat[:, i]))\n",
    "    x = torch.cat(embeddings, 1)\n",
    "    x = self.emb_drop(x)\n",
    "\n",
    "    x_cont = self.bn_cont(x_cont)\n",
    "    x = torch.cat([x, x_cont], 1)\n",
    "    x = self.layers(x)\n",
    "    return x\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Pozostawiamy ten uk≈Çad krok po kroku bez dodatkowych wyr√≥≈ºnik√≥w ‚Äì jest przejrzysty i wystarczajƒÖcy.\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\\\"alert alert-danger\\\"><strong>Rozbijamy krok embedding√≥w na czƒô≈õci sk≈Çadowe</strong> (ten kod s≈Çu≈ºy wy≈ÇƒÖcznie ilustracji).</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:34.763036Z",
     "start_time": "2025-09-24T20:21:34.753376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To nasze dane ≈∫r√≥d≈Çowe\n",
    "catz = cats[:4]\n",
    "catz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:36.086978Z",
     "start_time": "2025-09-24T20:21:36.083675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To jest przekazywane podczas tworzenia instancji modelu\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:37.891192Z",
     "start_time": "2025-09-24T20:21:37.887079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 4)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To przypisanie wykonywane jest w metodzie __init__()\n",
    "selfembeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "selfembeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:38.921117Z",
     "start_time": "2025-09-24T20:21:38.918681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, Embedding(24, 12)), (1, Embedding(2, 1)), (2, Embedding(7, 4))]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(selfembeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:39.552902Z",
     "start_time": "2025-09-24T20:21:39.545002Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.9052,  0.1919,  0.5433, -0.3039,  0.3522,  0.3176, -0.1628,  0.0160,\n",
       "          -1.8537,  0.0525,  0.6894,  2.2636],\n",
       "         [-0.8170, -0.2481, -0.5454,  0.9071,  1.5864, -0.0928,  0.6091,  0.0478,\n",
       "           0.2307, -1.8650, -0.9861,  0.2455],\n",
       "         [-0.8156,  1.3224,  0.6381,  0.7878,  0.2942,  1.2955, -0.7603,  0.5212,\n",
       "          -0.4220,  0.5602, -0.5419, -0.5408],\n",
       "         [ 0.9723, -0.4110, -1.3849,  0.2936, -0.2292,  0.4962, -0.5656,  1.2057,\n",
       "           2.6844, -0.8396, -1.7026,  0.3883]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[ 1.8399],\n",
       "         [ 1.8399],\n",
       "         [ 1.8399],\n",
       "         [-0.3339]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.6708, -2.2616,  0.7411, -0.0683],\n",
       "         [-0.9923, -0.3268,  0.4467,  2.0421],\n",
       "         [-0.9923, -0.3268,  0.4467,  2.0421],\n",
       "         [ 0.0135,  0.4746,  0.8613, -1.3922]], grad_fn=<EmbeddingBackward0>)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To dzieje siƒô wewnƒÖtrz metody forward()\n",
    "embeddingz = []\n",
    "for i,e in enumerate(selfembeds):\n",
    "    embeddingz.append(e(catz[:,i]))\n",
    "embeddingz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:41.296841Z",
     "start_time": "2025-09-24T20:21:41.291532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9052,  0.1919,  0.5433, -0.3039,  0.3522,  0.3176, -0.1628,  0.0160,\n",
       "         -1.8537,  0.0525,  0.6894,  2.2636,  1.8399, -0.6708, -2.2616,  0.7411,\n",
       "         -0.0683],\n",
       "        [-0.8170, -0.2481, -0.5454,  0.9071,  1.5864, -0.0928,  0.6091,  0.0478,\n",
       "          0.2307, -1.8650, -0.9861,  0.2455,  1.8399, -0.9923, -0.3268,  0.4467,\n",
       "          2.0421],\n",
       "        [-0.8156,  1.3224,  0.6381,  0.7878,  0.2942,  1.2955, -0.7603,  0.5212,\n",
       "         -0.4220,  0.5602, -0.5419, -0.5408,  1.8399, -0.9923, -0.3268,  0.4467,\n",
       "          2.0421],\n",
       "        [ 0.9723, -0.4110, -1.3849,  0.2936, -0.2292,  0.4962, -0.5656,  1.2057,\n",
       "          2.6844, -0.8396, -1.7026,  0.3883, -0.3339,  0.0135,  0.4746,  0.8613,\n",
       "         -1.3922]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ≈ÅƒÖczymy sekcje embedding√≥w (12,1,4) w jednƒÖ (17)\n",
    "z = torch.cat(embeddingz, 1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:44.443784Z",
     "start_time": "2025-09-24T20:21:44.441489Z"
    }
   },
   "outputs": [],
   "source": [
    "# To zosta≈Ço przypisane w metodzie __init__()\n",
    "selfembdrop = nn.Dropout(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-24T20:21:45.200786Z",
     "start_time": "2025-09-24T20:21:45.191279Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5087,  0.0000,  0.9056, -0.0000,  0.5871,  0.5293, -0.2713,  0.0000,\n",
       "         -3.0895,  0.0000,  1.1490,  0.0000,  3.0666, -1.1180, -0.0000,  0.0000,\n",
       "         -0.1139],\n",
       "        [-1.3617, -0.4134, -0.9089,  1.5119,  2.6440, -0.0000,  1.0151,  0.0000,\n",
       "          0.3845, -3.1084, -0.0000,  0.0000,  3.0666, -0.0000, -0.0000,  0.7445,\n",
       "          3.4034],\n",
       "        [-1.3594,  2.2041,  0.0000,  1.3130,  0.0000,  2.1591, -0.0000,  0.8687,\n",
       "         -0.7034,  0.0000, -0.9032, -0.9014,  3.0666, -1.6538, -0.5447,  0.0000,\n",
       "          3.4034],\n",
       "        [ 0.0000, -0.0000, -2.3082,  0.0000, -0.0000,  0.0000, -0.0000,  2.0095,\n",
       "          0.0000, -0.0000, -2.8376,  0.0000, -0.0000,  0.0000,  0.0000,  1.4355,\n",
       "         -0.0000]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = selfembdrop(z)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\\\"alert alert-danger\\\"><strong>Tak przekazujemy embeddingi kategoryczne do kolejnych warstw.</strong></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(24, 12)\n",
      "    (1): Embedding(2, 1)\n",
      "    (2): Embedding(7, 4)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        # Embeddingi dla kolumn kategorycznych\n",
    "        # Ka≈ºda kategoria (np. \"miasto\", \"p≈Çeƒá\") dostaje w≈Çasny wektor liczb\n",
    "        # To bƒôdzie powiƒÖzane z danymi kt√≥re podamy w metodzie format\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in emb_szs])\n",
    "        \n",
    "        # Dropout na embeddingach ‚Äì losowo zeruje czƒô≈õƒá warto≈õci, by model nie przeucza≈Ç siƒô\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        \n",
    "        # BatchNorm dla cech ciƒÖg≈Çych ‚Äì normalizacja (≈õrednia=0, wariancja=1), stabilizuje uczenie\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        # Budowa sieci gƒôstej (MLP)\n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni, nf in emb_szs))  # ca≈Çkowita d≈Çugo≈õƒá wektora embedding√≥w\n",
    "        n_in = n_emb + n_cont                    # wej≈õcie = embeddingi + cechy ciƒÖg≈Çe\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in, i))     # warstwa liniowa (pe≈Çne po≈ÇƒÖczenie)\n",
    "            layerlist.append(nn.ReLU(inplace=True))  # aktywacja ReLU wprowadza nieliniowo≈õƒá\n",
    "            layerlist.append(nn.BatchNorm1d(i))      # normalizacja wyj≈õƒá danej warstwy\n",
    "            layerlist.append(nn.Dropout(p))          # dropout zapobiega przeuczeniu\n",
    "            n_in = i                                 # rozmiar wyj≈õcia staje siƒô wej≈õciem dla nastƒôpnej\n",
    "        layerlist.append(nn.Linear(layers[-1], out_sz))  # ostatnia warstwa ‚Üí wynik (np. 1 logit)\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)  # ≈ÇƒÖczenie wszystkiego w sekwencjƒô\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        # --- 1. Embeddingi dla kolumn kategorycznych ---\n",
    "        embeddings = []\n",
    "        for i, e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:, i]))        # wektor embeddingu dla danej kolumny\n",
    "        \n",
    "        # Sklej wszystkie embeddingi w jednƒÖ macierz\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        \n",
    "        # Dropout na embeddingach\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        # --- 2. Normalizacja cech ciƒÖg≈Çych ---\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        \n",
    "        # --- 3. Po≈ÇƒÖczenie embedding√≥w i cech ciƒÖg≈Çych ---\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        \n",
    "        # --- 4. Przepuszczenie przez sieƒá gƒôstƒÖ (MLP) ---\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# Przyk≈Çad: 3 kolumny kategoryczne + 6 cech ciƒÖg≈Çych\n",
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs=[(24, 12), (2, 1), (7, 4)],  # embeddingi dla kolumn kategorycznych\n",
    "                     n_cont=6,                           # liczba cech ciƒÖg≈Çych\n",
    "                     out_sz=1,                           # jedno wyj≈õcie (np. do regresji/klasyfikacji binarnej)\n",
    "                     layers=[200, 100],                  # ukryte warstwy: 200 ‚Üí 100\n",
    "                     p=0.4)                              # dropout = 0.4\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs, conts.shape[1], 1, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4, inplace=False)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4, inplace=False)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zdefiniuj funkcjƒô straty i optymalizator\n",
    "\n",
    "PyTorch nie ma wbudowanej funkcji straty <a href='https://en.wikipedia.org/wiki/Root-mean-square_deviation'>RMSE</a>, a chcieliby≈õmy u≈ºyƒá jej zamiast MSE.\n",
    "\n",
    "Dlatego podczas trenowania zastosujemy `torch.sqrt()` na wyniku `MSELoss`.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # p√≥≈∫niej przekszta≈Çcimy to na RMSE\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podziel dane na zbiory treningowy i testowy\n",
    "\n",
    "W tej chwili rozmiar partii odpowiada ca≈Çemu zbiorowi 120‚ÄØ000 rekord√≥w. Trenowanie trwa≈Çoby bardzo d≈Çugo, wiƒôc warto go zmniejszyƒá. My u≈ºyjemy 60‚ÄØ000. Pamiƒôtaj, ≈ºe nasze tensory sƒÖ ju≈º losowo potasowane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60000\n",
    "test_size = int(batch_size * .2)\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wytrenuj model\n",
    "\n",
    "Przygotuj siƒô na kilka minut pracy! Dodali≈õmy kod, kt√≥ry na ko≈Ñcu poda czas trwania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 12.56661701\n",
      "epoch:  26  loss: 10.91411972\n",
      "epoch:  51  loss: 10.22180843\n",
      "epoch:  76  loss: 9.74225330\n",
      "epoch: 101  loss: 9.18566704\n",
      "epoch: 126  loss: 8.43124580\n",
      "epoch: 151  loss: 7.42796469\n",
      "epoch: 176  loss: 6.23023224\n",
      "epoch: 201  loss: 5.07406998\n",
      "epoch: 226  loss: 4.21130562\n",
      "epoch: 251  loss: 3.89492106\n",
      "epoch: 276  loss: 3.78523421\n",
      "epoch: 301  loss: 3.67429900\n",
      "epoch: 326  loss: 3.64834642\n",
      "epoch: 351  loss: 3.58250666\n",
      "epoch: 376  loss: 3.53372526\n",
      "epoch: 400  loss: 3.49451923\n",
      "\n",
      "Duration: 37 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 400\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # sprytny trik, ≈ºeby oszczƒôdziƒá miejsce na ekranie:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # wypisz ostatniƒÖ liniƒô\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # wypisz czas trwania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wykres funkcji straty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), [loss.detach().numpy() for loss in losses])\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zweryfikuj model\n",
    "\n",
    "Przepu≈õcimy ca≈Çy zbi√≥r testowy przez model i por√≥wnamy wyniki z rzeczywistymi etykietami.  \n",
    "Na tym etapie **nie chcemy aktualizowaƒá wag i bias√≥w**, dlatego u≈ºyjemy kontekstu `torch.no_grad()`.\n",
    "\n",
    "---\n",
    "\n",
    "## RMSE ‚Äì Root Mean Squared Error\n",
    "\n",
    "**RMSE** (pierwiastek z b≈Çƒôdu ≈õredniokwadratowego) to jedna z najczƒô≈õciej stosowanych metryk do oceny jako≈õci modeli regresyjnych.  \n",
    "\n",
    "### Jak dzia≈Ça?\n",
    "\n",
    "1. Model przewiduje warto≈õci $\\hat{y}_i$, a my mamy warto≈õci rzeczywiste $y_i$.  \n",
    "2. Liczymy r√≥≈ºnice (residua): $e_i = y_i - \\hat{y}_i$.  \n",
    "3. Podnosimy r√≥≈ºnice do kwadratu: $e_i^2$ ‚Äì dziƒôki temu nie ma znaczenia znak i mocniej karzemy du≈ºe b≈Çƒôdy.  \n",
    "4. Liczymy ≈õredniƒÖ z tych kwadrat√≥w ‚Äì to **MSE** (*Mean Squared Error*).  \n",
    "5. Bierzemy pierwiastek kwadratowy ‚Üí otrzymujemy **RMSE**.  \n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 }\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretacja\n",
    "\n",
    "- RMSE jest **w tej samej jednostce**, co przewidywana warto≈õƒá (np. z≈Çote, kilometry, stopnie Celsjusza).  \n",
    "- **Im mniejsze RMSE, tym lepiej** ‚Äì oznacza to, ≈ºe przewidywania sƒÖ bli≈ºej warto≈õci rzeczywistych.  \n",
    "- RMSE jest **wra≈ºliwe na du≈ºe odchylenia** (outliers), poniewa≈º b≈Çƒôdy sƒÖ podnoszone do kwadratu.  \n",
    "\n",
    "üëâ Mo≈ºesz my≈õleƒá o RMSE jako o **‚Äû≈õrednim b≈Çƒôdzie‚Äù w jednostkach przewidywanej wielko≈õci**.\n",
    "\n",
    "```\n",
    "\n",
    "Chcesz, ≈ºebym przygotowa≈Ç jeszcze kr√≥tkƒÖ tabelkƒô por√≥wnujƒÖcƒÖ RMSE z MAE i R¬≤, ≈ºeby by≈Ço jasne, kiedy kt√≥rƒÖ metrykƒô wybraƒá?\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.43492579\n"
     ]
    }
   ],
   "source": [
    "# ABY OCENIƒÜ CA≈ÅY ZBI√ìR TESTOWY\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = torch.sqrt(criterion(y_val, y_test))\n",
    "print(f'RMSE: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oznacza to, ≈ºe ≈õrednio prognozy r√≥≈ºniƒÖ siƒô od warto≈õci rzeczywistej o ¬±\\$3.31.\n",
    "\n",
    "Sp√≥jrzmy teraz na pierwsze 10 przewidywanych warto≈õci:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PREDICTED   ACTUAL     DIFF\n",
      " 1.   4.2129   2.9000   1.3129\n",
      " 2.  23.5540   5.7000  17.8540\n",
      " 3.   4.2738   7.7000   3.4262\n",
      " 4.  11.8067  12.5000   0.6933\n",
      " 5.   4.0164   4.1000   0.0836\n",
      " 6.   4.4431   5.3000   0.8569\n",
      " 7.   1.5540   3.7000   2.1460\n",
      " 8.  13.7873  14.5000   0.7127\n",
      " 9.   5.6618   5.7000   0.0382\n",
      "10.  14.4415  10.1000   4.3415\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
    "for i in range(10):\n",
    "    diff = np.abs(y_val[i].item()-y_test[i].item())\n",
    "    print(f'{i+1:2}. {y_val[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wiele predykcji pomyli≈Ço siƒô o kilka cent√≥w, ale niekt√≥re nawet o kilkana≈õcie dolar√≥w.\n",
    "\n",
    "\n",
    "Spr√≥buj zmieniaƒá rozmiar partii, wielko≈õƒá zbioru testowego i liczbƒô epok, aby uzyskaƒá lepszy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zapisz model\n",
    "\n",
    "Wytrenowany model warto zachowaƒá, by p√≥≈∫niej m√≥c wykorzystaƒá go do nowych danych.  \n",
    "NajlepszƒÖ praktykƒÖ jest zapis **stanu modelu** (wag i bias√≥w), a nie ca≈Çej definicji.  \n",
    "\n",
    "Upewnij siƒô te≈º, ≈ºe zapisujesz wy≈ÇƒÖcznie **model po treningu**, aby nie nadpisaƒá poprzedniej wersji nieprzeszkolonym modelem.  \n",
    "\n",
    "Wiƒôcej informacji znajdziesz w [oficjalnym poradniku PyTorch](https://pytorch.org/tutorials/beginner/saving_loading_models.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pamiƒôtaj, ≈ºeby zapisaƒá model dopiero po zako≈Ñczeniu treningu!\n",
    "if len(losses) == epochs:\n",
    "    torch.save(model.state_dict(), 'TaxiFareRegrModel.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wczytanie zapisanego modelu (od zera)\n",
    "\n",
    "Mo≈ºemy wczytaƒá wyuczone wagi i biasy z zapisanej wersji.  \n",
    "Je≈õli dopiero otworzy≈Çe≈õ notatnik, uruchom najpierw **standardowe importy** i **definicje funkcji**.  \n",
    "\n",
    "Aby to zademonstrowaƒá, przed dalszƒÖ pracƒÖ **zrestartuj kernel**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 12.50666714\n",
      "epoch:  26  loss: 10.72367573\n",
      "epoch:  51  loss: 10.12331867\n",
      "epoch:  76  loss: 9.70387554\n",
      "epoch: 101  loss: 9.19267559\n",
      "epoch: 126  loss: 8.44067955\n",
      "epoch: 151  loss: 7.45702410\n",
      "epoch: 176  loss: 6.23063993\n",
      "epoch: 201  loss: 4.99481392\n",
      "epoch: 226  loss: 4.14790440\n",
      "epoch: 251  loss: 3.81091595\n",
      "epoch: 276  loss: 3.70445657\n",
      "epoch: 301  loss: 3.64069176\n",
      "epoch: 326  loss: 3.58935976\n",
      "epoch: 351  loss: 3.55485582\n",
      "epoch: 376  loss: 3.53260016\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    r = 6371\n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    return r * c\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        return self.layers(x)\n",
    "\n",
    "emb_szs = [(24, 12), (2, 1), (7, 4)]\n",
    "model2 = TabularModel(emb_szs, 6, 1, [200,100], p=0.4)\n",
    "\n",
    "criterion = nn.MSELoss()  # p√≥≈∫niej przekszta≈Çcimy to na RMSE\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 400\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model2(cat_train, con_train)\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # sprytny trik, ≈ºeby oszczƒôdziƒá miejsce na ekranie:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 12.54976082\n",
      "epoch:  26  loss: 12.54480553\n",
      "epoch:  51  loss: 12.54600620\n",
      "epoch:  76  loss: 12.54979801\n",
      "epoch: 101  loss: 12.54709244\n",
      "epoch: 126  loss: 12.55134201\n",
      "epoch: 151  loss: 12.55424976\n",
      "epoch: 176  loss: 12.54741573\n",
      "epoch: 201  loss: 12.54950523\n",
      "epoch: 226  loss: 12.55294704\n",
      "epoch: 251  loss: 12.55544281\n",
      "epoch: 276  loss: 12.55192089\n",
      "epoch: 301  loss: 12.55470371\n",
      "epoch: 326  loss: 12.54674244\n",
      "epoch: 351  loss: 12.54883003\n",
      "epoch: 376  loss: 12.54930496\n",
      "epoch: 400  loss: 12.54578018\n",
      "\n",
      "Duration: 40 seconds\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujmy model. \n",
    "\n",
    "Zanim za≈Çadujemy zapisane ustawienia, musimy utworzyƒá instancjƒô TabularModel z tymi samymi parametrami co wcze≈õniej \n",
    "(rozmiary embedding√≥w, liczba zmiennych ciƒÖg≈Çych, rozmiar wyj≈õcia, rozmiary warstw i warto≈õƒá dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_szs = [(24, 12), (2, 1), (7, 4)]\n",
    "# model2 = TabularModel(emb_szs, 6, 1, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gdy model jest gotowy, za≈Çadowanie zapisanych ustawie≈Ñ to formalno≈õƒá.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.load_state_dict(torch.load('TaxiFareRegrModel.pt'));\n",
    "# model2.eval() # koniecznie wykonaj ten krok!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"TaxiFareClssModel.pt\"))\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdefiniujemy teraz funkcjƒô, kt√≥ra przyjmie nowe dane u≈ºytkownika, wykona wszystkie opisane wcze≈õniej kroki przetwarzania i przepu≈õci dane przez wytrenowany model.\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_dataframe(\n",
    "    plat: float, plong: float,\n",
    "    dlat: float, dlong: float,\n",
    "    psngr: int, dt: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Buduje bazowy DataFrame z pojedynczym rekordem.\"\"\"\n",
    "    return pd.DataFrame({\n",
    "        'pickup_latitude': plat,\n",
    "        'pickup_longitude': plong,\n",
    "        'dropoff_latitude': dlat,\n",
    "        'dropoff_longitude': dlong,\n",
    "        'passenger_count': psngr,\n",
    "        'EDTdate': pd.to_datetime(dt)\n",
    "    }, index=[0])\n",
    "\n",
    "\n",
    "def add_distance_feature(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Dodaje kolumnƒô z odleg≈Ço≈õciƒÖ (w km).\"\"\"\n",
    "    df['dist_km'] = haversine_distance(\n",
    "        df, 'pickup_latitude', 'pickup_longitude',\n",
    "        'dropoff_latitude', 'dropoff_longitude'\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_datetime_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Dodaje cechy zwiƒÖzane z czasem (Hour, AMorPM, Weekday).\"\"\"\n",
    "    df['Hour'] = df['EDTdate'].dt.hour\n",
    "    df['AMorPM'] = np.where(df['Hour'] < 12, 0, 1)\n",
    "    df['Weekday'] = (\n",
    "        df['EDTdate']\n",
    "        .dt.strftime(\"%a\")\n",
    "        .replace(\n",
    "            ['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n",
    "            [0,1,2,3,4,5,6]\n",
    "        )\n",
    "        .astype('int64')\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def dataframe_to_tensors(df: pd.DataFrame) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Konwertuje DataFrame do tensor√≥w kategorii i warto≈õci ciƒÖg≈Çych.\"\"\"\n",
    "    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "    cont_cols = [\n",
    "        'pickup_latitude', 'pickup_longitude',\n",
    "        'dropoff_latitude', 'dropoff_longitude',\n",
    "        'passenger_count', 'dist_km'\n",
    "    ]\n",
    "\n",
    "    xcats = torch.tensor(\n",
    "        np.stack([df[col].values for col in cat_cols], 1),\n",
    "        dtype=torch.int64\n",
    "    )\n",
    "    xconts = torch.tensor(\n",
    "        np.stack([df[col].values for col in cont_cols], 1),\n",
    "        dtype=torch.float\n",
    "    )\n",
    "    return xcats, xconts\n",
    "\n",
    "\n",
    "def prepare_features(\n",
    "    plat: float, plong: float,\n",
    "    dlat: float, dlong: float,\n",
    "    psngr: int, dt: str\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Przygotowuje cechy wej≈õciowe (kategoryczne i ciƒÖg≈Çe) \n",
    "    na podstawie podanych parametr√≥w.\n",
    "    \"\"\"\n",
    "    df = build_dataframe(plat, plong, dlat, dlong, psngr, dt)\n",
    "    df = add_distance_feature(df)\n",
    "    df = add_datetime_features(df)\n",
    "    return dataframe_to_tensors(df)\n",
    "\n",
    "\n",
    "def predict_fare(\n",
    "    model,\n",
    "    plat: float, plong: float,\n",
    "    dlat: float, dlong: float,\n",
    "    psngr: int, dt: str\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Zwraca przewidywanƒÖ op≈Çatƒô za kurs taks√≥wkƒÖ na podstawie modelu i parametr√≥w wej≈õciowych.\n",
    "    \"\"\"\n",
    "    xcats, xconts = prepare_features(plat, plong, dlat, dlong, psngr, dt)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(xcats, xconts)\n",
    "\n",
    "    return prediction.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Przepu≈õƒá nowe dane przez wytrenowany model\n",
    "\n",
    "Dla wygody poni≈ºej znajdziesz warto≈õci minimalne i maksymalne ka≈ºdej zmiennej:\n",
    "\n",
    "| Kolumna           | Minimum               | Maksimum             |\n",
    "|-------------------|-----------------------|----------------------|\n",
    "| pickup_latitude   | 40                    | 41                   |\n",
    "| pickup_longitude  | -74.5                 | -73.3                |\n",
    "| dropoff_latitude  | 40                    | 41                   |\n",
    "| dropoff_longitude | -74.5                 | -73.3                |\n",
    "| passenger_count   | 1                     | 5                    |\n",
    "| EDTdate           | 2010-04-11 00:00:00   | 2010-04-24 23:59:42  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted fare amount is $192.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ff/6wst9f1n1g96lc__ld426szh0000gn/T/ipykernel_84035/566468548.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace(\n"
     ]
    }
   ],
   "source": [
    "fare = predict_fare(\n",
    "    model2,\n",
    "    plat=40.0,\n",
    "    plong=-74.5,\n",
    "    dlat=41,\n",
    "    dlong=-73.3,\n",
    "    psngr=1,\n",
    "    dt=\"2010-04-12 08:24:00\"\n",
    ")\n",
    "print(f\"The predicted fare amount is ${fare:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Zachowaj ostro≈ºno≈õƒá!</strong> Odleg≈Ço≈õƒá odpowiadajƒÖca 1 stopniowi szeroko≈õci geograficznej (od 40 do 41) to 111 km (69 mil), a 1 stopniowi d≈Çugo≈õci (od -73 do -74) ‚Äì 85 km (53 mile). \n",
    "\n",
    "Najd≈Çu≈ºszy kurs w zbiorze r√≥≈ºni≈Ç siƒô zaledwie o 0.243 stopnia szeroko≈õci i 0.284 stopnia d≈Çugo≈õci. \n",
    "\n",
    "≈örednia r√≥≈ºnica dla obu wynosi ok. 0.02. \n",
    "\n",
    "Aby otrzymaƒá wiarygodne prognozy, korzystaj z warto≈õci po≈Ço≈ºonych blisko siebie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zr√≥bmy to jeszcze w TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogiczny model w TensorFlow/Keras\n",
    "\n",
    "Poni≈ºsza sekcja odtwarza sieƒá tablicowƒÖ w Keras, korzystajƒÖc z tych samych cech kategorycznych i ciƒÖg≈Çych oraz analogicznej architektury (embeddingi + MLP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cats[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Ustawiamy ziarno losowe (seed), ≈ºeby wyniki by≈Çy powtarzalne\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Konwersja danych wej≈õciowych z tensora PyTorch/TF na numpy arrays \n",
    "# i rzutowanie na odpowiednie typy (int32 dla kategorii, float32 dla liczb zmiennoprzecinkowych).\n",
    "# Dziƒôki temu model w Kerasie dostaje dane w formacie, kt√≥rego oczekuje.\n",
    "cat_train_np = cat_train.numpy().astype('int32')\n",
    "cat_test_np = cat_test.numpy().astype('int32')\n",
    "con_train_np = con_train.numpy().astype('float32')\n",
    "con_test_np = con_test.numpy().astype('float32')\n",
    "y_train_np = y_train.numpy().astype('float32')\n",
    "y_test_np = y_test.numpy().astype('float32')\n",
    "\n",
    "# Przygotowanie s≈Çownika wej≈õƒá dla modelu:\n",
    "# - ka≈ºdy atrybut kategoryczny dostaje osobny \"wektor kolumnowy\"\n",
    "# - dane ciƒÖg≈Çe grupujemy razem w jednej macierzy pod kluczem 'cont'\n",
    "train_inputs = {f'cat_{i}': cat_train_np[:, i:i+1] for i in range(cat_train_np.shape[1])}\n",
    "test_inputs = {f'cat_{i}': cat_test_np[:, i:i+1] for i in range(cat_test_np.shape[1])}\n",
    "train_inputs['cont'] = con_train_np\n",
    "test_inputs['cont'] = con_test_np\n",
    "\n",
    "# Informacyjnie wypisujemy wersjƒô TensorFlow (pomocne przy debugowaniu i odtwarzaniu wynik√≥w)\n",
    "print(f'TensorFlow version: {tf.__version__}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_cat = []     # lista wej≈õƒá dla zmiennych kategorycznych\n",
    "embeddings = []     # lista embedding√≥w odpowiadajƒÖcych tym wej≈õciom\n",
    "\n",
    "# Tworzymy osobne wej≈õcie i warstwƒô embedding dla ka≈ºdej cechy kategorycznej\n",
    "for idx, (cardinality, emb_dim) in enumerate(emb_szs):\n",
    "    # Wej≈õcie (pojedyncza liczba ca≈Çkowita reprezentujƒÖca kategoriƒô)\n",
    "    input_layer = keras.Input(shape=(1,), name=f'cat_{idx}')\n",
    "    \n",
    "    # Warstwa embedding: zamiana indeksu kategorii na gƒôsty wektor o wymiarze emb_dim\n",
    "    embed = keras.layers.Embedding(cardinality, emb_dim, name=f'emb_{idx}')(input_layer)\n",
    "    \n",
    "    # Reshape: sp≈Çaszczenie (bo Embedding zwraca kszta≈Çt (batch, 1, emb_dim))\n",
    "    embed = keras.layers.Reshape((emb_dim,), name=f'emb_{idx}_reshape')(embed)\n",
    "    \n",
    "    # Zbieramy do list\n",
    "    embeddings.append(embed)\n",
    "    inputs_cat.append(input_layer)\n",
    "\n",
    "embeddings, inputs_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ≈ÇƒÖczymy je w jeden wektor cech\n",
    "cat_features = keras.layers.Concatenate(name='cats_concat')(embeddings)\n",
    "\n",
    "\n",
    "# Dropout dla embedding√≥w ‚Äî redukuje przeuczenie\n",
    "cat_features = keras.layers.Dropout(0.4, name='cats_dropout')(cat_features)\n",
    "\n",
    "# Wej≈õcie dla zmiennych ciƒÖg≈Çych\n",
    "cont_input = keras.Input(shape=(con_train_np.shape[1],), name='cont')\n",
    "\n",
    "# BatchNormalization ‚Äî normalizacja danych ciƒÖg≈Çych (przyspiesza uczenie)\n",
    "cont_features = keras.layers.BatchNormalization(name='cont_bn')(cont_input)\n",
    "\n",
    "# Po≈ÇƒÖczenie cech kategorycznych i ciƒÖg≈Çych w jeden wektor\n",
    "x = keras.layers.Concatenate(name='features_concat')([cat_features, cont_features])\n",
    "\n",
    "# Klasyczne gƒôste warstwy ukryte (MLP)\n",
    "for i, units in enumerate([200, 100]):\n",
    "    # Gƒôsta warstwa w pe≈Çni po≈ÇƒÖczona z ReLU\n",
    "    x = keras.layers.Dense(units, activation='relu', name=f'dense_{i}')(x)\n",
    "    # Normalizacja batchowa stabilizuje rozk≈Çad aktywacji\n",
    "    x = keras.layers.BatchNormalization(name=f'bn_{i}')(x)\n",
    "    # Dropout dla redukcji przeuczenia\n",
    "    x = keras.layers.Dropout(0.4, name=f'dropout_{i}')(x)\n",
    "\n",
    "# Warstwa wyj≈õciowa ‚Äî 1 neuron (predykcja ceny przejazdu)\n",
    "output = keras.layers.Dense(1, name='fare')(x)\n",
    "\n",
    "# Sk≈Çadamy ca≈Çy model ‚Äî wej≈õcia to embeddingi + cechy ciƒÖg≈Çe\n",
    "tf_model = keras.Model(inputs=inputs_cat + [cont_input], outputs=output, name='taxi_fare_model_tf')\n",
    "\n",
    "# Kompilacja modelu:\n",
    "# - optimizer Adam (0.001)\n",
    "# - funkcja straty: MSE (b≈ÇƒÖd ≈õredniokwadratowy)\n",
    "# - metryka: RMSE (bardziej interpretowalna w jednostkach ceny)\n",
    "tf_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.001),\n",
    "    loss='mse',\n",
    "    metrics=[keras.metrics.RootMeanSquaredError(name='rmse')]\n",
    ")\n",
    "\n",
    "# Podsumowanie modelu (lista warstw, parametry, kszta≈Çty)\n",
    "tf_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback: EarlyStopping\n",
    "# Monitorujemy walidacyjnƒÖ metrykƒô RMSE (val_rmse).\n",
    "# Je≈õli przez 20 epok nie bƒôdzie poprawy, zatrzymujemy trening.\n",
    "# restore_best_weights=True oznacza, ≈ºe model przywr√≥ci najlepsze wagi z okresu treningu.\n",
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_rmse',\n",
    "    patience=20,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Trening modelu:\n",
    "# - dane treningowe (wej≈õcia + etykiety)\n",
    "# - walidacja na zbiorze testowym\n",
    "# - max 200 epok, batch_size=512\n",
    "# - verbose=0, czyli bez spamowania logami\n",
    "# - EarlyStopping, ≈ºeby nie przeuczaƒá modelu\n",
    "history = tf_model.fit(\n",
    "    train_inputs,\n",
    "    y_train_np,\n",
    "    validation_data=(test_inputs, y_test_np),\n",
    "    epochs=200,\n",
    "    batch_size=512,\n",
    "    verbose=0,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Historia treningu (loss + metryki) do DataFrame dla wygodnego przeglƒÖdania\n",
    "history_df = pd.DataFrame(history.history)\n",
    "print(history_df[['rmse', 'val_rmse']].tail())\n",
    "\n",
    "# Ewaluacja na danych testowych ‚Äî obliczamy stratƒô i RMSE\n",
    "test_loss, test_rmse = tf_model.evaluate(test_inputs, y_test_np, verbose=0)\n",
    "print(f'Test RMSE: {test_rmse:.4f}')\n",
    "\n",
    "# Predykcje na zbiorze testowym\n",
    "preds = tf_model.predict(test_inputs, verbose=0).flatten()\n",
    "actuals = y_test_np.flatten()\n",
    "\n",
    "# Por√≥wnanie: przewidywane vs rzeczywiste warto≈õci (pierwsze 10 przypadk√≥w)\n",
    "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
    "for i in range(10):\n",
    "    diff = abs(preds[i] - actuals[i])  # r√≥≈ºnica absolutna\n",
    "    print(f'{i+1:2}. {preds[i]:8.4f} {actuals[i]:8.4f} {diff:8.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_fare_keras(model, plat, plong, dlat, dlong, psngr, dt):\n",
    "    xcats, xconts = prepare_features(plat, plong, dlat, dlong, psngr, dt)\n",
    "    keras_inputs = {f'cat_{i}': xcats.numpy()[:, i:i+1].astype('int32') for i in range(xcats.shape[1])}\n",
    "    keras_inputs['cont'] = xconts.numpy().astype('float32')\n",
    "    prediction = model.predict(keras_inputs, verbose=0)\n",
    "    return float(prediction.squeeze())\n",
    "\n",
    "fare_tf = predict_fare_keras(\n",
    "    tf_model,\n",
    "    plat=40.0,\n",
    "    plong=-74.5,\n",
    "    dlat=41,\n",
    "    dlong=-73.3,\n",
    "    psngr=1,\n",
    "    dt=\"2010-04-12 08:24:00\"\n",
    ")\n",
    "print(f\"TensorFlow prognoza op≈Çaty: ${fare_tf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### uwaga - w przykladzie PyTorch nie byo early stoppingu. Trzeba by go implementowac rƒôcznie w petli uczenia\n",
    "\n",
    "Co≈õ w ten dese≈Ñ:\n",
    "\n",
    "\n",
    "```python\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_one_epoch(...)   # trening na batchach\n",
    "    val_loss = evaluate_on_validation(...)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "# przywracamy najlepsze wagi\n",
    "model.load_state_dict(best_model_wts)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
