{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f288ccd43487d87e",
   "metadata": {},
   "source": [
    "# TensorFlow ‚Äì czym jest i do czego s≈Çu≈ºy?\n",
    "\n",
    "**TensorFlow** to jedna z najpopularniejszych bibliotek do uczenia maszynowego i g≈Çƒôbokiego uczenia, stworzona i rozwijana przez **Google Brain Team** (premiera w 2015 roku). Jest napisana w **C++**, z interfejsem w **Pythonie**, a tak≈ºe z wersjami dla jƒôzyk√≥w takich jak JavaScript czy Swift.\n",
    "\n",
    "### Kluczowe cechy\n",
    "\n",
    "* **Statyczne grafy oblicze≈Ñ (w oryginalnej wersji)** ‚Äì model by≈Ç definiowany jako ca≈Çy graf, a nastƒôpnie wykonywany. To dawa≈Ço du≈ºƒÖ wydajno≈õƒá i ≈Çatwo≈õƒá optymalizacji, ale poczƒÖtkowo utrudnia≈Ço debugowanie.\n",
    "* **Keras jako wysoki poziom** ‚Äì od TensorFlow 2.0 domy≈õlnie integruje API **Keras**, co bardzo u≈Çatwia budowanie i trenowanie modeli.\n",
    "* **Wydajno≈õƒá i skalowalno≈õƒá** ‚Äì TensorFlow jest zoptymalizowany pod kƒÖtem du≈ºych modeli i rozproszonych oblicze≈Ñ (np. na wielu GPU lub w chmurze).\n",
    "* **Wsparcie dla produkcji** ‚Äì ma narzƒôdzia takie jak **TensorFlow Serving**, **TensorFlow Lite** (na urzƒÖdzenia mobilne) i **TensorFlow.js** (w przeglƒÖdarce), kt√≥re u≈ÇatwiajƒÖ wdra≈ºanie modeli.\n",
    "* **Eager execution** ‚Äì od TensorFlow 2.0 dzia≈Ça w trybie ‚Äûna ≈ºywo‚Äù (dynamicznym), podobnie jak PyTorch, ale wciƒÖ≈º pozwala prze≈ÇƒÖczaƒá siƒô na grafy statyczne dla optymalizacji.\n",
    "\n",
    "### Do czego jest u≈ºywany?\n",
    "\n",
    "* **Deep learning** ‚Äì trenowanie modeli CNN, RNN, transformer√≥w.\n",
    "* **Wizja komputerowa** ‚Äì rozpoznawanie obraz√≥w, detekcja obiekt√≥w (czƒôsto z bibliotekƒÖ **tf.keras.applications**).\n",
    "* **Przetwarzanie jƒôzyka naturalnego (NLP)** ‚Äì od klasyfikacji tekst√≥w po nowoczesne modele jƒôzykowe.\n",
    "* **Du≈ºe wdro≈ºenia produkcyjne** ‚Äì dziƒôki wsparciu Google Cloud i narzƒôdziom do serwowania modeli.\n",
    "* **IoT i mobile** ‚Äì TensorFlow Lite umo≈ºliwia uruchamianie modeli na smartfonach, Raspberry Pi czy mikrokontrolerach.\n",
    "\n",
    "### Dlaczego jest popularny?\n",
    "\n",
    "TensorFlow by≈Ç pierwszym du≈ºym, otwartym frameworkiem wspieranym przez gigantycznƒÖ firmƒô (Google), dlatego szybko sta≈Ç siƒô standardem przemys≈Çowym. Dziƒôki ogromnemu ekosystemowi i integracji z Kerasem jest szeroko u≈ºywany zar√≥wno w badaniach, jak i w zastosowaniach komercyjnych.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7263e0eeaa28a03",
   "metadata": {},
   "source": [
    "## TensorFlow 1.x vs TensorFlow 2.x\n",
    "\n",
    "### TensorFlow 1.x (2015‚Äì2019)\n",
    "\n",
    "* **Statyczny graf oblicze≈Ñ**: najpierw budujesz ca≈Çy graf (np. `tf.placeholder`, `tf.Session`), potem go uruchamiasz.\n",
    "* **Kod mniej ‚Äûpythoniczny‚Äù** ‚Äì wymaga≈Ç znajomo≈õci specyficznych konstrukcji (`tf.cond`, `tf.while_loop`) zamiast zwyk≈Çych `if` i `for`.\n",
    "* **Trudniejsze debugowanie** ‚Äì bo graf by≈Ç wykonywany dopiero w sesji, nie ‚Äûna ≈ºywo‚Äù.\n",
    "* **Du≈ºa moc i optymalizacja** ‚Äì ≈õwietny do produkcji i rozproszonych oblicze≈Ñ, ale trudniejszy dla poczƒÖtkujƒÖcych.\n",
    "\n",
    "### TensorFlow 2.x (od 2019)\n",
    "\n",
    "* **Domy≈õlnie ‚Äûeager execution‚Äù** ‚Äì dzia≈Ça podobnie jak PyTorch: obliczenia wykonywane sƒÖ natychmiast.\n",
    "* **Keras w centrum** ‚Äì `tf.keras` sta≈Ç siƒô oficjalnym, wysokopoziomowym API do budowania i trenowania modeli.\n",
    "* **Lepsza integracja z Pythonem** ‚Äì mo≈ºna pisaƒá kod z `if`, `for`, itp. (dynamiczny graf).\n",
    "* **Zachowane tryby statyczne** ‚Äì dziƒôki `@tf.function` mo≈ºna nadal ‚Äûzamroziƒá‚Äù graf i uzyskaƒá optymalizacjƒô w produkcji.\n",
    "* **≈Åatwiejsza nauka i migracja** ‚Äì kod jest kr√≥tszy, czytelniejszy, bardziej intuicyjny.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8122542ffc077cd8",
   "metadata": {},
   "source": [
    "## Keras\n",
    "\n",
    "Keras to tak naprawdƒô **wysokopoziomowe API** (interfejs) do budowania i trenowania sieci neuronowych w Pythonie.\n",
    "\n",
    "üîπ **Kr√≥tko historycznie:**\n",
    "\n",
    "* Powsta≈Ç w **2015 roku**, autor: **Fran√ßois Chollet** (in≈ºynier Google, tw√≥rca te≈º frameworka `Xception`).\n",
    "* PoczƒÖtkowo dzia≈Ça≈Ç jako ‚Äûnak≈Çadka‚Äù na r√≥≈ºne backendy (np. TensorFlow, Theano, CNTK).\n",
    "* Od **TensorFlow 2.0** Keras zosta≈Ç wbudowany w TensorFlow jako **tf.keras** i sta≈Ç siƒô jego oficjalnym API.\n",
    "\n",
    "---\n",
    "\n",
    "### Po co jest Keras?\n",
    "\n",
    "* Upraszcza tworzenie modeli: zamiast pisaƒá dziesiƒÖtki linijek kodu, mo≈ºna w kilku krokach zbudowaƒá i wytrenowaƒá sieƒá neuronowƒÖ.\n",
    "* Ukrywa szczeg√≥≈Çy techniczne (np. graf oblicze≈Ñ, zarzƒÖdzanie sesjami, optymalizacjƒô GPU).\n",
    "* Jest intuicyjny ‚Äì modele buduje siƒô prawie jak z klock√≥w Lego.\n",
    "\n",
    "---\n",
    "\n",
    "### G≈Ç√≥wne cechy Keras:\n",
    "\n",
    "1. **Prostota** ‚Äì ≈Çatwy start dla poczƒÖtkujƒÖcych.\n",
    "2. **Czytelno≈õƒá** ‚Äì kod przypomina zwyk≈Çy Python, a nie niszowy DSL.\n",
    "3. **Elastyczno≈õƒá** ‚Äì mimo prostoty, mo≈ºna te≈º tworzyƒá bardzo z≈Ço≈ºone modele.\n",
    "4. **Integracja z TensorFlow** ‚Äì korzysta z jego mocy obliczeniowej (GPU/TPU, rozproszone trenowanie).\n",
    "\n",
    "---\n",
    "\n",
    "### Przyk≈Çad ‚Äì sieƒá klasyfikujƒÖca cyfry (MNIST)\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Model sekwencyjny\n",
    "model = models.Sequential([\n",
    "    layers.Flatten(input_shape=(28, 28)),    # wej≈õcie 28x28\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Kompilacja modelu\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Trenowanie\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))\n",
    "```\n",
    "\n",
    "‚úÖ W kilkunastu linijkach mamy kompletny proces trenowania.\n",
    "Gdyby pisaƒá to od zera w ‚Äûczystym‚Äù TensorFlow albo PyTorch ‚Äì zajƒô≈Çoby znacznie wiƒôcej kodu.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Dane\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# --- Definicja parametr√≥w (rƒôcznie) ---\n",
    "W1 = tf.Variable(tf.random.normal([784, 128]))\n",
    "b1 = tf.Variable(tf.zeros([128]))\n",
    "W2 = tf.Variable(tf.random.normal([128, 10]))\n",
    "b2 = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# --- Funkcja forward ---\n",
    "def model(x):\n",
    "    x = tf.reshape(x, [-1, 784])                  # flatten\n",
    "    h = tf.nn.relu(tf.matmul(x, W1) + b1)         # warstwa ukryta\n",
    "    y = tf.nn.softmax(tf.matmul(h, W2) + b2)      # wyj≈õcie\n",
    "    return y\n",
    "\n",
    "# --- Funkcja straty ---\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "# --- Optymalizator ---\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# --- Pƒôtla treningowa ---\n",
    "for epoch in range(5):\n",
    "    for i in range(len(x_train)):\n",
    "        x = x_train[i:i+1]\n",
    "        y_true = y_train[i:i+1]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_true, y_pred)\n",
    "\n",
    "        grads = tape.gradient(loss, [W1, b1, W2, b2])\n",
    "        optimizer.apply_gradients(zip(grads, [W1, b1, W2, b2]))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.numpy():.4f}\")\n",
    "\n",
    "```\n",
    "\n",
    "üëâ W skr√≥cie: **Keras = przyjazna, prosta nak≈Çadka na TensorFlow**, kt√≥ra sprawia, ≈ºe praca z sieciami neuronowymi jest szybsza i ≈Çatwiejsza.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45afd7e3aebf7fd",
   "metadata": {},
   "source": [
    "/## 1. TensorFlow vs PyTorch\n",
    "\n",
    "| Cecha                               | **TensorFlow**                                                                                       | **PyTorch**                                                            |\n",
    "| ----------------------------------- | ---------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------- |\n",
    "| **Rok powstania**                   | 2015 (Google Brain)                                                                                  | 2016 (Facebook AI Research)                                            |\n",
    "| **Graf oblicze≈Ñ**                   | TF1: statyczny graf; TF2: domy≈õlnie dynamiczny (eager), z opcjƒÖ kompilacji do grafu (`@tf.function`) | Zawsze dynamiczny graf (budowany w trakcie wykonywania kodu)           |\n",
    "| **Produkcja / wdra≈ºanie**           | Bardzo mocny ekosystem: TensorFlow Serving, TF Lite, TF.js                                           | TorchServe, TorchScript, ONNX ‚Äì dobre, ale mniej dopracowane ni≈º TF    |\n",
    "| **Spo≈Çeczno≈õƒá**                     | Du≈ºe wsparcie przemys≈Çowe (Google, firmy u≈ºywajƒÖce TF w chmurze)                                     | Popularniejszy w ≈õrodowisku akademickim i badawczym                    |\n",
    "| **Uczenie rozproszone / wydajno≈õƒá** | Bardzo rozwiniƒôte, integracja z TPU                                                                  | Bardzo dobre wsparcie GPU, integracja z CUDA, ostatnio te≈º z Apple MPS |\n",
    "| **Krzywa nauki**                    | TF1 ‚Äì trudna, TF2/Keras ‚Äì ≈Çatwa                                                                      | Bardzo intuicyjna, ≈õwietna do nauki i eksperyment√≥w                    |\n",
    "\n",
    "üëâ Podsumowanie:\n",
    "\n",
    "* **TensorFlow** ‚Äì ≈õwietny do **produkcji, du≈ºych wdro≈ºe≈Ñ i skalowalno≈õci**.\n",
    "* **PyTorch** ‚Äì idealny do **bada≈Ñ, eksperyment√≥w i prototypowania**.\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Keras vs PyTorch\n",
    "\n",
    "| Cecha              | **Keras (tf.keras)**                                                                      | **PyTorch**                                                                          |\n",
    "| ------------------ | ----------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------ |\n",
    "| **Filozofia**      | Prosta, wysoki poziom, ‚Äûmodele z klock√≥w Lego‚Äù                                            | Bardziej niskopoziomowy, ale elastyczny                                              |\n",
    "| **≈Åatwo≈õƒá startu** | Bardzo ≈Çatwy ‚Äì parƒô linijek i masz sieƒá                                                   | Prosty, ale wymaga jawnego pisania pƒôtli treningowej                                 |\n",
    "| **Elastyczno≈õƒá**   | Ograniczona ‚Äì do typowych modeli (ale mo≈ºna pisaƒá w≈Çasne warstwy, trudniej ni≈º w PyTorch) | Bardzo elastyczny ‚Äì ≈Çatwo tworzyƒá nietypowe architektury, dynamiczne zmiany w modelu |\n",
    "| **Debugowanie**    | Dzia≈Ça w TF eager mode, ale bywa ‚Äûukryty‚Äù poziom                                          | Bardzo przejrzyste debugowanie (graf tworzony w trakcie)                             |\n",
    "| **Ekosystem**      | Wbudowane narzƒôdzia TensorFlow (Lite, Serving, TPU)                                       | TorchVision, TorchText, TorchAudio, ONNX ‚Äì mocne, ale mniej zunifikowane             |\n",
    "| **Dla kogo**       | PoczƒÖtkujƒÖcy, szybkie prototypowanie, projekty produkcyjne Google Cloud                   | Badacze, osoby chcƒÖce pe≈Çnej kontroli i eksperymentowania                            |\n",
    "\n",
    "üëâ Podsumowanie:\n",
    "\n",
    "* **Keras** = prostota, szybkie budowanie klasycznych modeli.\n",
    "* **PyTorch** = pe≈Çna kontrola i elastyczno≈õƒá, nawet kosztem wiƒôkszej ilo≈õci kodu.\n",
    "* **TensorFlow**  = du≈ºa wydajno≈õƒá, ≈õwietny na produkcjƒô\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad7f4087e392f39",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cfa90195e5a9287",
   "metadata": {},
   "source": [
    "# Podstawy TensorFlow ‚Äì Tensory\n",
    "\n",
    "W tej sekcji om√≥wimy:\n",
    "\n",
    "* Konwersjƒô tablic NumPy na tensory TensorFlow\n",
    "* Tworzenie tensor√≥w od zera* R√≥≈ºnice wzglƒôdem podej≈õcia w PyTorch\n",
    "\n",
    "## Wykonaj standardowe importy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92512c08ef13f5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:12:28.631665Z",
     "start_time": "2025-09-30T17:11:50.587212Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603d25dab29d1c4",
   "metadata": {},
   "source": [
    "## Sprawd≈∫ wersjƒô TensorFlow\n",
    "\n",
    "TensorFlow 2 domy≈õlnie uruchamia obliczenia w trybie eager, wiƒôc operacje dzia≈ÇajƒÖ podobnie jak w PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37d9b0620f9a359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:12:28.679054Z",
     "start_time": "2025-09-30T17:12:28.675126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450cdd3efbe21f65",
   "metadata": {},
   "source": [
    "## Konwersja tablic NumPy na tensory TensorFlow\n",
    "\n",
    "Analogicznie do `torch.tensor`, w TensorFlow u≈ºywamy m.in. `tf.convert_to_tensor` lub `tf.constant`.\n",
    "\n",
    "Zauwa≈º, ≈ºe TensorFlow domy≈õlnie tworzy tensory typu `tf.int64` dla liczb ca≈Çkowitych i `tf.float32` dla warto≈õci zmiennoprzecinkowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ce87287ed8502c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:13:16.933139Z",
     "start_time": "2025-09-30T17:13:16.898148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3 4 5], shape=(6,), dtype=int64)\n",
      "dtype: <dtype: 'int64'>\n",
      "Jako NumPy: [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "arr = np.arange(6)\n",
    "x = tf.convert_to_tensor(arr)\n",
    "print(x)\n",
    "print('dtype:', x.dtype)\n",
    "print('Jako NumPy:', x.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f584fd7649d64b",
   "metadata": {},
   "source": [
    "W przeciwie≈Ñstwie do PyTorch, tensory TensorFlow sƒÖ niemodyfikowalne (**immutable**).\n",
    "\n",
    "Zmiana tablicy ≈∫r√≥d≈Çowej NumPy nie wp≈Çywa na tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e36ab32b97da7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:13:51.853157Z",
     "start_time": "2025-09-30T17:13:51.840759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zmodyfikowane arr: [999   1   2   3   4   5]\n",
      "Tensor x pozosta≈Ç bez zmian: [0 1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "arr[0] = 999\n",
    "\n",
    "print('Zmodyfikowane arr:', arr)\n",
    "\n",
    "print('Tensor x pozosta≈Ç bez zmian:', x.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98f48c2789b44e7",
   "metadata": {},
   "source": [
    "## TensorFlow Variables\n",
    "\n",
    "Je≈õli potrzebujemy obiektu, kt√≥ry mo≈ºna modyfikowaƒá \"w miejscu\", u≈ºywamy `tf.Variable`.\n",
    "\n",
    "To r√≥≈ºnica wzglƒôdem PyTorch, gdzie ka≈ºdy tensor mo≈ºe przechowywaƒá gradienty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1ceb6941ca2f5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:14:25.045380Z",
     "start_time": "2025-09-30T17:14:25.012227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([1., 2., 3.], dtype=float32)>\n",
      "Po assign_add: <tf.Variable 'Variable:0' shape=(3,) dtype=float32, numpy=array([1.5, 2.5, 3.5], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "var = tf.Variable([1., 2., 3.], dtype=tf.float32)\n",
    "print(var)\n",
    "var.assign_add([0.5, 0.5, 0.5])\n",
    "print('Po assign_add:', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8390b6c4d3d8f5a",
   "metadata": {},
   "source": [
    "## Tworzenie tensor√≥w od zera\n",
    "\n",
    "Odpowiedniki funkcji `torch.zeros` czy `torch.ones` znajdujƒÖ siƒô w module `tf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40eb53e46eec9eb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:14:57.909737Z",
     "start_time": "2025-09-30T17:14:57.892003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros: [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "ones: [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "fill: [[7 7 7]\n",
      " [7 7 7]]\n"
     ]
    }
   ],
   "source": [
    "zeros = tf.zeros((2, 3))\n",
    "ones = tf.ones((2, 3), dtype=tf.float32)\n",
    "full = tf.fill((2, 3), 7)\n",
    "print('zeros:', zeros.numpy())\n",
    "print('ones:', ones.numpy())\n",
    "print('fill:', full.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346aefc1523cf8c9",
   "metadata": {},
   "source": [
    "## Losowe liczby\n",
    "\n",
    "TensorFlow udostƒôpnia metody `tf.random.normal`, `tf.random.uniform` i wiele innych.\n",
    "\n",
    "Nazwy sƒÖ nieco inne ni≈º w PyTorch, ale dzia≈Çanie jest analogiczne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "538e664a271954bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:15:24.578521Z",
     "start_time": "2025-09-30T17:15:24.553357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalny rozk≈Çad: [[-0.5798222   1.7611403  -0.09943233]\n",
      " [ 1.3010058   0.28214836  0.8640877 ]]\n",
      "Jednostajny rozk≈Çad: [[ 0.06529355  0.01903343  0.3020897 ]\n",
      " [-0.572804   -0.9006293   0.7291479 ]]\n"
     ]
    }
   ],
   "source": [
    "normal = tf.random.normal((2, 3), mean=0.0, stddev=1.0)\n",
    "uniform = tf.random.uniform((2, 3), minval=-1, maxval=1)\n",
    "print('Normalny rozk≈Çad:', normal.numpy())\n",
    "print('Jednostajny rozk≈Çad:', uniform.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1d71225019d45",
   "metadata": {},
   "source": [
    "## Konwersja typ√≥w danych\n",
    "\n",
    "Do zmiany typu u≈ºywamy `tf.cast`. To odpowiednik `tensor.type()` lub `tensor.to()` w PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44edbb926d7d1885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T17:15:42.990540Z",
     "start_time": "2025-09-30T17:15:42.980852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_float = tf.constant([1, 2, 3], dtype=tf.int32)\n",
    "x_float = tf.cast(x_float, tf.float32)\n",
    "print(x_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b8d1e97ba67aa",
   "metadata": {},
   "source": [
    "### ≈öwietna robota!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
