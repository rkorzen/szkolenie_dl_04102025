{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fc15ee3-82d5-4cfc-bff5-b6f1a8a7feb6",
   "metadata": {},
   "source": [
    "# ML i DL\n",
    "\n",
    "Uczenie maszynowe (ML) uczy modele na podstawie danych i etykiet. \n",
    "\n",
    "Deep learning (DL) to jego podzbiór wykorzystujący wielowarstwowe sieci neuronowe, które lepiej radzą sobie z obrazami, tekstem czy dźwiękiem kosztem większych wymagań danych i mocy obliczeniowej.\n",
    "\n",
    "## ✅ Główne zadania ML\n",
    "\n",
    "1. **Klasyfikacja**\n",
    "\n",
    "   * Odpowiada na pytanie: *do której klasy należy obiekt?*\n",
    "   * Przykłady: rozpoznawanie obrazów (kot vs pies), analiza sentymentu tekstu (pozytywny/negatywny).\n",
    "\n",
    "2. **Regresja**\n",
    "\n",
    "   * Przewiduje *wartość liczbową (ciągłą)*.\n",
    "   * Przykłady: przewidywanie cen nieruchomości, prognoza popytu.\n",
    "\n",
    "3. **Klasteryzacja**\n",
    "\n",
    "   * Grupuje podobne obiekty bez etykiet.\n",
    "   * Przykłady: segmentacja klientów, grupowanie dokumentów.\n",
    "\n",
    "4. **Rekomendacje**\n",
    "\n",
    "   * Proponują elementy na podstawie wcześniejszych wyborów.\n",
    "   * Przykłady: filmy w serwisach VOD, produkty w e-commerce.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f3eb8bbc57bb91",
   "metadata": {},
   "source": [
    "## Przegląd zastosowań machine learning (ML) i deep learning (DL)\n",
    "\n",
    "Poniżej znajdziesz szeroki przegląd zastosowań ML/DL wraz z praktycznymi wskazówkami „co do czego się nadaje”. Celem jest szybkie zorientowanie się, jakie typy modeli i technik wybierać do danego problemu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aadbdb15a58ab1",
   "metadata": {},
   "source": [
    "### Wizja komputerowa (Computer Vision)\n",
    "\n",
    "Wizja komputerowa to dział sztucznej inteligencji, który zajmuje się tym, aby **komputery „widziały” i rozumiały obrazy czy filmy w podobny sposób jak człowiek**.\n",
    "Wyobraź sobie, że pokazujesz komputerowi zdjęcie kota – wizja komputerowa pozwala mu powiedzieć: *„to jest kot”*, a czasem nawet *„to jest kot rasy syjamskiej, siedzący na kanapie”*.\n",
    "\n",
    "---\n",
    "\n",
    "#### Typowe zadania:\n",
    "\n",
    "* **Klasyfikacja obrazów** – odpowiedź na pytanie *„co znajduje się na obrazie?”*.\n",
    "  Np. zdjęcie psa → model mówi: „to pies”.\n",
    "\n",
    "* **Detekcja obiektów** – nie tylko *co* jest na obrazie, ale też *gdzie*.\n",
    "  Np. zdjęcie ulicy → model rysuje ramki wokół samochodów i pieszych.\n",
    "\n",
    "* **Segmentacja semantyczna / instancji** – komputer koloruje każdy piksel obrazu według tego, do czego należy.\n",
    "  Semantyczna: wszystkie samochody mają ten sam kolor.\n",
    "  Instancji: każdy samochód ma inny kolor.\n",
    "\n",
    "* **Rozpoznawanie twarzy, emocji** – wykrywanie kto jest na zdjęciu, albo jaka emocja jest wyrażona.\n",
    "\n",
    "* **OCR (Optical Character Recognition)** – odczyt tekstu z obrazów, np. ze skanu faktury.\n",
    "\n",
    "* **Image captioning** – komputer sam tworzy opis zdjęcia.\n",
    "  Np. „Na obrazku jest dziewczynka trzymająca balon”.\n",
    "\n",
    "* **VQA (Visual Question Answering)** – zadawanie pytań o obraz.\n",
    "  Np. pytasz: „Ile jest psów na zdjęciu?” → model odpowiada: „dwa”.\n",
    "\n",
    "* **Super-resolution** – poprawianie rozdzielczości obrazów.\n",
    "\n",
    "* **Denoising** – usuwanie szumu.\n",
    "\n",
    "* **Inpainting** – „domalowywanie” brakujących fragmentów obrazu.\n",
    "\n",
    "* **Medyczne obrazowanie** – wspieranie lekarzy przy analizie RTG, tomografii (TK), rezonansu (MRI).\n",
    "  Modele wykrywają np. zmiany nowotworowe albo złamania.\n",
    "\n",
    "---\n",
    "\n",
    "#### Co się sprawdza (najpopularniejsze metody i modele):\n",
    "\n",
    "* **CNN (Convolutional Neural Network)** – *splotowe sieci neuronowe*.\n",
    "To klasyczne modele, które bardzo dobrze analizują obrazy. „Skanują” obraz kawałek po kawałku i uczą się rozpoznawać wzory.\n",
    "\n",
    "* **ConvNeXt** – nowoczesna wersja CNN, bardziej efektywna.\n",
    "* **EfficientNet** – sieć zaprojektowana tak, by mieć jak najlepszy stosunek jakości do szybkości działania.\n",
    "\n",
    "* **Modele do detekcji obiektów**:\n",
    "\n",
    "* **Faster R-CNN** – łączy klasyfikację i lokalizację obiektów.\n",
    "* **Mask R-CNN** – dodatkowo potrafi segmentować piksele.\n",
    "* **YOLO (You Only Look Once)** – bardzo szybki model, popularny w praktyce.\n",
    "* **RetinaNet** – balansuje dokładność i szybkość.\n",
    "\n",
    "* **Modele do segmentacji obrazów**:\n",
    "\n",
    "* **U-Net** – świetny w medycynie, np. do zaznaczania guzów na RTG.\n",
    "* **DeepLab** – segmentacja w wysokiej jakości.\n",
    "* **Mask R-CNN** – także w tej kategorii.\n",
    "\n",
    "* **Transformery w wizji** (inspiracja z NLP – języka):\n",
    "\n",
    "* **ViT (Vision Transformer)** – traktuje obraz jak zbiór „kawałków” i analizuje je podobnie jak tekst.\n",
    "* **Swin Transformer** – lepiej radzi sobie z dużymi obrazami.\n",
    "* **SAM (Segment Anything Model)** – model od Meta, który potrafi segmentować dowolne obiekty z obrazu.\n",
    "\n",
    "* **Modele generatywne**:\n",
    "\n",
    "* **GAN (Generative Adversarial Network)** – sieci „rywalizujące”, które tworzą realistyczne obrazy.\n",
    "* **VAE (Variational Autoencoder)** – model kompresujący i odtwarzający obrazy.\n",
    "* **Diffusion Models (np. Stable Diffusion)** – najnowsze, bardzo mocne modele generujące obrazy na podstawie opisu tekstowego.\n",
    "\n",
    "---\n",
    "\n",
    "#### Kiedy nie używać Deep Learningu?\n",
    "\n",
    "Nie zawsze warto sięgać po skomplikowane sieci neuronowe.\n",
    "Jeśli zadanie jest proste i masz mało danych:\n",
    "\n",
    "* np. chcesz policzyć średnicę ziaren ryżu na zdjęciu,\n",
    "* albo odróżnić jabłko od pomarańczy na podstawie kilku cech geometrycznych (masa, kolor).\n",
    "\n",
    "Wtedy lepiej sprawdzi się klasyczne ML:\n",
    "\n",
    "* **SVM (Support Vector Machine)** – metoda klasyfikacji.\n",
    "* **Drzewa decyzyjne, Gradient Boosting (GBM, XGBoost, LightGBM)**.\n",
    "* Do tego **ręcznie wyciągnięte cechy** (np. kolor średni, kształt, tekstura).\n",
    "\n",
    "| Problem | Dane wejściowe | Typowe modele |\n",
    "| --- | --- | --- |\n",
    "| Klasyfikacja obrazów | Zdjęcia | CNN, Vision Transformer |\n",
    "| Detekcja obiektów | Obrazy z bbox | Faster R-CNN, YOLO |\n",
    "| Segmentacja | Obrazy z maskami | U-Net, DeepLab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4737bef58aa44e3e",
   "metadata": {},
   "source": [
    "### Przetwarzanie języka naturalnego (NLP)\n",
    "\n",
    "**Przetwarzanie języka naturalnego (ang. Natural Language Processing, NLP)** to dziedzina sztucznej inteligencji, której celem jest to, aby komputery potrafiły rozumieć, analizować i generować język ludzki – zarówno w mowie, jak i w piśmie. Dzięki NLP możliwe jest np. automatyczne tłumaczenie, wykrywanie spamu w mailach czy prowadzenie rozmowy z chatbotem.\n",
    "\n",
    "---\n",
    "\n",
    "#### Typowe zadania:\n",
    "\n",
    "* **Klasyfikacja tekstu** – przypisanie tekstu do jednej z kategorii.\n",
    "  Przykłady: wykrywanie spamu w wiadomościach e-mail, analiza sentymentu recenzji filmowych (pozytywna/negatywna), kategoryzacja artykułów według tematyki.\n",
    "\n",
    "* **NER (Named Entity Recognition) / Tagowanie sekwencji** – rozpoznawanie i oznaczanie nazw własnych w tekście.\n",
    "  Np. w zdaniu „Jan Kowalski mieszka w Warszawie” model wykrywa, że *Jan Kowalski* to osoba, a *Warszawa* to miejsce.\n",
    "\n",
    "* **Tłumaczenie maszynowe** – automatyczne tłumaczenie tekstu z jednego języka na inny (np. Google Translate).\n",
    "\n",
    "* **Streszczanie i parafrazy** – generowanie krótszej wersji tekstu lub wyrażanie tej samej treści innymi słowami.\n",
    "\n",
    "* **Odpowiadanie na pytania (QA, Question Answering)** – systemy, które potrafią znaleźć odpowiedź na pytanie w tekście.\n",
    "  Rozwinięciem tego podejścia jest **RAG (Retrieval-Augmented Generation)**, gdzie model nie tylko odpowiada, ale także korzysta z zewnętrznej bazy wiedzy, aby podać precyzyjne informacje.\n",
    "\n",
    "* **Chatboty i asystenci (LLM, Large Language Models)** – systemy prowadzące rozmowy z użytkownikiem, udzielające informacji czy wykonujące zadania.\n",
    "\n",
    "* **Analiza dokumentów** – szczególnie ważne przy dużych i skomplikowanych plikach (kontrakty prawne, raporty, faktury). Modele NLP potrafią wydobywać kluczowe informacje, streszczać długie fragmenty lub odpowiadać na pytania dotyczące treści dokumentu.\n",
    "\n",
    "---\n",
    "\n",
    "#### Co się sprawdza:\n",
    "\n",
    "* **Transformery / LLM (Large Language Models)** – to obecnie standard w NLP.\n",
    "  Modele takie jak **BERT, RoBERTa, DeBERTa** świetnie nadają się do klasyfikacji tekstu, analizy sentymentu, NER i innych zadań wymagających „rozumienia” treści.\n",
    "\n",
    "* **Generatywne modele językowe (LLM)** – np. **GPT, LLaMA, Mistral, T5**.\n",
    "  Są używane do generacji tekstu, odpowiedzi na pytania, tworzenia streszczeń czy tłumaczeń. Dzięki nim powstały współczesne chatboty i asystenci AI.\n",
    "\n",
    "* **Klasyczne metody NLP** – w przypadku mniejszych zbiorów danych nadal skuteczne są prostsze podejścia:\n",
    "\n",
    "  * **Logistyczna regresja (logreg)** czy **SVM (Support Vector Machine)**,\n",
    "  * reprezentacje tekstu oparte na **TF-IDF** (częstość słów z uwzględnieniem ich unikalności) lub **n-gramy** (ciągi kolejnych słów).\n",
    "\n",
    "---\n",
    "\n",
    "#### Kiedy nie używać Deep Learningu?\n",
    "\n",
    "Nie zawsze opłaca się sięgać po duże modele językowe.\n",
    "\n",
    "* Jeśli mamy **bardzo mało danych** albo problem jest prosty, lepiej wykorzystać reguły oparte na **wyrażeniach regularnych (regex)** czy proste heurystyki.\n",
    "  Przykład: wykrywanie numerów PESEL w tekście – zamiast trenować model, wystarczy odpowiedni regex.\n",
    "\n",
    "---\n",
    "\n",
    "| Problem | Dane wejściowe | Typowe modele |\n",
    "| --- | --- | --- |\n",
    "| Klasyfikacja tekstu | Dokumenty, wiadomości | BERT, logistyczna regresja + TF-IDF |\n",
    "| QA / chatboty | Pytania, dialog | GPT, T5 |\n",
    "| Tłumaczenie | Parowane zdania | Transformer, seq2seq |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee174545d76485",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Mowa, audio, sygnały\n",
    "\n",
    "Przetwarzanie mowy i sygnałów dźwiękowych to dziedzina sztucznej inteligencji, która zajmuje się **rozumieniem, analizą i generowaniem dźwięku**. W odróżnieniu od NLP, gdzie punktem wyjścia jest tekst, tutaj bazą są **sygnały akustyczne** (fale dźwiękowe) lub inne dane sekwencyjne (np. sygnały biomedyczne).\n",
    "\n",
    "#### Typowe zadania:\n",
    "\n",
    "* **Rozpoznawanie mowy (ASR, Automatic Speech Recognition)** – zamiana dźwięku na tekst.\n",
    "  Przykład: dyktujesz wiadomość, a system zapisuje ją jako tekst.\n",
    "\n",
    "* **Synteza mowy (TTS, Text-to-Speech)** – odwrotny proces: zamiana tekstu na naturalnie brzmiącą mowę.\n",
    "  Przykład: głosowe odpowiedzi w asystentach takich jak Siri czy Google Assistant.\n",
    "\n",
    "* **Klasyfikacja dźwięków** – rozpoznawanie i kategoryzowanie odgłosów.\n",
    "  Przykłady: identyfikacja gatunków ptaków po śpiewie, wykrywanie odgłosów awarii maszyn, rozpoznawanie odgłosów kroków czy strzałów.\n",
    "\n",
    "* **Biomedyczne sygnały (EEG/ECG)** – analiza fal mózgowych, pracy serca czy innych sygnałów z organizmu w celu diagnozy i monitorowania stanu zdrowia.\n",
    "\n",
    "* **Analiza wibracji i sygnałów technicznych** – np. monitorowanie maszyn przemysłowych w celu wykrywania anomalii i przewidywania awarii.\n",
    "\n",
    "---\n",
    "\n",
    "#### Co się sprawdza:\n",
    "\n",
    "* **Modele sekwencyjne i transformerowe** – dobrze radzą sobie z długimi sygnałami audio.\n",
    "\n",
    "  * **wav2vec 2.0** – model od Facebook AI, który nauczył się reprezentować mowę bez potrzeby ręcznej transkrypcji dużych zbiorów.\n",
    "  * **Whisper** (OpenAI) – uniwersalny model do rozpoznawania mowy w wielu językach.\n",
    "  * **Conformer** – architektura łącząca transformatory i konwolucje, świetna do ASR.\n",
    "\n",
    "* **CNN (Convolutional Neural Networks) / TDNN (Time-Delay Neural Networks)** – dobre przy analizie krótszych fragmentów dźwięku, np. przy klasyfikacji krótkich odgłosów.\n",
    "\n",
    "* **Augmentacje audio** – techniki zwiększania różnorodności danych, aby modele były bardziej odporne na szumy.\n",
    "\n",
    "  * **SpecAugment** – metoda modyfikacji spektrogramów (graficznej reprezentacji dźwięku), np. poprzez zakrywanie fragmentów.\n",
    "\n",
    "| Problem | Dane wejściowe | Typowe modele |\n",
    "| --- | --- | --- |\n",
    "| Rozpoznawanie mowy | Pliki audio | Wav2Vec2, Whisper |\n",
    "| Synteza mowy | Tekst | Tacotron, VITS |\n",
    "| Klasyfikacja dźwięków | Spektrogramy | CNN, CRNN |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5672bb-3cf7-48f7-85e2-1c5c8b4d6dc6",
   "metadata": {},
   "source": [
    "### Szeregi czasowe i prognozowanie\n",
    "\n",
    "**Szeregi czasowe** to dane uporządkowane w czasie. Mogą to być np. ceny akcji z kolejnych dni, liczba zamówień co godzinę, zużycie prądu w ciągu tygodnia czy odczyty z czujników w maszynach przemysłowych.\n",
    "**Prognozowanie szeregów czasowych** polega na przewidywaniu przyszłych wartości oraz na wykrywaniu nietypowych zdarzeń (anomalii).\n",
    "\n",
    "Wyobraź sobie firmę energetyczną, która chce wiedzieć, ile prądu zużyją mieszkańcy miasta jutro wieczorem – to właśnie klasyczne zadanie prognozowania szeregów czasowych.\n",
    "\n",
    "---\n",
    "\n",
    "#### Typowe zadania:\n",
    "\n",
    "* **Prognoza popytu i sprzedaży** – np. ile produktów sprzeda się w przyszłym tygodniu w sklepie internetowym.\n",
    "* **Prognoza obciążenia i zapotrzebowania** – np. ile energii elektrycznej będzie potrzebne w danym regionie o konkretnej godzinie.\n",
    "* **Prognoza cen** – np. przewidywanie cen akcji, kryptowalut czy surowców.\n",
    "* **Monitorowanie sensorów i maszyn** – przewidywanie przyszłych odczytów czujników w systemach przemysłowych.\n",
    "* **Detekcja anomalii** – wychwytywanie nietypowych zdarzeń, np. nagłego wzrostu temperatury w silniku czy spadku napięcia w sieci.\n",
    "* **Predykcja awarii** – przewidywanie, kiedy maszyna lub system może ulec uszkodzeniu, aby wcześniej zaplanować konserwację.\n",
    "\n",
    "---\n",
    "\n",
    "#### Co się sprawdza (najpopularniejsze metody i modele):\n",
    "\n",
    "* **Modele klasyczne** – proste i szybkie, dobre jako punkt odniesienia (baseline):\n",
    "\n",
    "    * **ARIMA (AutoRegressive Integrated Moving Average)** – statystyczny model prognozowania uwzględniający zależności w czasie.\n",
    "    * **Prophet** (Meta/Facebook) – łatwy w użyciu, dobrze radzi sobie z trendami i sezonowością (np. dzienną, tygodniową, roczną).\n",
    "\n",
    "* **Modele oparte na cechach czasowych** – gdy z daty wyciągamy dodatkowe informacje (dzień tygodnia, pora roku, święta) i trenujemy klasyczne modele ML:\n",
    "\n",
    "* **XGBoost, LightGBM, CatBoost** – algorytmy gradient boosting, które świetnie sprawdzają się w zastosowaniach biznesowych i często dominują w konkursach.\n",
    "\n",
    "* **Deep Learning (DL)** – szczególnie dla dużych i złożonych danych:\n",
    "\n",
    " * **LSTM (Long Short-Term Memory)** – sieci rekurencyjne, które dobrze „pamiętają” dłuższe zależności w czasie.\n",
    " * **GRU (Gated Recurrent Unit)** – prostsza i szybsza wersja LSTM.\n",
    " * **Temporal Convolutional Networks (TCN)** – sieci konwolucyjne przetwarzające dane sekwencyjne.\n",
    " * **Transformers** – coraz częściej stosowane w szeregach czasowych, zwłaszcza gdy trzeba analizować **wiele serii jednocześnie** i uchwycić **bardzo długie zależności w czasie**.\n",
    "\n",
    "---\n",
    "#### Kiedy nie używać Deep Learningu?\n",
    "\n",
    "* Jeśli masz **mało danych** albo prognozujesz krótkie serie, klasyczne modele (ARIMA, Prophet) i boosting zwykle są wystarczające.\n",
    "* Jeśli ważna jest **interpretowalność** modelu – łatwiej wyjaśnić prognozę z ARIMA czy LightGBM niż z LSTM czy Transformerów.\n",
    "* Deep learning wymaga dużo mocy obliczeniowej i danych – jeśli tego brakuje, proste modele mogą być skuteczniejsze i tańsze.\n",
    "\n",
    "| Problem | Dane | Typowe modele |\n",
    "| --- | --- | --- |\n",
    "| Prognoza obrotów | Historia sprzedaży | ARIMA, LSTM, Prophet |\n",
    "| Wykrywanie anomalii | Czujniki IoT | Autoencoder, Isolation Forest |\n",
    "| Planowanie zapasów | Zamówienia dzienne | Gradient Boosting, N-BEATS |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b430b6a23e1e4338",
   "metadata": {},
   "source": [
    "### Dane tabelaryczne (Tabular Data)\n",
    "\n",
    "**Dane tabelaryczne** to najczęściej spotykany format w biznesie – w arkuszach Excel, bazach danych czy systemach CRM.\n",
    "Każdy wiersz odpowiada obiektowi (np. klientowi, transakcji, produktowi), a kolumny to jego cechy (wiek, kraj, cena, liczba zakupów).\n",
    "\n",
    "Wyobraź sobie tabelę klientów sklepu internetowego:\n",
    "dla każdego klienta mamy **wiek, płeć, liczbę zakupów i średnią wartość koszyka**. Na tej podstawie możemy próbować przewidzieć, czy klient zrobi kolejne zakupy lub jak duże będzie miał wydatki.\n",
    "\n",
    "---\n",
    "\n",
    "#### Typowe zadania:\n",
    "\n",
    "* **Klasyfikacja klientów (CRM, churn prediction)** – np. czy klient odejdzie w najbliższym miesiącu.\n",
    "* **Ocena ryzyka kredytowego** – czy klient spłaci kredyt.\n",
    "* **Prognoza wartości** – np. cena nieruchomości na podstawie jej cech.\n",
    "* **Detekcja oszustw (fraud detection)** – wykrywanie podejrzanych transakcji.\n",
    "* **Analizy scoringowe** – przypisywanie punktów ryzyka, jakości lub wartości.\n",
    "\n",
    "---\n",
    "\n",
    "#### Co się sprawdza (najpopularniejsze metody i modele):\n",
    "\n",
    "* **Gradient boosting na drzewach decyzyjnych** – złoty standard dla tabular:\n",
    "\n",
    "   * **XGBoost** – bardzo popularny, wydajny model.\n",
    "   * **LightGBM** – szybszy i bardziej pamięciooszczędny.\n",
    "   * **CatBoost** – dobrze radzi sobie z danymi kategorycznymi.\n",
    "\n",
    "Te modele często wygrywają konkursy Kaggle i w praktyce są **state-of-the-art (SOTA)** dla danych tabelarycznych.\n",
    "\n",
    "* **Uczenie głębokie (Deep Learning)** – ma sens w pewnych warunkach:\n",
    "\n",
    "    * **TabNet, TabTransformer** – architektury specjalnie zaprojektowane dla tabular.\n",
    "    * **Sieci w pełni połączone (MLP)** – dla bardzo dużych zbiorów danych.\n",
    "    * Szczególnie przydatne, gdy łączymy różne typy danych: np. **tekst + obrazy + liczby**.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "\n",
    "**Czy MLP mają sens dla danych tabelarycznych?**\n",
    "\n",
    "👉 Ogólnie: **nie zawsze** – w praktyce klasyczne modele oparte na drzewach (XGBoost, LightGBM, CatBoost) biją MLP na głowę przy małych i średnich zbiorach tabularnych. Ale są sytuacje, gdzie sieci neuronowe **zaczynają wygrywać**.\n",
    "\n",
    "---\n",
    " ✅ Kiedy MLP mogą działać dobrze?\n",
    "\n",
    "1. **Bardzo duże zbiory danych** (miliony rekordów)\n",
    "\n",
    "   * Boostingi potrafią się wtedy „nasycać”, a sieci neuronowe dzięki ogromnej liczbie parametrów potrafią lepiej uogólniać.\n",
    "\n",
    "2. **Wysoka liczba cech i złożone zależności**\n",
    "\n",
    "   * MLP potrafi uchwycić interakcje nieliniowe pomiędzy cechami, których boosting nie zawsze wychwyci wprost.\n",
    "\n",
    "3. **Multimodalne dane** (łączenie różnych źródeł)\n",
    "\n",
    "   * Jeśli oprócz tabeli masz też **teksty, obrazy czy sygnały czasowe**, MLP (lub inne sieci głębokie) mogą łączyć te różne reprezentacje.\n",
    "\n",
    "4. **End-to-end learning**\n",
    "\n",
    "   * Możesz trenować model bezpośrednio z danymi surowymi (np. embeddings kategorii + liczby), bez czasochłonnego feature engineering.\n",
    "\n",
    "5. **Dostęp do GPU**\n",
    "\n",
    "   * Przy dużych zbiorach MLP skalują się lepiej na GPU niż boosting na CPU.\n",
    "\n",
    "---\n",
    "\n",
    "❌ Kiedy boostingi są lepsze niż MLP?\n",
    "\n",
    "* **Małe i średnie zbiory (np. <100k rekordów)** – boosting jest dużo stabilniejszy.\n",
    "* **Dane głównie kategoryczne/liczbowe** – CatBoost i LightGBM radzą sobie znakomicie bez dużych nakładów na tuning.\n",
    "* **Konkursy Kaggle/tabular benchmarks** – tam drzewiaste modele zwykle wygrywają.\n",
    "\n",
    "---\n",
    "\n",
    "Podsumowanie\n",
    "\n",
    "* **Domyślnie → boosting (XGBoost, LightGBM, CatBoost).**\n",
    "* **MLP / Deep Learning → sens, gdy mamy:**\n",
    "\n",
    "  * *bardzo duże dane*,\n",
    "  * *różne typy danych (multimodalne)*,\n",
    "  * *dużą moc obliczeniową*.\n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Kiedy nie używać Deep Learningu?\n",
    "\n",
    "Deep learning nie zawsze jest najlepszy:\n",
    "\n",
    "* Przy **małych i średnich zbiorach danych** – łatwo wtedy o przeuczenie, a boosting na drzewach działa lepiej i szybciej.\n",
    "* Gdy cechy są dobrze opisane i uporządkowane – klasyczne modele ML są prostsze i bardziej interpretable.\n",
    "\n",
    "Lepsze będą wtedy:\n",
    "\n",
    "* **Drzewa decyzyjne** – łatwe do interpretacji.\n",
    "* **Random Forest** – dobry kompromis między skutecznością a prostotą.\n",
    "* **Logistic Regression, SVM** – skuteczne dla prostych klasyfikacji.\n",
    "\n",
    "| Problem | Dane | Typowe modele |\n",
    "| --- | --- | --- |\n",
    "| Scoring kredytowy | Wartości liczbowe/kategoryczne | XGBoost, CatBoost |\n",
    "| Churn | Dane klientów | LightGBM, sieć tabularna |\n",
    "| Wycenianie polis | Historia roszczeń | GLM, GBM |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27cc8b1df1509a9",
   "metadata": {},
   "source": [
    "### Rekomendacje i personalizacja\n",
    "\n",
    "**Systemy rekomendacyjne** to rozwiązania, które pomagają użytkownikowi znaleźć najbardziej interesujące treści lub produkty.\n",
    "Wyobraź sobie sklep internetowy: zamiast przeglądać tysiące artykułów, widzisz listę „Produkty dla Ciebie” – to właśnie efekt działania systemu rekomendacyjnego.\n",
    "\n",
    "Podobnie na platformach streamingowych (np. filmy, muzyka) czy w mediach społecznościowych – rekomendacje decydują, jakie treści pojawią się na Twojej stronie głównej.\n",
    "\n",
    "---\n",
    "\n",
    "#### Typowe zadania:\n",
    "\n",
    "* **Ranking produktów lub treści** – układanie listy w kolejności dopasowania do użytkownika (np. sortowanie filmów w serwisie streamingowym).\n",
    "* **Predykcja klikalności (CTR prediction)** – przewidywanie, czy użytkownik kliknie w reklamę lub artykuł.\n",
    "* **„Użytkownicy podobni do…”** – znajdowanie grup osób o zbliżonych preferencjach.\n",
    "* **Rekomendacje spersonalizowane** – np. dobór playlist muzycznych, produktów w koszyku czy artykułów w aplikacji newsowej.\n",
    "\n",
    "---\n",
    "\n",
    "#### Co się sprawdza (najpopularniejsze metody i modele):\n",
    "\n",
    "* **Metody klasyczne**:\n",
    "\n",
    "    * **Collaborative filtering (ALS – Alternating Least Squares)** – bazuje na macierzy użytkownicy–produkty, dobrze działa, gdy mamy dużo interakcji (ocen, kliknięć).\n",
    "\n",
    "* **Deep Learning**:\n",
    "\n",
    "    * **Wide & Deep** – łączy modele liniowe (wide) z głębokimi (deep), balansując między dopasowaniem a generalizacją.\n",
    "    * **DeepFM** – rozszerza wide&deep, dobrze znajduje interakcje między cechami.\n",
    "    * **Transformers dla sekwencji kliknięć** – analizują historię działań użytkownika jak sekwencję zdarzeń (podobnie jak zdania w NLP).\n",
    "\n",
    "* **Praktyczne elementy ekosystemu rekomendacji**:\n",
    "\n",
    "    * **Feature stores** – centralne repozytoria cech, żeby system działał spójnie online i offline.\n",
    "    * **Duże zbiory logów** – kluczowe do trenowania, bo interakcje użytkowników generują olbrzymie ilości danych.\n",
    "    * **Negatywne próbkowanie** – technika uczenia, w której model dostaje przykłady zarówno kliknięte, jak i niekliknięte, żeby nauczyć się rozróżniać.\n",
    "    * **A/B testy** – absolutna podstawa przy wdrażaniu systemów rekomendacyjnych, pozwalają sprawdzić, czy nowy model faktycznie poprawia zaangażowanie użytkowników.\n",
    "\n",
    "---\n",
    "\n",
    "#### Kiedy nie używać Deep Learningu?\n",
    "\n",
    "* Jeśli baza interakcji jest **mała** – proste metody (np. collaborative filtering) sprawdzą się lepiej.\n",
    "* Gdy potrzebujesz **prostego i szybkiego baseline’u** – często wystarczy macierz użytkownicy–produkty lub model liniowy.\n",
    "* Deep learning ma sens dopiero wtedy, gdy masz **bardzo dużo danych** (miliony użytkowników, miliardy kliknięć).\n",
    "\n",
    "| Problem | Dane | Typowe modele |\n",
    "| --- | --- | --- |\n",
    "| Filmy dla użytkownika | Oceny, kliknięcia | Matrix Factorization, Two-Tower |\n",
    "| Produkty | Historia zakupów | LightFM, DeepFM |\n",
    "| Kontent | Logi odsłon | Transformers, seq2seq |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b85597e7493eeb",
   "metadata": {},
   "source": [
    "### Modele generatywne\n",
    "\n",
    "**Modele generatywne** to algorytmy sztucznej inteligencji, które potrafią **tworzyć nowe dane podobne do tych, na których były uczone**.\n",
    "Mogą generować tekst, obrazy, muzykę, a nawet wideo czy dane syntetyczne do testów.\n",
    "\n",
    "Wyobraź sobie, że prosisz komputer: *„Napisz wiersz w stylu Mickiewicza”* albo *„Stwórz obraz psa w czapce astronauty na Księżycu”*. Dzięki modelom generatywnym to jest możliwe.\n",
    "\n",
    "---\n",
    "\n",
    "#### Typowe zadania:\n",
    "\n",
    "* **Generowanie tekstu** – np. czaty, artykuły, streszczenia (LLM).\n",
    "* **Generowanie obrazów** – np. obrazy ze Stable Diffusion, DALL·E czy MidJourney.\n",
    "* **Generowanie muzyki i wideo** – modele komponujące utwory lub tworzące krótkie klipy filmowe.\n",
    "* **Tworzenie danych syntetycznych** – np. uzupełnianie brakujących danych w tabelach albo wzbogacanie zbiorów treningowych.\n",
    "* **Uzupełnianie braków (inpainting)** – „domalowywanie” fragmentów zdjęcia.\n",
    "* **Style transfer** – np. zamiana zdjęcia w obraz olejny albo nadanie tekstowi stylu poetyckiego.\n",
    "* **Super-resolution** – zwiększanie rozdzielczości obrazu.\n",
    "\n",
    "---\n",
    "\n",
    "#### Co się sprawdza (najpopularniejsze metody i modele):\n",
    "\n",
    "* **Modele dyfuzyjne (Diffusion Models)** – obecnie najpotężniejsze do obrazów i multimediów.\n",
    "\n",
    "    * **Stable Diffusion** – generowanie obrazów na podstawie opisu tekstowego.\n",
    "    * Działają przez stopniowe usuwanie szumu i odtwarzanie struktury obrazu.\n",
    "\n",
    "* **GAN (Generative Adversarial Network)** – sieci rywalizujące: generator tworzy dane, a dyskryminator ocenia, czy są prawdziwe.\n",
    "\n",
    "    * Świetne do tworzenia realistycznych obrazów, wideo czy deepfake’ów.\n",
    "\n",
    "* **VAE (Variational Autoencoder)** – kompresuje dane do ukrytej reprezentacji i odtwarza je, co pozwala generować nowe warianty.\n",
    "\n",
    "* **Modele autoregresyjne** – szczególnie w tekście:\n",
    "\n",
    "    * **LLM (Large Language Models)** – np. GPT, LLaMA, Mistral, Gemini.\n",
    "    * Generują sekwencję token po tokenie, przewidując kolejne słowo.\n",
    "\n",
    "---\n",
    "\n",
    "#### Kiedy uważać?\n",
    "\n",
    "Modele generatywne są bardzo potężne, ale:\n",
    "\n",
    "* Mogą **halucynować** – wymyślać fakty, które brzmią wiarygodnie, ale są fałszywe.\n",
    "* Mogą tworzyć **treści wrażliwe lub niepożądane** – dlatego wymagają filtrów i kontroli.\n",
    "* Ich **ewaluacja** powinna być dopasowana do zadania – nie wystarczy sprawdzić dokładności, trzeba ocenić jakość, spójność, zgodność z kontekstem i bezpieczeństwo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a615cae987e4a6b",
   "metadata": {},
   "source": [
    "### Uczenie ze wzmocnieniem (RL)\n",
    "\n",
    "**Uczenie ze wzmocnieniem (ang. Reinforcement Learning, RL)** to podejście w sztucznej inteligencji, w którym agent (program/algorytm) **uczy się poprzez interakcję ze środowiskiem**. Zamiast mieć gotowe poprawne odpowiedzi (jak w klasyfikacji czy regresji), agent próbuje różnych działań i na podstawie **nagrody (reward)** lub **kary (penalty)** stopniowo odkrywa, które strategie są najlepsze.\n",
    "\n",
    "Można to porównać do nauki jazdy na rowerze: nikt nie mówi ci dokładnie, jak poruszać nogami i balansować ciałem. Uczysz się sam, próbując, popełniając błędy i stopniowo dostajesz „nagrody” (utrzymujesz równowagę, jedziesz dalej).\n",
    "\n",
    "---\n",
    "\n",
    "#### Typowe zadania:\n",
    "\n",
    "* **Sterowanie i gry** – np. nauka grania w szachy, Go, Atari, StarCraft. Agent próbuje różnych ruchów, a nagrodą jest wygrana partia.\n",
    "\n",
    "* **Robotyka** – uczenie robota chodzenia, chwytania przedmiotów czy poruszania się po pomieszczeniu.\n",
    "\n",
    "* **Optymalizacja decyzji** – np. systemy rekomendacyjne, które uczą się, jakie produkty polecać, żeby zwiększyć sprzedaż.\n",
    "\n",
    "* **Autonomiczne pojazdy** – samochód uczy się prowadzić, testując różne działania i obserwując efekty (utrzymanie pasa, unikanie kolizji).\n",
    "\n",
    "* **Zarządzanie zasobami** – np. w energetyce czy IT: RL może optymalizować zużycie energii, alokację serwerów albo przepustowość sieci.\n",
    "\n",
    "---\n",
    "\n",
    "#### Kluczowe pojęcia:\n",
    "\n",
    "* **Agent** – „uczeń”, który podejmuje decyzje.\n",
    "* **Środowisko (environment)** – świat, w którym działa agent.\n",
    "* **Stan (state)** – opis aktualnej sytuacji.\n",
    "* **Akcja (action)** – ruch, który agent może wykonać.\n",
    "* **Nagroda (reward)** – informacja zwrotna, czy dana akcja była dobra czy zła.\n",
    "* **Polityka (policy)** – strategia, czyli sposób wybierania akcji w danych stanach.\n",
    "* **Wartość (value)** – przewidywana suma nagród, jakie agent otrzyma w przyszłości.\n",
    "\n",
    "---\n",
    "\n",
    "#### Co się sprawdza:\n",
    "\n",
    "* **Q-learning** – klasyczna metoda, w której agent uczy się przypisywać wartości do par (stan, akcja).\n",
    "* **Deep Q-Networks (DQN)** – połączenie Q-learningu z sieciami neuronowymi, co pozwala rozwiązywać bardziej złożone problemy (np. gry Atari).\n",
    "* **Policy Gradient** – metody, w których agent bezpośrednio uczy się polityki (strategii).\n",
    "* **Actor-Critic** – połączenie podejścia wartości (critic) i polityki (actor), często stosowane w praktyce.\n",
    "* **Zaawansowane algorytmy** – np. PPO (Proximal Policy Optimization), A3C (Asynchronous Advantage Actor-Critic), które świetnie działają w skomplikowanych środowiskach.\n",
    "\n",
    "---\n",
    "\n",
    "#### Kiedy nie używać RL?\n",
    "\n",
    "Uczenie ze wzmocnieniem jest bardzo potężne, ale też trudne:\n",
    "\n",
    "* wymaga **dużej liczby prób** (często milionów kroków interakcji ze środowiskiem),\n",
    "* może być **niestabilne i trudne do dostrojenia**,\n",
    "* bywa nieopłacalne, jeśli można zastosować prostsze podejścia (np. klasyfikację, regresję czy reguły).\n",
    "\n",
    "Przykład: jeśli chcemy przewidzieć, czy klient kupi produkt, prościej zastosować klasyfikację niż uczyć agenta RL, który testuje różne strategie marketingowe od zera.\n",
    "\n",
    "| Środowisko | Cel | Przykłady |\n",
    "| --- | --- | --- |\n",
    "| Gry | Maks. wynik | Atari, AlphaGo |\n",
    "| Robotyka | Sterowanie ruchem | roboty manipulacyjne |\n",
    "| Optymalizacja | Minimalizacja kosztu | systemy logistyczne |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b93264e95abff",
   "metadata": {},
   "source": [
    "### Grafy i sieci (Graph Neural Networks, GNN)\n",
    "\n",
    "**Grafy** to struktury danych, w których elementy (węzły) połączone są relacjami (krawędziami).\n",
    "Przykłady grafów to **sieci społeczne** (osoby i ich znajomości), **sieci finansowe** (transakcje między firmami), czy **struktury chemiczne** (atomy i wiązania w molekułach).\n",
    "\n",
    "**Graph Neural Networks (GNN)** pozwalają modelom uczyć się nie tylko na podstawie cech poszczególnych obiektów, ale także na podstawie ich **relacji i kontekstu w całej sieci**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Typowe zadania:\n",
    "\n",
    "* **Detekcja nadużyć i powiązań** – np. wykrywanie fraudów w sieciach płatniczych dzięki analizie relacji między kontami.\n",
    "* **Rekomendacje oparte na grafach** – np. „użytkownicy podobni do Ciebie kupili…” z wykorzystaniem powiązań między produktami i użytkownikami.\n",
    "* **Chemia i bioinformatyka** – analiza molekuł jako grafów atomów, przewidywanie właściwości leków.\n",
    "* **Analiza sieci społecznych** – wykrywanie społeczności, influencerów czy przewidywanie powstania nowych połączeń (link prediction).\n",
    "\n",
    "---\n",
    "\n",
    "#### Co się sprawdza (najpopularniejsze metody i modele):\n",
    "\n",
    "🔹 **Graph Neural Networks (GNN)** – sieci neuronowe specjalnie zaprojektowane do pracy na grafach:\n",
    "\n",
    "* **GCN (Graph Convolutional Network)** – przenosi ideę konwolucji na strukturę grafu.\n",
    "* **GraphSAGE** – uczy się reprezentacji węzłów na podstawie sąsiadów, skalowalny do dużych grafów.\n",
    "* **GAT (Graph Attention Network)** – wykorzystuje mechanizm uwagi (attention), żeby różnie ważyć znaczenie sąsiadów.\n",
    "\n",
    "🔹 **Metody osadzania (embedding)** – tworzą wektorowe reprezentacje węzłów lub całych grafów, które można używać w klasycznych modelach ML:\n",
    "\n",
    "* **DeepWalk** – uczy się embeddingów węzłów na podstawie losowych przejść po grafie.\n",
    "* **node2vec** – rozszerzenie DeepWalk, które lepiej kontroluje balans między eksploracją lokalną i globalną w grafie.\n",
    "\n",
    "---\n",
    "\n",
    "#### Kiedy nie używać GNN?\n",
    "\n",
    "* Jeśli dane mają **prostą tabelaryczną strukturę**, a relacje nie odgrywają dużej roli – lepiej sprawdzą się klasyczne modele ML.\n",
    "* GNN wymagają **dużych grafów** i odpowiedniej mocy obliczeniowej – dla małych problemów mogą być przesadą.\n",
    "* Modele osadzania (node2vec, DeepWalk) często wystarczą jako prostsze i szybsze podejście.\n",
    "\n",
    "| Problem | Dane | Modele |\n",
    "| --- | --- | --- |\n",
    "| Rekomendacje oparte na grafie | Graf relacji użytkownik–produkt | GraphSAGE, GAT |\n",
    "| Analiza ryzyka | Graf transakcji finansowych | GCN, GNN z uwagą |\n",
    "| Chemia | Molekuły jako grafy | Message Passing Neural Network |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd67576e0a8133",
   "metadata": {},
   "source": [
    "### Zastosowania branżowe (przykłady)\n",
    "\n",
    "#### Medycyna\n",
    "\n",
    "* **Wsparcie diagnostyki obrazowej** – wykrywanie zmian na zdjęciach RTG, rezonansach czy tomografii.\n",
    "  📌 *Case study:* Szpital wdrożył system analizy RTG klatki piersiowej. Model wykrywa potencjalne zmiany (np. guz, zapalenie płuc) i oznacza je dla radiologa. Lekarz podejmuje decyzję szybciej, bo AI wskazuje obszary wymagające uwagi.\n",
    "\n",
    "* **Triaż pacjentów** – automatyczne przypisywanie priorytetów w izbie przyjęć.\n",
    "  📌 *Case study:* W izbie przyjęć chatbot zbiera od pacjenta podstawowe informacje o objawach. Model ML szacuje ryzyko i decyduje, czy pacjent powinien być przyjęty natychmiast, czy może poczekać.\n",
    "\n",
    "* **Transkrypcja i podsumowania wizyt** – automatyczne notatki z rozmów lekarz–pacjent.\n",
    "  📌 *Case study:* Lekarz prowadzi rozmowę, a system ASR + NLP generuje streszczenie: objawy, diagnoza, zalecenia. Lekarz jedynie zatwierdza dokumentację.\n",
    "\n",
    "* **Przewidywanie readmisji** – szacowanie ryzyka powrotu pacjenta do szpitala.\n",
    "  📌 *Case study:* Model analizuje historię chorób, wyniki badań i zalecenia przy wypisie. Pacjenci z wysokim ryzykiem dostają dodatkowe wsparcie i częstsze kontrole.\n",
    "\n",
    "---\n",
    "\n",
    "#### Przemysł / IoT\n",
    "\n",
    "* **Predykcja awarii** – monitorowanie maszyn i prognozowanie usterek.\n",
    "  📌 *Case study:* Fabryka produkująca turbiny instaluje sensory IoT. Model analizuje wibracje i temperaturę, przewidując zużycie łożysk. Dzięki temu serwis odbywa się przed awarią.\n",
    "\n",
    "* **Kontrola jakości wizyjna** – automatyczne wykrywanie defektów na liniach produkcyjnych.\n",
    "  📌 *Case study:* Kamera na linii montażowej rejestruje każdy produkt. System CV wykrywa rysy i defekty w czasie rzeczywistym, zatrzymując wadliwy element przed dalszą obróbką.\n",
    "\n",
    "* **Optymalizacja energii** – inteligentne sterowanie urządzeniami i procesami.\n",
    "  📌 *Case study:* Zakład przemysłowy używa modeli prognozujących zapotrzebowanie na energię. System wyłącza część maszyn w godzinach szczytu, obniżając koszty.\n",
    "\n",
    "---\n",
    "\n",
    "#### Finanse\n",
    "\n",
    "* **Scoring kredytowy** – ocena wiarygodności kredytowej klientów.\n",
    "  📌 *Case study:* Bank korzysta z gradient boosting (XGBoost) do analizy danych klientów. Klienci z wysokim scoringiem otrzymują decyzję kredytową w kilka minut bez angażowania analityka.\n",
    "\n",
    "* **AML (Anti-Money Laundering)** – wykrywanie podejrzanych transakcji.\n",
    "  📌 *Case study:* Model GNN analizuje sieci powiązań transakcyjnych. Nietypowe wzorce (łańcuchy przelewów między spółkami-słupami) automatycznie trafiają do działu compliance.\n",
    "\n",
    "* **Detekcja fraudów** – analiza schematów płatności w celu wychwycenia oszustw.\n",
    "  📌 *Case study:* System monitoruje transakcje kartowe w czasie rzeczywistym. W razie podejrzeń blokuje płatność i wysyła klientowi SMS z prośbą o potwierdzenie.\n",
    "\n",
    "* **Prognozy rynkowe** – przewidywanie trendów giełdowych i kursów walut.\n",
    "  📌 *Case study:* Fundusz inwestycyjny używa modelu LSTM do przewidywania krótkoterminowych trendów kursu EUR/USD i dostosowuje portfel inwestycji.\n",
    "\n",
    "* **Chatboty obsługi klienta** – automatyczne odpowiedzi na pytania klientów.\n",
    "  📌 *Case study:* Bankowy chatbot odpowiada na pytania o saldo, limity kart, a w razie problemów przekierowuje rozmowę do konsultanta.\n",
    "\n",
    "---\n",
    "\n",
    "#### Handel i marketing\n",
    "\n",
    "* **Rekomendacje produktów** – dobór ofert dopasowanych do klienta.\n",
    "  📌 *Case study:* Sklep internetowy wdrożył model transformerowy, który analizuje sekwencje kliknięć. Klient po wejściu na stronę od razu widzi listę produktów „dla Ciebie”.\n",
    "\n",
    "* **Personalizacja mailingów** – dynamiczne treści w e-mailach.\n",
    "  📌 *Case study:* System wybiera w mailingu różne zdjęcia i teksty w zależności od profilu klienta – fani sportu dostają promocje na sprzęt, a miłośnicy elektroniki na nowe gadżety.\n",
    "\n",
    "* **Prognozy popytu** – planowanie sprzedaży i zapasów.\n",
    "  📌 *Case study:* Sieć handlowa prognozuje sprzedaż produktów na podstawie historii i sezonowości. Dzięki temu unika braków towarów i strat z powodu nadmiaru.\n",
    "\n",
    "* **Dynamic pricing** – automatyczne dostosowywanie cen.\n",
    "  📌 *Case study:* Platforma rezerwacyjna hoteli ustala ceny w zależności od lokalnego popytu i wydarzeń. Podczas koncertu w mieście ceny rosną, a poza sezonem spadają.\n",
    "\n",
    "---\n",
    "\n",
    "#### Media\n",
    "\n",
    "* **Klasyfikacja treści** – kategoryzowanie artykułów, zdjęć czy filmów.\n",
    "  📌 *Case study:* Portal newsowy automatycznie oznacza artykuły etykietami „polityka”, „sport”, „rozrywka”. To ułatwia rekomendacje i wyszukiwanie.\n",
    "\n",
    "* **Moderacja treści** – wykrywanie naruszeń regulaminu.\n",
    "  📌 *Case study:* Serwis społecznościowy używa NLP i CV do filtrowania komentarzy oraz zdjęć. Posty oznaczone przez AI trafiają do moderatora.\n",
    "\n",
    "* **Generowanie opisów** – np. podpisy do zdjęć.\n",
    "  📌 *Case study:* Agencja prasowa korzysta z modelu Vision+Language. Do zdjęcia z wydarzenia generowany jest opis: „Premier przemawia podczas szczytu w Brukseli”.\n",
    "\n",
    "* **Tłumaczenia** – automatyczne przekłady treści.\n",
    "  📌 *Case study:* Serwis streamingowy udostępnia serial w kilkunastu językach dzięki modelom tłumaczeniowym (MarianMT, M2M-100).\n",
    "\n",
    "---\n",
    "\n",
    "#### Administracja / sektor publiczny\n",
    "\n",
    "* **OCR dokumentów** – automatyczne odczytywanie i digitalizacja.\n",
    "  📌 *Case study:* Urząd gminy skanuje papierowe wnioski. OCR zamienia je w tekst, który trafia bezpośrednio do systemu obiegu dokumentów.\n",
    "\n",
    "* **Kategoryzacja pism** – przypisywanie spraw do działów.\n",
    "  📌 *Case study:* Model NLP klasyfikuje wnioski jako „podatki”, „budownictwo”, „świadczenia socjalne”. Trafiają od razu do odpowiedniego urzędnika.\n",
    "\n",
    "* **Chatboty informacyjne** – odpowiadają mieszkańcom.\n",
    "  📌 *Case study:* Mieszkaniec pyta przez stronę miasta: „Jak złożyć wniosek o dowód osobisty?”. Chatbot odsyła do formularza i podaje listę wymaganych dokumentów.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c625b2588411c5d4",
   "metadata": {},
   "source": [
    "## „Co do czego się nadaje” – praktyczna ściąga doboru modeli\n",
    "\n",
    "- Obrazy (klasyfikacja/detekcja/segmentacja): CNN/ViT; mało danych – transfer learning (fine‑tuning pre‑trained)\n",
    "- Tekst (klasyfikacja/QA/streszczanie): BERT/T5/LLM; mało danych – logreg/SVM + TF‑IDF jako baseline\n",
    "- ASR/TTS: Whisper, wav2vec 2.0, Tacotron/HiFi‑GAN\n",
    "- Szeregi czasowe: Prophet/ARIMA (baseline), GBM, następnie LSTM/Transformers przy większej skali\n",
    "- Tabular: najpierw XGBoost/LightGBM/CatBoost; DL gdy łączysz multimodalne dane lub masz bardzo duże zbiory\n",
    "- Rekomendacje: matrix factorization → DeepFM/Wide&Deep → sekwencyjne Transformers\n",
    "- Anomalie: izolacyjne lasy (IF), One‑Class SVM, autoenkodery, probabilistyczne (VAE)\n",
    "- Grafy: GNN gdy relacje między obiektami są kluczowe\n",
    "\n",
    "Dodatkowe wskazówki:\n",
    "- Zawsze zacznij od prostego baseline’u (regresja/logreg, GBM) i dopiero potem przechodź do DL.\n",
    "- Transfer learning i gotowe wektory (obrazy: ImageNet, tekst: BERT/fastText) często kluczowe przy małej liczbie próbek.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6779835-80fc-4c5c-aa64-2a15a6b0b686",
   "metadata": {},
   "source": [
    "## Jak wybierać model? Krótka procedura\n",
    "\n",
    "### Zdefiniuj typ problemu\n",
    "\n",
    "Najpierw jasno określ, co chcesz osiągnąć:\n",
    "\n",
    "* **Klasyfikacja** – przewidywanie kategorii (np. spam / nie-spam).\n",
    "* **Regresja** – przewidywanie wartości liczbowej (np. cena mieszkania).\n",
    "* **Detekcja / segmentacja** – znajdowanie obiektów na obrazach.\n",
    "* **QA (Question Answering)** – odpowiadanie na pytania na podstawie tekstu.\n",
    "* **Ranking / rekomendacje** – porządkowanie wyników względem użytkownika.\n",
    "* **Generacja** – tworzenie tekstów, obrazów czy dźwięków.\n",
    "\n",
    "---\n",
    "\n",
    "### Sprawdź dane\n",
    "\n",
    "Zrozum charakterystykę danych:\n",
    "\n",
    "* **Struktura** – obraz, tekst, dane tabelaryczne, graf, sygnał.\n",
    "* **Rozmiar** – mały zbiór (setki przykładów) vs. bardzo duży (miliony).\n",
    "* **Jakość** – szumy, brakujące wartości, błędne etykiety.\n",
    "* **Balans klas** – czy wszystkie etykiety są reprezentowane porównywalnie.\n",
    "\n",
    "---\n",
    "\n",
    "### Ustal metryki biznesowe\n",
    "\n",
    "Zanim zaczniesz trenować, określ co znaczy „dobrze”:\n",
    "\n",
    "* **Klasyfikacja**: F1, ROC-AUC, Precision, Recall.\n",
    "* **Regresja**: MAE, RMSE, R².\n",
    "* **Ranking / rekomendacje**: Precision@K, nDCG.\n",
    "* **Generacja**: BLEU, ROUGE, METEOR, albo metryki subiektywne (np. ocena użytkownika).\n",
    "\n",
    "---\n",
    "\n",
    "### Zbuduj prosty baseline\n",
    "\n",
    "Nie zaczynaj od najbardziej złożonych sieci – prosty punkt odniesienia jest kluczowy:\n",
    "\n",
    "* **Tabular**: gradient boosting (XGBoost, LightGBM, CatBoost).\n",
    "* **Tekst**: TF-IDF + logreg/SVM.\n",
    "* **Obrazy**: prosta regresja logistyczna na cechach z modelu pre-trained (np. ResNet).\n",
    "\n",
    "---\n",
    "\n",
    "### Gdy baseline za słaby → Deep Learning dopasowany do modalności\n",
    "\n",
    "* **Obrazy**: CNN, ViT (Vision Transformer).\n",
    "* **Tekst**: BERT/LLM, T5, GPT.\n",
    "* **Ciągi czasowe**: LSTM, GRU, Transformer.\n",
    "* **Grafy**: GCN, GraphSAGE, GAT.\n",
    "\n",
    "---\n",
    "\n",
    "### Walidacja i higiena eksperymentu\n",
    "\n",
    "* **Cross-validation** lub dedykowane podziały (np. time series split).\n",
    "* **Unikanie data leakage** – dane z przyszłości albo informacje ze zbioru testowego nie mogą trafiać do treningu.\n",
    "* **Rzetelna ocena** – nie opieraj się tylko na accuracy, jeśli problem jest niezbalansowany.\n",
    "\n",
    "---\n",
    "\n",
    "### Uprość wdrożenie\n",
    "\n",
    "Nawet najlepszy model nie ma sensu, jeśli nie da się go efektywnie używać:\n",
    "\n",
    "* **Rozmiar modelu** – czy mieści się w pamięci?\n",
    "* **Latencja** – czy odpowiada szybko (np. <100 ms w chatbotach)?\n",
    "* **Koszty** – GPU/CPU, inference w chmurze.\n",
    "* **Optymalizacja**:\n",
    "\n",
    "  * *Destylacja* – mniejszy model uczony przez większy.\n",
    "  * *KV-cache* – przyspiesza generację w LLM.\n",
    "  * *Quantization* – redukuje rozmiar kosztem minimalnej utraty jakości.\n",
    "\n",
    "### Przykład: prognozowanie sprzedaży\n",
    "\n",
    "\n",
    "### Zdefiniuj typ problemu\n",
    "\n",
    "Cel: **przewidzieć sprzedaż produktów w kolejnych dniach**.\n",
    "➡️ Typ: **regresja (time series forecasting)**.\n",
    "\n",
    "---\n",
    "\n",
    "### Sprawdź dane\n",
    "\n",
    "Masz dane historyczne:\n",
    "\n",
    "* cechy czasowe (dzień tygodnia, święta, promocje),\n",
    "* cechy produktu (kategoria, cena),\n",
    "* dane o pogodzie i kampaniach reklamowych.\n",
    "  ➡️ Dane są dość obszerne (miliony wierszy), ale pojawiają się brakujące wartości (np. brak odnotowanej sprzedaży).\n",
    "\n",
    "---\n",
    "\n",
    "### Ustal metryki biznesowe\n",
    "\n",
    "Firma chce **unikać braków w magazynie**.\n",
    "➡️ Metryka: **MAE (Mean Absolute Error)** dla prognozy liczby sztuk.\n",
    "Dodatkowo: **MAPE** (żeby rozumieć błąd w %).\n",
    "\n",
    "---\n",
    "\n",
    "### Zbuduj baseline\n",
    "\n",
    "* Prosty model: **Prophet / ARIMA** dla każdej serii produktowej.\n",
    "* Alternatywnie: **LightGBM** z cechami kalendarzowymi i lagami (sprzedaż z ostatnich dni).\n",
    "  ➡️ Szybko sprawdzasz, czy nawet prosty model daje zadowalającą prognozę.\n",
    "\n",
    "---\n",
    "\n",
    "### Gdy baseline za słaby → Deep Learning\n",
    "\n",
    "Jeśli MAE nadal jest wysokie:\n",
    "\n",
    "* **LSTM / GRU** – do modelowania sekwencji sprzedaży.\n",
    "* **Temporal Convolutional Networks (TCN)** – do dłuższych zależności czasowych.\n",
    "* **Transformery do szeregów czasowych** (np. Informer, TFT) – szczególnie przy wielu produktach i dużych zbiorach danych.\n",
    "\n",
    "---\n",
    "\n",
    "### Walidacja i higiena eksperymentu\n",
    "\n",
    "* Użyj **time series split** (nie shuffle, żeby nie mieszać przyszłości z przeszłością).\n",
    "* Sprawdź, czy model nie podgląda danych z przyszłości (np. feature leakage z agregatów).\n",
    "* Oceń wyniki nie tylko na średnim MAE, ale też na produktach kluczowych biznesowo.\n",
    "\n",
    "---\n",
    "\n",
    "### Uprość wdrożenie\n",
    "\n",
    "* Czy model może działać codziennie dla tysięcy produktów?\n",
    "* Jeśli Transformer jest za wolny → distylacja lub prostszy GBM z dobrze dobranymi cechami.\n",
    "* Jeżeli deployment jest w chmurze → policz koszty inference (czy GPU się opłaca).\n",
    "\n",
    "---\n",
    "\n",
    "📌 **Efekt końcowy:**\n",
    "Sklep zaczyna od **LightGBM baseline**, który daje szybkie i zaskakująco dobre wyniki.\n",
    "\n",
    "Dla najważniejszych produktów eksperymentuje z **Transformerem**, a tam gdzie koszty są zbyt duże – zostaje przy GBM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3cf593dff775e",
   "metadata": {},
   "source": [
    "## Kiedy nie używać deep learningu?\n",
    "\n",
    "- Bardzo mało danych, prosta struktura → klasyczne ML lub nawet reguły\n",
    "- Silne ograniczenia latency/zasobów na urządzeniu i brak możliwości kompresji → model lekki (GBM, logreg)\n",
    "- Problem zrozumiałości (compliance) → modele interpretowalne (drzewa, GLM) lub techniki XAI (SHAP, LIME) do DL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d866c53f1a1929",
   "metadata": {},
   "source": [
    "## Zasoby i biblioteki\n",
    "\n",
    "- PyTorch, TensorFlow/Keras – główne frameworki DL\n",
    "- Hugging Face Transformers/Datasets – NLP i multi‑modal\n",
    "- timm, ultralytics/YOLO, detectron2, mmcv/mmdetection – CV\n",
    "- xgboost, lightgbm, catboost – tabular\n",
    "- prophet, darts, gluonts – szeregi czasowe\n",
    "- pytorch‑geometric, dgl – GNN\n",
    "- mlflow, wandb – śledzenie eksperymentów; onnx/torch‑tensorrt – wdrażanie i przyspieszanie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a1dbdb8c60ae4",
   "metadata": {},
   "source": [
    "## Podsumowanie\n",
    "\n",
    "- Dobór techniki zależy od typu danych, ilości przykładów i ograniczeń wdrożeniowych.\n",
    "- Zaczynaj od prostych baseline’ów i stopniowo zwiększaj złożoność.\n",
    "- Transfer learning, dobre walidacje i właściwe metryki często dają większy zwrot niż „nowa architektura”.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187607e6-6358-48a3-828c-ecb516bf29ac",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Słowniczek – ściąga\n",
    "\n",
    "| Pojęcie                   | Definicja                                                                          |\n",
    "| ------------------------- | ---------------------------------------------------------------------------------- |\n",
    "| **ML (Machine Learning)** | Uczenie maszynowe.                                                                 |\n",
    "| **DL (Deep Learning)**    | Uczenie głębokie, poddziedzina ML.                                                 |\n",
    "| **model**                 | Algorytm rozwiązujący konkretny problem. W tym też często sieć neuronowa           |\n",
    "| **sieć neuronowa (NN)**   | Podstawowy budulec DL – uczy się z danych wykonywać zadania (np. klasyfikację).    |\n",
    "| **warstwa wejściowa**     | Pierwsza warstwa sieci, przyjmuje dane.                                            |\n",
    "| **warstwa wyjściowa**     | Ostatnia warstwa sieci, zwraca wynik (np. prawdopodobieństwa klas).                |\n",
    "| **warstwy ukryte**        | Wszystkie warstwy pomiędzy wejściem a wyjściem; tam dzieje się „magia” obliczeń.   |\n",
    "| **funkcja aktywacyjna**   | Nadaje sieci nieliniowość, umożliwia uczenie się złożonych zależności.             |\n",
    "| **optymalizator**         | Algorytm modyfikujący wagi w procesie uczenia.                                     |\n",
    "| **framework ML**          | Biblioteka do budowania/uczenia sieci (np. TensorFlow, PyTorch).                   |\n",
    "| **funkcja błędu (loss)**  | Określa, jak bardzo wynik modelu różni się od wartości oczekiwanej.                |\n",
    "| **forward propagation**   | Przekazywanie danych od wejścia do wyjścia.                                        |\n",
    "| **backpropagation**       | Mechanizm uczenia – korekta wag na podstawie błędu.                                |\n",
    "| **Gradient Descent**      | Metoda optymalizacji wag polegająca na „schodzeniu” po zboczu funkcji błędu w dół. |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a808ee-8540-4328-8930-4254d6594b49",
   "metadata": {},
   "source": [
    "## Nasze zajęcia\n",
    "\n",
    "Na zajęciach praktycznych wykorzystamy te koncepcje w prostych przykładach:\n",
    "\n",
    "* użyjemy **sieci neuronowych do regresji i klasyfikacji**,\n",
    "* popracujemy także na **danych tabelarycznych** – mimo że deep learning nie zawsze jest tu najlepszym wyborem, to na ich przykładzie łatwo pokazać podstawowe mechanizmy,\n",
    "* zastosujemy sieci do **rozpoznawania pisma ręcznego (MNIST)**,\n",
    "* spróbujemy także swoich sił w problemach z danymi sekwencyjnymi - takimi jak NLP czy serie czasowe. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
