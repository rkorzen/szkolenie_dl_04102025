{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb46bcbe",
   "metadata": {},
   "source": [
    "# Embeddingi w Uczeniu Maszynowym\n",
    "Embedding to reprezentacja obiektów (np. słów, produktów, użytkowników) w przestrzeni wektorowej o niskim wymiarze. Umożliwia uchwycenie podobieństw semantycznych lub kontekstowych, których nie widać w prostych reprezentacjach.\n",
    "\n",
    "Embeddingi istnieją tylko „na tokenach” i bez tokenizacji nie da się ich użyć."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621f2cf9-dfd8-4352-a1c7-d30f246744e3",
   "metadata": {},
   "source": [
    "\n",
    "## Token – co to jest?\n",
    "\n",
    "**Token** to podstawowa jednostka tekstu, na której pracuje model NLP.\n",
    "To „kawałek” zdania zamieniony na liczbę (indeks w słowniku).\n",
    "\n",
    "### Rodzaje tokenów\n",
    "\n",
    "* **słowo** – np. „lubię uczyć się” → `[lubię] [uczyć] [się]`\n",
    "* **znak (litera)** – „kot” → `[k] [o] [t]`\n",
    "* **subword (fragment wyrazu)** – „uczyłbym” → `[uczył] [by] [m]`\n",
    "* **specjalne tokeny** – `<pad>` (padding), `<unk>` (nieznane słowo), `<cls>` (początek zdania)\n",
    "\n",
    "### Token w praktyce\n",
    "\n",
    "1. **Tokenizacja** – tekst dzielimy na tokeny.\n",
    "   „lubię uczyć się pytorch” → `[1, 2, 3, 4]`\n",
    "   (gdzie każdemu słowu przypisany jest numer w słowniku).\n",
    "2. **Embedding** – każdy token (numer) zamieniany jest na wektor liczb.\n",
    "   `[1, 2, 3, 4]` →\n",
    "\n",
    "   ```\n",
    "   [[0.01, -0.02, 0.03],   # token „lubię”\n",
    "    [0.05,  0.01, -0.04],  # token „uczyć”\n",
    "    [0.02,  0.07, -0.01],  # token „się”\n",
    "    [0.09, -0.03, 0.02]]   # token „pytorch”\n",
    "   ```\n",
    "\n",
    "### Podsumowanie\n",
    "\n",
    "* **Token = indeks w słowniku** (np. 2 → „uczyć”).\n",
    "* **Embedding = wektor liczb przypisany do tokenu**, który reprezentuje jego znaczenie w przestrzeni wektorowej.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e79ea9",
   "metadata": {},
   "source": [
    "## Dlaczego embeddingi?\n",
    "- **Problem z one-hot encodingiem**: \n",
    "  - wymiar wektora rośnie liniowo wraz z liczbą kategorii (np. dla 50 kategorii dostajemy wektory długości 50, w większości wypełnione zerami),\n",
    "  - brak informacji o podobieństwie między kategoriami (wszystkie są tak samo odległe).\n",
    "  - np. kategorie `1, 2, 3` → one-hot: `[1,0,0]`, `[0,1,0]`, `[0,0,1]`.\n",
    "- **Embeddingi (gęste wektory)**:\n",
    "  - reprezentują każdą kategorię jako wektor w przestrzeni o dużo niższym wymiarze (np. 50 kategorii → embeddingi 4-wymiarowe),\n",
    "  - odległość i kierunek wektorów mogą uchwycić podobieństwo między kategoriami (np. `pies` i `kot` będą bliżej siebie niż `pies` i `samochód`).\n",
    "- **Uczenie embeddingów**:\n",
    "  - embeddingi są **parametrami modelu**,\n",
    "  - są aktualizowane podczas trenowania (uczone end-to-end razem z resztą sieci),\n",
    "  - dzięki temu model sam znajduje „najlepszą” reprezentację kategorii dla zadania.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051f97c",
   "metadata": {},
   "source": [
    "## Jak embeddingi działają matematycznie\n",
    "- Każdy obiekt otrzymuje numer (indeks).\n",
    "- Indeks trafia do macierzy `E` o wymiarach `(liczba_kategorii, rozmiar_wektora)`.\n",
    "- Wektor embeddingu to po prostu wiersz macierzy `E` wskazywany przez indeks.\n",
    "- Podczas uczenia gradienty przepływają do odpowiednich wierszy, dzięki czemu wektory uczą się reprezentować relacje między obiektami."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d988481",
   "metadata": {},
   "source": [
    "### Przykład: od `one-hot` do embeddingu\n",
    "Załóżmy, że mamy taki mały słownik:\n",
    "\n",
    "```{\"kot\":0, \"pies\":1, \"ryba\":2}``` \n",
    "\n",
    "i rozmiar wektora równy 3. \n",
    "\n",
    "Macierz embeddingu `E` będzie miała kształt `(3, 3)`. \n",
    "\n",
    "Wektor *kot* to odpowiedni wiersz macierzy. \n",
    "\n",
    "Poniżej pokazujemy, jak można wykorzystać prostą tablicę NumPy do symulacji pobierania embeddingów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2d887bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2,  0.5, -0.1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "vocab = {\"kot\": 0, \"pies\": 1, \"ryba\": 2}\n",
    "E = np.array([\n",
    "    [0.2, 0.5, -0.1],  # wektor \"kot\"\n",
    "    [0.3, 0.4, -0.2],  # wektor \"pies\"\n",
    "    [-0.1, 0.7, 0.6],  # wektor \"ryba\"\n",
    "])\n",
    "\n",
    "word = \"kot\"\n",
    "idx = vocab[word]\n",
    "vector = E[idx]\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c4f7f",
   "metadata": {},
   "source": [
    "Wynikowy wektor można użyć w dalszych obliczeniach (np. przekazać do warstw liniowych, LSTM czy Transformerów)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2504ca00",
   "metadata": {},
   "source": [
    "## Trenowanie embeddingów\n",
    "\n",
    "Jedną z cech embeddingów jest to, że są uczone razem z modelem:\n",
    "\n",
    "1. Inicjalizujemy macierz losowo (lub z pretreningu).\n",
    "2. Przekazujemy indeksy kategorii przez warstwę embedding.\n",
    "3. Strata (np. krzyżowa entropia) aktualizuje konkretne wiersze macierzy.\n",
    "4. Po treningu mamy gęste reprezentacje uchwytujące współwystępowanie i podobieństwa.\n",
    "\n",
    "Embeddingi można również wstępnie wytrenować (Word2Vec, GloVe) i później dostosować do konkretnego zadania."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67909ada",
   "metadata": {},
   "source": [
    "### Embeddingi w TensorFlow\n",
    "\n",
    "W TensorFlow mamy specjalną warstwę `tf.keras.layers.Embedding`, która przyjmuje parametry `input_dim` (rozmiar słownika) oraz `output_dim` (rozmiar wektora). \n",
    "\n",
    "Warto ustawić również `mask_zero=True`, jeśli `0` oznacza padding - czyli wypełnianie pustych miejsc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d9fa7265-47bc-455e-9a9a-6056ba5ca459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b6ede3-e658-4dac-8391-539782f1b1c8",
   "metadata": {},
   "source": [
    "#### Słownik słów\n",
    "\n",
    "`<pad>` = specjalny token paddingu, zawsze indeks `0`\n",
    "\n",
    "Używa się go, aby \"wypełnić\" krótsze sekwencje do jednakowej długości.\n",
    "\n",
    "Dzięki temu możemy ułożyć zdania w macierz (**batch**), gdzie wszystkie mają tyle samo elementów.\n",
    "\n",
    "Padding to też jest token - tyle, że taki specjalny, który ma swój indeks, ale jest ignorowany w obliczeniach dzięki mask_zero / padding_idx”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1a4aac1b-cfec-4a74-be73-b000af5a7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {\"<pad>\": 0, \"lubię\": 1, \"uczyć\": 2, \"się\": 3, \"pytorch\": 4, \"tensorflow\": 5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0046c5-2a90-47f6-a026-3288469d18ba",
   "metadata": {},
   "source": [
    "#### zdania zakodowane indeksami (różne długości!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a33565f-e871-4688-996d-b2e4c7fb0e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    [1, 2],                # \"lubię uczyć\"\n",
    "    [1, 5],                # \"lubię tensorflow\"\n",
    "    [1, 2, 3, 4],          # \"lubię uczyć się pytorch\"\n",
    "    [1, 2, 3, 5, 4],        # \"lubię uczyć się tensorflow pytorch\"\n",
    "    [1, 4, 1, 5, 1, 2, 3]  # \"lubię pytorch lubię tensorflow lubie uczyć się\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152c7819-22dd-4acc-9090-4efd23108263",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f3a7eb8-bd0a-4681-8200-a8a3aac6b051",
   "metadata": {},
   "source": [
    "\n",
    "### Co to jest *batch*?\n",
    "\n",
    "Mamy 5 zdań - najdłuższe ma 7 wyrazów. Nasza próbka będzie mieć więc wymiar 5 x 7. Jak zbudujemy z tego macierz wypełnioną paddingami to to będzie batch - próbka\n",
    "\n",
    "* **Batch** = paczka/próbka zbiorcza danych, którą podajemy **naraz** do modelu w jednej iteracji.\n",
    "* Zamiast uczyć model na **pojedynczym zdaniu**, bierzemy kilka naraz, żeby:\n",
    "\n",
    "  1. **przyspieszyć uczenie** (wykorzystujemy równoległość na GPU),\n",
    "  2. **ustabilizować gradienty** (średnia z kilku próbek jest mniej „szarpana” niż z jednej).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e0c63145-2140-4a19-9d15-c70e75ad15b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad_sequences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e793e669-50fe-46ac-a99c-2c0ef8f224f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sekwencje po paddingu:\n",
      " [[1 2 0 0 0 0 0]\n",
      " [1 5 0 0 0 0 0]\n",
      " [1 2 3 4 0 0 0]\n",
      " [1 2 3 5 4 0 0]\n",
      " [1 4 1 5 1 2 3]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- padding do równej długości ---\n",
    "# domyślnie pad_sequences uzupełnia zerami (czyli <pad>)\n",
    "sequences = pad_sequences(sentences, padding=\"post\")\n",
    "\n",
    "print(\"Sekwencje po paddingu:\\n\", sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1d985559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 7, 4])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# --- Warstwa embedding ---\n",
    "embedding_layer = tf.keras.layers.Embedding(\n",
    "    input_dim=len(word_index),  # rozmiar słownika = 6 (liczymy też <pad>)\n",
    "    output_dim=4,               # każdy token będzie reprezentowany 4 liczbowymi współrzędnymi\n",
    "    mask_zero=True,             # bardzo ważne: ignoruj indeks 0 (czyli padding)\n",
    ")\n",
    "\n",
    "# --- Zastosowanie warstwy embedding ---\n",
    "embedded = embedding_layer(sequences)\n",
    "embedded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa5e6cd-1daf-456f-a3c8-1dac11335388",
   "metadata": {},
   "source": [
    "Zwrócony tensor ma kształt `(batch, sequence_length, output_dim)`.\n",
    "\n",
    "Warstwę embedding można dalej połączyć z modelami sekwencyjnymi (LSTM, GRU) lub konwolucyjnymi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d90da32",
   "metadata": {},
   "source": [
    "### Mini model z embeddingiem TensorFlow\n",
    "\n",
    "Poniżej prosty model klasyfikacji sentymentu złożony z embeddingu, warstwy global average pooling i gęstej warstwy wyjściowej.\n",
    "\n",
    "Warstwa global average pooling uśrednia wektory embeddingów wszystkich tokenów w zdaniu, tworząc jeden reprezentacyjny wektor zdania niezależny od jego długości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0e97cf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │            <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m4\u001b[0m)           │            \u001b[38;5;34m24\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_4      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29</span> (116.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m29\u001b[0m (116.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">29</span> (116.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m29\u001b[0m (116.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_tf = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(word_index), output_dim=4, mask_zero=True),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "])\n",
    "\n",
    "model_tf.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "model_tf.build(input_shape=(None, 5))\n",
    "model_tf.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f7b0c2cc-e3db-484b-b78a-85e125ed5086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kształt wejścia: (2, 5)\n",
      "Kształt po embeddingu: (2, 5, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 4), dtype=float32, numpy=\n",
       "array([[[-0.04859709,  0.04813931, -0.02673558,  0.03258622],\n",
       "        [-0.03453139,  0.04224342,  0.01542932,  0.00607534],\n",
       "        [-0.02308285,  0.03955093, -0.00429424, -0.04624949],\n",
       "        [-0.03083962, -0.03724318,  0.03123887, -0.02536358],\n",
       "        [-0.03083962, -0.03724318,  0.03123887, -0.02536358]],\n",
       "\n",
       "       [[-0.03374977,  0.04049555,  0.0312377 ,  0.00256505],\n",
       "        [-0.03451729,  0.01253356,  0.02043447,  0.0099626 ],\n",
       "        [-0.04859709,  0.04813931, -0.02673558,  0.03258622],\n",
       "        [-0.03083962, -0.03724318,  0.03123887, -0.02536358],\n",
       "        [-0.03083962, -0.03724318,  0.03123887, -0.02536358]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Załóżmy słownik o rozmiarze 6 (tokeny 0–5), embedding 4D\n",
    "embedding_layer = tf.keras.layers.Embedding(input_dim=6, output_dim=4, mask_zero=True)\n",
    "\n",
    "# Przykładowe zdania zakodowane jako indeksy tokenów\n",
    "# 0 = padding\n",
    "sentences = np.array([\n",
    "    [1, 2, 3, 0, 0],   # zdanie 1: trzy tokeny + padding\n",
    "    [4, 5, 1, 0, 0],   # zdanie 2: dwa tokeny + padding\n",
    "])\n",
    "\n",
    "print(\"Kształt wejścia:\", sentences.shape)\n",
    "\n",
    "# Embedding\n",
    "embedded = embedding_layer(sentences)\n",
    "print(\"Kształt po embeddingu:\", embedded.shape)\n",
    "embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6296f3b7-d10c-454f-a617-c5fe99ad7417",
   "metadata": {},
   "source": [
    "A więc 1 zdanie to taka macierz - coś takieggo (bedzie sie zmieniac przy uruchomieniach)\n",
    "\n",
    "        [[ 0.01423473, -0.00483084, -0.02746737, -0.02501923],  # 1\n",
    "        [ 0.02149788, -0.04756809, -0.04644064, -0.00472618],   # 2   \n",
    "        [ 0.00689582,  0.03334036, -0.00995095, -0.02848799],   # 3 \n",
    "        [-0.02906418, -0.01756475,  0.00183201,  0.03547058],   # 0\n",
    "        [-0.02906418, -0.01756475,  0.00183201,  0.03547058]]   # 0\n",
    "\n",
    "I pooling sumuje to kolumnami i liczy średnią - ale pomija to co jest naszym paddingiem\n",
    "\n",
    "To 1, 2, 3  nazywamy tokenami - czyli najmniejszymi porcjami tekstu, który rozumie nasz model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "077413d2-8a68-47db-9eed-3a06eda2467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kształt po pooling: (2, 4)\n",
      "Wektor reprezentujący każde zdanie:\n",
      " [[-0.03540378  0.04331122 -0.00520017 -0.00252931]\n",
      " [-0.03895472  0.0337228   0.0083122   0.01503795]]\n"
     ]
    }
   ],
   "source": [
    "# Global Average Pooling\n",
    "pooled = tf.keras.layers.GlobalAveragePooling1D()(embedded)\n",
    "print(\"Kształt po pooling:\", pooled.shape)\n",
    "print(\"Wektor reprezentujący każde zdanie:\\n\", pooled.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a9e82-ddb8-4f3b-9452-1ae1a975312e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a57cc3b9",
   "metadata": {},
   "source": [
    "### Embeddingi w PyTorch\n",
    "W PyTorch embeddingi tworzymy przez `torch.nn.Embedding(num_embeddings, embedding_dim)`. Przykład poniżej pokazuje pobieranie wektorów oraz prosty model klasyfikacyjny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8b5f00ac-b89b-4bb6-8a17-34ae953c3445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 0, 0, 0],\n",
      "        [1, 2, 3, 4, 0],\n",
      "        [1, 2, 3, 5, 4]])\n",
      "Kształt: torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# --- przykładowe zdania o różnej długości ---\n",
    "sentences = [\n",
    "    torch.tensor([1, 2]),          # \"lubię uczyć\"\n",
    "    torch.tensor([1, 2, 3, 4]),    # \"lubię uczyć się pytorch\"\n",
    "    torch.tensor([1, 2, 3, 5, 4])  # \"lubię uczyć się tensorflow pytorch\"\n",
    "]\n",
    "\n",
    "# --- padding ---\n",
    "# domyślnie padding jest z lewej (do najdłuższej sekwencji)\n",
    "seqences = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
    "\n",
    "print(seqences)\n",
    "print(\"Kształt:\", seqences.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6eac8381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 4])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = nn.Embedding(num_embeddings=len(word_index), embedding_dim=4, padding_idx=0)\n",
    "embedded_torch = embedding(seqences)\n",
    "embedded_torch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db3a48-3449-4734-b9db-76ff9ddf79fc",
   "metadata": {},
   "source": [
    "Tu nasz batch_size to 3, najdłuższe zdanie ma 5 wyrazów a embedding ma wymiar 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594c5b8d",
   "metadata": {},
   "source": [
    "#### Mini model z embeddingiem w PyTorch\n",
    "Poniższy moduł wykorzystuje warstwę embedding, uśrednia wektory wzdłuż sekwencji i przekazuje wynik do warstwy liniowej. To minimalny szkic klasyfikatora tekstu opartego na PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9b05c77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleTextClassifier(\n",
       "  (embedding): Embedding(6, 4, padding_idx=0)\n",
       "  (pool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (classifier): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleTextClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.classifier = nn.Linear(embed_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)  # (batch, seq, embed_dim)\n",
    "        # zamieniamy na (batch, embed_dim, seq), aby użyć 1D pooling\n",
    "        pooled = self.pool(embedded.transpose(1, 2)).squeeze(-1)\n",
    "        logits = self.classifier(pooled)\n",
    "        return torch.sigmoid(logits)\n",
    "\n",
    "model_torch = SimpleTextClassifier(vocab_size=len(word_index), embed_dim=4)\n",
    "model_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ec75cbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5364],\n",
       "        [0.5611],\n",
       "        [0.5526]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    pred = model_torch(seqences)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5479ed",
   "metadata": {},
   "source": [
    "## 6. Dobre praktyki i wskazówki\n",
    "- Dobierz `embedding_dim` do wielkości słownika (zazwyczaj 16–300 dla prostych zadań NLP, więcej dla rekomendacji).\n",
    "- Używaj `padding_idx` (PyTorch) lub `mask_zero` (TensorFlow), jeśli w sekwencjach występują wartości wypełniające.\n",
    "- Możesz zacząć od losowej inicjalizacji i pozwolić modelowi uczyć się embeddingów lub wykorzystać embeddingi pretrenowane (np. FastText) i dostosować je (`fine-tuning`).\n",
    "- Analizuj embeddingi po treningu: wizualizuj PCA/TSNE, porównuj najbliższe wektory, by zweryfikować, czy model nauczył się semantyki."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dfb3ec",
   "metadata": {},
   "source": [
    "## 7. Zastosowania embeddingów\n",
    "- Natural Language Processing (word embeddings, sentence embeddings, wektory dokumentów).\n",
    "- Systemy rekomendacji (embeddingi użytkowników i produktów).\n",
    "- Modele grafowe (Graph Embedding, Node2Vec).\n",
    "- Kodowanie zmiennych kategorycznych w modelach tablicowych (np. tabular deep learning).\n",
    "\n",
    "Embeddingi stanowią fundament nowoczesnych modeli, ponieważ pozwalają zamienić surowe kategorie na przestrzenie, w których łatwiej znaleźć wzorce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9e8493-d12e-4229-ad24-64f4f1c20dae",
   "metadata": {},
   "source": [
    "## Przykład: embeddingi w prostym modelu\n",
    "\n",
    "Symulujemy prosty zbiór danych klientów:\n",
    "\n",
    "* **`region`** – kategoria (10 regionów, zakodowane jako liczby 0–9),\n",
    "* **`wiek`** – zmienna ciągła,\n",
    "* **`dochód`** – zmienna ciągła,\n",
    "* **`abonament`** – target (0/1, czy klient ma abonament).\n",
    "\n",
    "W typowym ML:\n",
    "\n",
    "* cechy ciągłe możemy podać „tak jak są” (po normalizacji/standaryzacji),\n",
    "* ale **cechy kategoryczne** (jak `region`) nie mają sensownego porządku → tu właśnie używamy **embeddingów**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b38a4c2b-9a3b-4c1c-b390-156ab5f057a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ---------------------\n",
    "# 1. Dane przykładowe\n",
    "# ---------------------\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 500\n",
    "n_regions = 10  # kategorie regionów\n",
    "\n",
    "raw_data = pd.DataFrame({\n",
    "    # to są od razu indeksy kategorii wiec nie zamieniam juz tego na dane kategoryczne\n",
    "    # gdyby tu były jakies labelki - typu \"dolnosląski\", \"polnocno-zachodni\" itd to zamieniałbym\n",
    "    \"region\": np.random.randint(0, n_regions, size=n_samples),  \n",
    "    \"wiek\": np.random.randint(18, 70, size=n_samples),\n",
    "    \"dochód\": np.random.randint(2000, 12000, size=n_samples),\n",
    "    \"abonament\": np.random.randint(0, 2, size=n_samples)  # target: 0/1\n",
    "})\n",
    "\n",
    "categorical_cols = [\"region\"]\n",
    "continuous_cols = [\"wiek\", \"dochód\"]\n",
    "target_col = \"abonament\"\n",
    "\n",
    "X_cat = torch.tensor(raw_data[categorical_cols].values, dtype=torch.long)\n",
    "X_cont = torch.tensor(raw_data[continuous_cols].values, dtype=torch.float32)\n",
    "y = torch.tensor(raw_data[target_col].values, dtype=torch.float32).view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d21305-851d-4520-8bb9-bc4705bd0508",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Model\n",
    "\n",
    "* Dla cechy kategorycznej `region` uczymy **embedding** o wymiarze 6 (czyli każdemu regionowi odpowiada wektor długości 6).\n",
    "* Dla cech ciągłych (`wiek`, `dochód`) stosujemy prostą warstwę liniową, aby dopasować skalę.\n",
    "* Oba wektory (embedding + cechy ciągłe) są łączone i wysyłane do sieci neuronowej, która przewiduje `abonament`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6f8b81c4-ded3-47f4-9cac-043c37f91b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------\n",
    "# 2. Model z embeddingami\n",
    "# ---------------------\n",
    "class CustomerModel(nn.Module):\n",
    "    def __init__(self, n_regions, emb_dim, n_cont):\n",
    "        super().__init__()\n",
    "        # embedding dla zmiennej kategorycznej \"region\" - wartość będzie podana przy inicjalizacji\n",
    "        self.emb = nn.Embedding(n_regions, emb_dim)\n",
    "        # warstwa dla cech ciągłych\n",
    "        self.fc_cont = nn.Linear(n_cont, 4)\n",
    "        # klasyfikator końcowy\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(emb_dim + 4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x_emb = self.emb(x_cat).squeeze(1)        # embedding regionu\n",
    "        x_cont = self.fc_cont(x_cont)             # przekształcone dane ciągłe\n",
    "        x = torch.cat([x_emb, x_cont], dim=1)     # połączenie\n",
    "        return self.fc(x)\n",
    "\n",
    "model = CustomerModel(n_regions=n_regions, emb_dim=6, n_cont=len(continuous_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae4ef6f-526f-460f-82dc-309ca1f49378",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Trening\n",
    "\n",
    "Model uczy się end-to-end:\n",
    "\n",
    "* embeddingi regionów są **parametrami sieci**,\n",
    "* w trakcie treningu są aktualizowane, aby jak najlepiej pomagały w przewidywaniu abonamentu.\n",
    "\n",
    "W praktyce oznacza to: **regiony, które w podobny sposób wpływają na prawdopodobieństwo posiadania abonamentu, będą miały embeddingi bliżej siebie w przestrzeni wektorowej**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77575e7c-995d-4937-934b-4a665e4b7dc1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Analiza embeddingów\n",
    "\n",
    "Po treningu wyciągamy macierz embeddingów:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e783bb99-86a4-48b6-94c4-368d510fb700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6737331 , -0.60998917, -0.22300157,  1.916311  , -0.25630867,\n",
       "        0.7061841 ], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.emb.weight.detach().numpy()\n",
    "\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98180006-78c4-4ddd-9e2c-27b8be1e53a5",
   "metadata": {},
   "source": [
    "* kształt = `10 x 6` (10 regionów, embedding_dim=6),\n",
    "* każda linia = wektor opisujący dany region. Ten wektor ma 6 współrzędnych.\n",
    "\n",
    "Aby je zobaczyć:\n",
    "\n",
    "* redukujemy wymiar do 2D przy pomocy PCA,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ce5d37-d7cd-4441-9f3f-bdb5f6bb7442",
   "metadata": {},
   "source": [
    "### PCA — Principal Component Analysis (Analiza Głównych Składowych)\n",
    "\n",
    "Metoda redukcji wymiaru, która przekształca dane do nowej przestrzeni współrzędnych,\n",
    "tak aby **pierwsze składowe** przechwytywały jak najwięcej wariancji w danych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "848be7fa-4568-4bb8-bd6b-9d9e5f3e805b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.6035028, -0.3859304], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "embeddings_2d[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c05d508-773f-4fc5-9e5b-7353883944f9",
   "metadata": {},
   "source": [
    "* rysujemy punkty odpowiadające regionom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c11142e8-ae2b-48fa-af5a-00ed9b05d7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=range(n_regions), cmap=\"tab10\", s=80)\n",
    "\n",
    "for i in range(n_regions):\n",
    "    plt.annotate(f\"region {i}\", (embeddings_2d[i, 0]+0.02, embeddings_2d[i, 1]+0.02))\n",
    "\n",
    "plt.title(\"Embeddingi regionów (PCA do 2D)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa68ad-9892-485b-bff1-15c649a10125",
   "metadata": {},
   "source": [
    "Wykres pokazuje, że **niektóre regiony grupują się bliżej siebie** — czyli model „uznał”, że są podobne z punktu widzenia abonamentu.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Wnioski i korzyści z embeddingów\n",
    "\n",
    "1. **Redukcja wymiarowości**\n",
    "\n",
    "   * Zamiast one-hot (10 kategorii → wektor długości 10), używamy embeddingów (np. wymiar 6).\n",
    "   * Przy większych słownikach (np. 1000 kategorii) oszczędność jest ogromna.\n",
    "\n",
    "2. **Uchwycenie podobieństw**\n",
    "\n",
    "   * W one-hot wszystkie kategorie są „równie odległe”.\n",
    "   * Embeddingi pozwalają modelowi samodzielnie nauczyć się, które kategorie są podobne.\n",
    "   * Np. regiony o podobnej strukturze klientów będą mieć wektory bliżej siebie.\n",
    "\n",
    "3. **Uczą się razem z modelem**\n",
    "\n",
    "   * Nie musimy ręcznie kodować relacji między kategoriami.\n",
    "   * Model sam znajdzie najlepszą reprezentację dla danego zadania.\n",
    "\n",
    "4. **Łatwość analizy**\n",
    "\n",
    "   * Po treningu embeddingi można interpretować:\n",
    "\n",
    "     * grupować kategorie,\n",
    "     * wizualizować (PCA/t-SNE/UMAP),\n",
    "     * szukać najbliższych sąsiadów (np. „które regiony są najbardziej podobne?”).\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Podsumowanie**:\n",
    "W tym przykładzie embedding pozwala traktować **region** nie jako arbitralny numer, lecz jako **punkt w przestrzeni wektorowej**, gdzie bliskość oznacza podobieństwo w kontekście abonamentu. Dzięki temu model uczy się szybciej, ma mniej parametrów i potrafi generalizować lepiej niż przy gołym one-hot encodingu.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
